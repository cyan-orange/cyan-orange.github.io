<feed>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15322256.html</id>
        <title type="text">Java 集合-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-22T15:12:00Z</published>
        <updated>2021-09-22T15:12:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15322256.html" />
        <content type="text">
Java 集合就像一种容器，可以动态地把多个对象的引用放入容器中。


# 数组与集合的比较


数组在内存存储方面的特点：


- 数组初始化以后，长度就确定了。
- 数组声明的类型，就决定了进行元素初始化时的类型



数组在存储数据方面的弊端：

1. 数组初始化以后，长度就不可变了，不便于扩展
2. 数组中提供的属性和方法少，不便于进行添加、删除、插入等操作，且效率不高。同时无法直接获取存储元素的个数
3. 数组存储的数据是有序的、可以重复的。存储数据的特点单一



Java 集合类可以用于存储数量不等的多个对象，还可用于保存具有映射关系的
关联数组。


# 集合框架概述


Java 集合可分为 Collection 和 Map 两种体系：

1. Collection接口：单列数据，定义了存取一组对象的方法的集合
   - List：元素有序、可重复的集合
   - Set：元素无序、不可重复的集合
2. Map接口：双列数据，保存具有映射关系“key-value对”的集合



# List接口概述


1. 鉴于Java中数组用来存储数据的局限性，我们通常使用List替代数组
2. List集合类中元素有序、且可重复，集合中的每个元素都有其对应的顺序索引。
3. List容器中的元素都对应一个整数型的序号记载其在容器中的位置，可以根据序号存取容器中的元素。
4. JDK API中List接口的实现类常用的有：ArrayList、LinkedList和Vector。



## ArrayList


1. ArrayList 是 List 接口的典型实现类、主要实现类
2. 本质上，ArrayList是对象引用的一个”变长”数组
3. ArrayList的JDK1.8之前与之后的实现区别？
   1. JDK1.7：ArrayList像饿汉式，直接创建一个初始容量为10的数组
   2. JDK1.8：ArrayList像懒汉式，一开始创建一个长度为0的数组，当添加第一个元素时再创建一个始容量为10的数组
4. Arrays.asList(…) 方法返回的 List 集合，既不是 ArrayList 实例，也不是Vector 实例。 Arrays.asList(…) 返回值是一个固定长度的 List 集合



**扩容机制**


如果添加到底层数组容量不够，则扩容。默认情况下，扩容为原来的容量的1.5倍，同时需要将原有数组中的数据复制到新的数组中。


## LinkedList


对于频繁的插入或删除元素的操作，建议使用LinkedList类，效率较高


LinkedList：双向链表，实现了List接口和Deque接口, 内部没有声明数组，而是定义了Node类型的first和last，用于记录首末元素。同时，定义内部类Node，作为LinkedList中保存数据的基本结构。Node除了保存数据，还定义了两个变量：


1. prev变量记录前一个元素的位置
2. next变量记录下一个元素的位置



```java
private static class Node&lt;E&gt; {
    E item;
    Node&lt;E&gt; next;
    Node&lt;E&gt; prev;
    Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) {
        this.item = element;
        this.next = next;
        this.prev = prev;
    }
}
```


## Vector


Vector 是一个古老的集合，JDK1.0就有了。大多数操作与ArrayList相同，区别之处在于Vector是线程安全的。
在各种list中，最好把ArrayList作为缺省选择。当插入、删除频繁时，使用LinkedList；Vector总是比ArrayList慢，所以尽量避免使用。


Vector每次扩容请求其大小的2倍空间


## ArrayList和LinkedList的区别


1. 二者都线程不安全，相对线程安全的Vector，执行效率高。
2. ArrayList是实现了基于动态数组的数据结构，LinkedList基于链表的数据结构。对于随机访问get和set，ArrayList觉得优于LinkedList，因为LinkedList要移动指针。
3. 对于新增和删除操作add(特指插入)和remove，LinkedList比较占优势，因为ArrayList要移动数据。



## ArrayList和Vector的区别


Vector和ArrayList几乎是完全相同的,唯一的区别在于Vector是同步类(synchronized)，属于强同步类。因此开销就比ArrayList要大，访问要慢。正常情况下,大多数的Java程序员使用ArrayList而不是Vector,因为同步完全可以由程序员自己来控制。Vector每次扩容请求其大小的2倍空间，而ArrayList是1.5倍。Vector还有一个子类Stack。


# Set 接口概述


1. Set接口是Collection的子接口，set接口没有提供额外的方法
2. Set 集合不允许包含相同的元素，如果试把两个相同的元素加入同一个Set 集合中，则添加操作失败。
3. Set 判断两个对象是否相同不是使用 == 运算符，而是根据 equals() 方法



## HashSet


1. HashSet 是 Set 接口的典型实现，大多数时候使用 Set 集合时都使用这个实现类。
2. HashSet 按 Hash 算法来存储集合中的元素，因此具有很好的存取、查找、删除性能。
3. HashSet 具有以下特点：
   1. 不能保证元素的排列顺序
   2. HashSet 不是线程安全的
   3. 集合元素可以是 null
4. HashSet 集合判断两个元素相等的标准：两个对象通过 hashCode() 方法比较相等，并且两个对象的 equals() 方法返回值也相等。
5. 对于存放在Set容器中的对象，对应的类一定要重写equals()和hashCode(Object obj)方法，以实现对象相等规则。即：“相等的对象必须具有相等的散列码”。
6. `HashSet`底层也是数组，初始容量为16，当如果使用率超过0.75（16*0.75=12）, 就会扩大容量为原来的2倍。（16扩容为32，依次为64,128....等）



### 添加元素的过程：


1. 当向 HashSet 集合中存入一个元素时，HashSet 会调用该对象的 `hashCode()` 方法来得到该对象的 hashCode 值，然后根据 hashCode 值，通过某种散列函数决定该对象在 HashSet 底层数组中的存储位置。（这个散列函数会与底层数组的长度相计算得到在数组中的下标，并且这种散列函数计算还尽可能保证能均匀存储元素，越是散列分布，该散列函数设计的越好）
   1. 如果两个元素的hashCode()值相等，会再继续调用equals方法，如果equals方法结果
      为true，添加失败；如果为false，那么会保存该元素，但是该数组的位置已经有元素了，
      那么会通过链表的方式继续链接。
   2. 如果它们的 hashCode() 返回值不相等，但两个元素的 equals() 方法返回 true，hashSet 将会把它们存储在不同的位置，但依然可以添加成功。



## LinkedHashSet


1. LinkedHashSet 是 HashSet 的子类
2. LinkedHashSet 根据元素的 hashCode 值来决定元素的存储位置，但它同时使用双向链表维护元素的次序，这使得元素看起来是以插入顺序保存的。
3. LinkedHashSet插入性能略低于 HashSet，但在迭代访问 Set 里的全部元素时有很好的性能。
4. LinkedHashSet 不允许集合元素重复。



## TreeSet


因为只有相同类的两个实例才会比较大小，所以向 TreeSet 中添加的应该是同一个类的对象


1. TreeSet 是 SortedSet 接口的实现类，TreeSet 可以确保集合元素处于排序状态。
2. TreeSet底层使用红黑树结构存储数据
3. TreeSet 两种排序方法：自然排序和定制排序。默认情况下，TreeSet 采用自然排序。



### 自然排序


**第一种排序方式：**
**

1. 自然排序：TreeSet 会调用集合元素的 `compareTo(Object obj)` 方法来比较元素之间的大小关系，然后将集合元素按升序(默认情况)排列
2. 如果试图把一个对象添加到 TreeSet 时，则该对象的类必须实现 `Comparable`接口。
   1. 实现 `Comparable`的类必须实现 `compareTo(Object obj)` 方法，两个对象即通过`compareTo(Object obj)`方法的返回值来比较大小。
3. Comparable 的典型实现：
   1. `BigDecimal`、`BigInteger` 以及所有的数值型对应的包装类：按它们对应的数值大小进行比较
   2. `Character`：按字符的 unicode值来进行比较
   3. `Boolean`：true 对应的包装类实例大于 false 对应的包装类实例
   4. `String`：按字符串中字符的 unicode 值进行比较
   5. `Date`、`Time`：后边的时间、日期比前面的时间、日期大



**第二种排序方式**


1. TreeSet 中添加元素时，只有第一个元素无须比较compareTo()方法，后面添加的所有元素都会调用compareTo()方法进行比较。
2. 因为只有相同类的两个实例才会比较大小，所以向 TreeSet 中添加的应该是同一个类的对象。
3. 对于 TreeSet 集合而言，它判断两个对象是否相等的唯一标准是：两个对象通过 compareTo(Object obj) 方法比较返回值。
4. 当需要把一个对象放入 TreeSet 中，重写该对象对应的 equals() 方法时，应保证该方法与 compareTo(Object obj) 方法有一致的结果：如果两个对象通过equals() 方法比较返回 true，则通过 compareTo(Object obj) 方法比较应返回 0。否则，让人难以理解。



### 定制排序


1. TreeSet的自然排序要求元素所属的类实现Comparable接口，如果元素所属的类没有实现Comparable接口，或不希望按照升序(默认情况)的方式排列元素或希望按照其它属性大小进行排序，则考虑使用定制排序。定制排序，通过Comparator接口来实现。需要重写compare(T o1,T o2)方法。
2. 利用int compare(T o1,T o2)方法，比较o1和o2的大小：如果方法返回正整数，则表示o1大于o2；如果返回0，表示相等；返回负整数，表示o1小于o2。
3. 要实现定制排序，需要将实现Comparator接口的实例作为形参传递给TreeSet的构造器。
4. 此时，仍然只能向TreeSet中添加类型相同的对象。否则发生ClassCastException异常。
5. 使用定制排序判断两个元素相等的标准是：通过Comparator比较两个元素返回了0。



# Map接口概述


1. Map与Collection并列存在。用于保存具有映射关系的数据:key-value
2. Map 中的 key 和 value 都可以是任何引用类型的数据
3. Map 中的 key 用Set来存放，不允许重复，即同一个 Map 对象所对应的类，须重写hashCode()和equals()方法
4. 常用String类作为Map的“键”
5. key 和 value 之间存在单向一对一关系，即通过指定的 key 总能找到唯一的、确定的 value
6. Map接口的常用实现类：`HashMap`、`TreeMap`、`LinkedHashMap`和`Properties`。其中，HashMap是 Map 接口使用频率最高的实现类



## HashMap


1. HashMap是 Map 接口使用频率最高的实现类。
2. 允许使用null键和null值，与HashSet一样，不保证映射的顺序。
3. 所有的key构成的集合是Set:无序的、不可重复的。所以，key所在的类要重写：equals()和hashCode()
4. 所有的value构成的集合是Collection:无序的、可以重复的。所以，value所在的类要重写：equals()
5. 一个key-value构成一个entry
6. 所有的entry构成的集合是Set:无序的、不可重复的
7. HashMap 判断两个 key 相等的标准是：两个 key 通过 equals() 方法返回 true，hashCode 值也相等。
8. HashMap 判断两个 value相等的标准是：两个 value 通过 equals() 方法返回 true。



### HashMap的存储结构


**JDK 7及以前版本：HashMap是数组+链表结构(即为链地址法)**


1. HashMap的内部存储结构其实是数组和链表的结合。当实例化一个HashMap时，系统会创建一个长度为Capacity的Entry数组，这个长度在哈希表中被称为容量(Capacity)，在这个数组中可以存放元素的位置我们称之为“桶”(bucket)，每个bucket都有自己的索引，系统可以根据索引快速的查找bucket中的元素。
2. 每个bucket中存储一个元素，即一个Entry对象，但每一个Entry对象可以带一个引用变量，用于指向下一个元素，因此，在一个桶中，就有可能生成一个Entry链。而且新添加的元素作为链表的head。
3. 添加元素的过程：
   向HashMap中添加entry1(key，value)，需要首先计算entry1中key的哈希值(根据key所在类的hashCode()计算得到)，此哈希值经过处理以后，得到在底层Entry[]数组中要存储的位置i。如果位置i上没有元素，则entry1直接添加成功。如果位置i上已经存在entry2(或还有链表存在的entry3，entry4)，则需要通过循环的方法，依次比较entry1中key和其他的entry。如果彼此hash值不同，则直接添加成功。如果hash值不同，继续比较二者是否equals。如果返回值为true，则使用entry1的value去替换equals为true的entry的value。如果遍历一遍以后，发现所有的equals返回都为false,则entry1仍可添加成功。entry1指向原有的entry元素。



**JDK 1.8之前HashMap的扩容**


当HashMap中的元素越来越多的时候，hash冲突的几率也就越来越高，因为数组的长度是固定的。所以为了提高查询的效率，就要对HashMap的数组进行扩容，而在HashMap数组扩容之后，最消耗性能的点就出现了：原数组中的数据必须重新计算其在新数组中的位置，并放进去，这就是resize。


那么HashMap什么时候进行扩容呢？
当HashMap中的元素个数超过数组大小(数组总大小length,不是数组中个数size)_loadFactor 时 ， 就 会 进 行 数 组 扩 容 ， loadFactor 的默认 值`(DEFAULT_LOAD_FACTOR)`为`0.75`，这是一个折中的取值。也就是说，默认情况，数组大小`(DEFAULT_INITIAL_CAPACITY)`为16，那么当HashMap中元素个数超过16_0.75=12（这个值就是代码中的threshold值，也叫做临界值）的时候，就把数组的大小扩展为 2*16=32，即扩大一倍，然后重新计算每个元素在数组中的位置，而这是一个非常消耗性能的操作，所以如果我们已经预知HashMap中元素的个数，那么预设元素的个数能够有效的提高HashMap的性能。


**JDK 8版本发布以后：HashMap是数组+链表+红黑树实现。**


1. HashMap的内部存储结构其实是数组+链表+树的结合。当实例化一个HashMap时，会初始化initialCapacity和loadFactor，在put第一对映射关系时，系统会创建一个长度为initialCapacity的Node数组，这个长度在哈希表中被称为容量(Capacity)，在这个数组中可以存放元素的位置我们称之为“桶”(bucket)，每个bucket都有自己的索引，系统可以根据索引快速的查找bucket中的元素。
2. 每个bucket中存储一个元素，即一个Node对象，但每一个Node对象可以带一个引用变量next，用于指向下一个元素，因此，在一个桶中，就有可能生成一个Node链。也可能是一个一个TreeNode对象，每一个TreeNode对象可以有两个叶子结点left和right，因此，在一个桶中，就有可能生成一个TreeNode树。而新添加的元素作为链表的last，或树的叶子结点。



### 那么 JDK1.8 HashMap什么时候进行扩容和树形化呢？


当HashMap中的元素个数超过数组大小(数组总大小length,不是数组中个数size)_loadFactor 时 ， 就会进行数组扩容 ， loadFactor 的默认 值(DEFAULT_LOAD_FACTOR)为0.75，这是一个折中的取值。也就是说，默认情况下，数组大小(DEFAULT_INITIAL_CAPACITY)为16，那么当HashMap中元素个数超过16_0.75=12（这个值就是代码中的threshold值，也叫做临界值）的时候，就把数组的大小扩展为 2*16=32，即扩大一倍，然后重新计算每个元素在数组中的位置，而这是一个非常消耗性能的操作，所以如果我们已经预知HashMap中元素的个数，那么预设元素的个数能够有效的提高HashMap的性能。当HashMap中的其中一个链的对象个数如果达到了8个，此时如果capacity没有达到64，那么HashMap会先扩容解决，如果已经达到了64，那么这个链会变成树，结点类型由Node变成TreeNode类型。当然，如果当映射关系被移除后，下次resize方法时判断树的结点个数低于6个，也会把树再转为链表。






### 负载因子值的大小，对HashMap有什么影响


1. 负载因子的大小决定了HashMap的数据密度。
2. 负载因子越大密度越大，发生碰撞的几率越高，数组中的链表越容易长,造成查询或插入时的比较次数增多，性能会下降。
3. 负载因子越小，就越容易触发扩容，数据密度也越小，意味着发生碰撞的几率越小，数组中的链表也就越短，查询和插入时比较的次数也越小，性能会更高。但是会浪费一定的内容空间。而且经常扩容也会影响性能，建议初始化预设大一点的空间。
4. 按照其他语言的参考及研究经验，会考虑将负载因子设置为0.7~0.75，此时平均检索长度接近于常数。



# LinkedHashMap


1. LinkedHashMap 是 HashMap 的子类
2. 在HashMap存储结构的基础上，使用了一对双向链表来记录添加元素的顺序
3. 与LinkedHashSet类似，LinkedHashMap 可以维护 Map 的迭代顺序：迭代顺序与 Key-Value 对的插入顺序一致



`HashMap`中的内部类：Node


```java
static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; {
    final int hash;
    final K key;
    V value;
    Node&lt;K,V&gt; next;
}
```


`LinkedHashMap`中的内部类：Entry


```java
static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; {
    Entry&lt;K,V&gt; before, after;
    Entry(int hash, K key, V value, Node&lt;K,V&gt; next) {
    	super(hash, key, value, next);
    }
}
```


# TreeMap


TreeMap 的所有的 Key 必须实现 Comparable 接口，而且所有的 Key 应该是同一个类的对象，否则将会抛出 ClasssCastException


1. TreeMap存储 Key-Value 对时，需要根据 key-value 对进行排序。TreeMap 可以保证所有的 Key-Value 对处于有序状态。
2. TreeSet底层使用红黑树结构存储数据
3. TreeMap 的 Key 的排序：
   1. 自然排序：TreeMap 的所有的 Key 必须实现 Comparable 接口，而且所有的 Key 应该是同一个类的对象，否则将会抛出 ClasssCastException
   2. 定制排序：创建 TreeMap 时，传入一个 Comparator 对象，该对象负责对TreeMap 中的所有 key 进行排序。此时不需要 Map 的 Key 实现Comparable 接口
   3. TreeMap判断两个key相等的标准：两个key通过compareTo()方法或者compare()方法返回0。



# Hashtable


1. Hashtable是个古老的 Map 实现类，JDK1.0就提供了。不同于HashMap，Hashtable是线程安全的。
2. Hashtable实现原理和HashMap相同，功能相同。底层都使用哈希表结构，查询速度快，很多情况下可以互用。
3. 与HashMap不同，Hashtable 不允许使用 null 作为 key 和 value
4. 与HashMap一样，Hashtable 也不能保证其中 Key-Value 对的顺序
5. Hashtable判断两个key相等、两个value相等的标准，与HashMap一致。



# Properties


1. Properties 类是 Hashtable 的子类，该对象用于处理属性文件
2. 由于属性文件里的 key、value 都是字符串类型，所以 Properties 里的 key 和 value 都是字符串类型
3. 存取数据时，建议使用setProperty(String key,String value)方法和getProperty(String key)方法



```java
//Properties:常用来处理配置文件。key和value都是String类型
public static void main(String[] args)  {
    FileInputStream fis = null;
    try {
        Properties pros = new Properties();

        fis = new FileInputStream("jdbc.properties");
        pros.load(fis);//加载流对应的文件

        String name = pros.getProperty("name");
        String password = pros.getProperty("password");

    } catch (IOException e) {
        e.printStackTrace();
    } finally {
        if(fis != null){
            try {
                fis.close();
            } catch (IOException e) {
                e.printStackTrace();
            }

        }
    }
```</content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15325005.html</id>
        <title type="text">RabbitMQ可靠消息投递-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-23T09:02:00Z</published>
        <updated>2021-09-23T09:02:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15325005.html" />
        <content type="text"># SpringBoot整合RabbitMQ


加入依赖
```xml
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;
&lt;/dependency&gt;
```

application.yml配置
```yaml
spring:
  rabbitmq:
    host: localhost
    port: 5672
    virtual-host: /
```


在配置类上加上注解@EnableRabbit开启RabbitMQ
```java
@EnableRabbit
@SpringBootApplication
public class RabbitmqApplication {

    public static void main(String[] args) {
        SpringApplication.run(RabbitmqTestApplication.class, args);
    }
}
```


创建消息队列（queue）、交换机（exchange）、绑定（binding）。


将交换机、队列和绑定装配到容器中，如果RabbitMQ中没有就会自动创建，但是修改交换机和队列的属性再重启项目，已经创建好的交换机和队列的属性不会改变。
```java
@Configuration
public class RabbitConfig {

    /**
     * 设置消息序列化为json格式传输
     *
     * @return
     */
    @Bean
    public MessageConverter messageConverter() {
        return new Jackson2JsonMessageConverter();
    }

    /**
     * 创建队列
     *
     * @return queue
     */
    @Bean
    public Queue userQueue() {
        /**
         * 创建队列的构造方法
         * Queue(String name, boolean durable, boolean exclusive, boolean autoDelete, @Nullable Map&lt;String, Object&gt; arguments)
         * name：队列的名字
         * durable：是否持久化
         * exclusive：是否排他
         * autoDelete：是否自动删除
         * arguments：自定义属性
         */
        Queue queue = new Queue("orange.user.queue", true, false, false, null);
        return queue;
    }

    /**
     * 创建交换机
     *
     * @return exchange
     */
    @Bean
    public Exchange userExChange() {

        /**
         * 创建主题交换机的构造方法
         * TopicExchange(String name, boolean durable, boolean autoDelete, Map&lt;String, Object&gt; arguments)
         * name：交换机的名字
         * durable：是否持久化
         * autoDelete：是否自动删除
         * arguments：自定义属性
         */
        return new TopicExchange("orange-user-exchange", true, false, null);
    }

    @Bean
    public Binding userBinding() {
        /**
         * 创建绑定的构造方法
         * Binding(String destination, Binding.DestinationType destinationType, String exchange, String routingKey, @Nullable Map&lt;String, Object&gt; arguments)
         * destination：目的地，就是队列的名字
         * destinationType：目的地类型
         * exchange：交换机名字
         * routingKey：路由键
         *
         */
        return new Binding("orange.user.queue", Binding.DestinationType.QUEUE, "orange-user-exchange", "orange.user", null);
    }
}

```


发送消息
使用 RabbitTemplate 发送消息，指定 exchange 和 routeKey
```java
    @Autowired
    private RabbitTemplate rabbitTemplate;

    @Override
    public void sendMQ(UserDTO userDTO) {
        //给mq发消息
         rabbitTemplate.convertAndSend("orange-user-exchange", "orange.user", userDTO);
    }
```


接收消息
监听消息常用两种方式

- 使用@RabbitListener 注解标注在方法上，注解属性queue是要监听的队列，是一个数组，可以监听多个队列。
- 使用@RabbitListener、@RabbitHandler，@RabbitListener标注在类上，@RabbitHandler标注在方法上，可以使用不同方法接收同一个队列中不同的消息。



方式一：使用@RabbitListener
```java
/**
 * RabbitListener(queues = {"orange.user.queue"})
 * 注解属性：queues 需要监听的队列，是一个数组，可以监听多个队列
 *
 * @param message 原生消息详细信息，包括消息头、消息体。
 * @param userDTO 发送的消息类型。
 * @param channel 当前传输数据的通道
 */
@RabbitListener(queues = {"orange.user.queue"})
public void consumerMassage(Message message, UserDTO userDTO, Channel channel) {
    log.info("收到消息：{}", userDTO);
}
```


方式二：使用@RabbitListener、@RabbitHandler
```java
@RabbitListener(queues = {"orange.user.queue"})
@Slf4j
@Service
public class MessageUserServiceImpl extends ServiceImpl&lt;MessageUserMapper, MessageUser&gt; implements MessageUserService {


    /**
     * 注解属性：queues 需要监听的队列，是一个数组，可以监听多个队列
     *
     * @param message 原生消息详细信息，包括消息头、消息体。
     * @param userDTO 发送的消息类型。
     * @param channel 当前传输数据的通道
     */
    @RabbitHandler
    public void userDTOMassage(Message message, UserDTO userDTO, Channel channel) {
        log.info("收到消息：{}", userDTO);
    }

    /**
     * @param user 发送的消息类型
     */
    @RabbitHandler
    public void userMessage(User user) {
        log.info("收到消息：{}", user);
    }
}
```




# RabbitMQ消息丢失问题


首先了解一下RabbitMQ的工作流程

1. 消息发送者把消息发送给RabbitMQ服务器Broker
1. 交换机（exchange）把消息按照指定的路由键（routeKey）发给相应的队列（queue）
1. 队列把消息发送给消息监听者



![](https://img2020.cnblogs.com/blog/1801000/202109/1801000-20210923170047141-1015180609.png)



**消息丢失问题**

**问题一：**消息没有到达RabbitMQ服务器
生产者把消息发给RabbitMQ的时候，可能由于网络或者其他原因，消息没有到达RabbitMQ服务器。
解决方法
方法一：开启事务机制。生产者发送消息之前开启RabbitMQ事务，如果消息没有成功被RabbitMQ收到，生产者就会收到异常信息。但是开启事务机制会使性能下降250倍。
方法二：发送方确认(publisher confirm)机制。消息到达服务器时触发回调方法

**问题二：**RabbitMQ收到消息后丢失了消息
RabbitMQ收到消息后，此时服务器突然挂掉，内存里的消息丢失。
解决方法：开启RabbitMQ持久化


**问题三：**消费者丢失消息
消费者收到消息后，还没执行完业务服务就挂掉。
解决方法：开启RabbitMQ手动ACK，确认消费消息。


## 发送方确认机制

消息抵达服务器确认 publisher-confirm-type: _correlated，该属性有三个取值_

- none：表示禁用发布确认模式，默认即此。
- correlated：表示成功发布消息到交换器后会触发的回调方法。
- simple：类似 correlated，并且支持 waitForConfirms() 和 waitForConfirmsOrDie() 方法的调用。

消息没有成功到达队列回调 publisher-returns: true
```yaml
spring:
  rabbitmq:
    host: localhost
    port: 5672
    virtual-host: /
    #消息抵达服务器确认
    publisher-confirm-type: correlated
    #消息没有到达队列确认
    publisher-returns: true
    template:
      #只要消息抵达队列，以异步优先回调 returns
      mandatory: true
```


定制RabbitTemplate，配置两个 Callback。
```java
@Slf4j
@Configuration
public class RabbitConfig {


    @Autowired
    private RabbitTemplate rabbitTemplate;

    /**
     * 定制 RabbitTemplate
     * &lt;p&gt;
     * PostConstruct ：RabbitConfig对象创建完成之后执行这个方法
     */
    @PostConstruct
    public void initRabbitTemplate() {

        /**
         * 设置消息到达服务器确认回调
         */
        rabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() {
            /**
             *
             * @param correlationData 当前消息的唯一关联数据（消息的唯一ID）
             * @param ack 交换机是否成功收到消息
             * @param cause 失败信息
             */
            @Override
            public void confirm(CorrelationData correlationData, boolean ack, String cause) {
                log.info("消息ID：{}，消息是否到达Broker：{}，失败信息：{}", correlationData, ack, cause);
            }
        });

        /**
         * 消息没有抵达队列的回调
         */
        rabbitTemplate.setReturnCallback(new RabbitTemplate.ReturnCallback() {
            /**
             * 消息没有投递给指定的队列，就会触发这个方法
             *
             * @param message 投递失败的消息详细信息
             * @param replyCode 回复的状态码
             * @param replyText 回复的文本内容
             * @param exchange 目标交换机
             * @param routingKey 使用的路由键
             */
            @Override
            public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) {
                log.info("失败消息的信息：{}，状态码：{}，文本内容：{}，目标交换机：{}，使用的路由键：{}", message, replyCode, replyText, exchange, routingKey);
            }
        });
    }

    /**
     * 设置消息序列化为json格式传输
     *
     * @return
     */
    @Bean
    public MessageConverter messageConverter() {
        return new Jackson2JsonMessageConverter();
    }
}
```


## 消费方确认机制


保证消息被正确消费，消息才从队列中删除。默认是自动确认的，只要消费端收到消息，服务端就会移除这个消息。


开启消费端手动ack确认
```yaml
spring:
  rabbitmq:
    host: localhost
    port: 5672
    virtual-host: /
    #消息抵达服务器确认
    publisher-confirm-type: correlated
    #消息没有到达队列确认
    publisher-returns: true
    template:
      #只要消息抵达队列，以异步优先回调 returns
      mandatory: true
    listener:
      simple:
        #开启消费端手动确认
        acknowledge-mode: manual
```


确认消费、拒绝消费


确认消费一个方法：
```java
/*
    deliveryTag：消息的头部属性信息，channel内按顺序自增
    multiple：是否批量确认
*/
void basicAck(long deliveryTag, boolean multiple)
```


拒绝消费的方法：
```java
/*
    deliveryTag：消息的头部属性信息，channel内按顺序自增
    multiple：是否批量拒绝
    requeue：拒绝后是否放入队列  true 从新发回服务器，false 丢弃消息
*/
void basicNack(long deliveryTag, boolean multiple, boolean requeue)

/*
    deliveryTag：消息的头部属性信息，channel内按顺序自增
    requeue：拒绝后是否放入队列  true 从新发回服务器，false 丢弃消息
*/
void basicReject(long deliveryTag, boolean requeue) throws IOException;
```


手动确认消费
```java
@RabbitHandler
public void userMessage(Message message, User user, Channel channel) {

    //消息头信息
    MessageProperties messageProperties = message.getMessageProperties();
    //channel内按顺序从1递增
    long deliveryTag = message.getMessageProperties().getDeliveryTag();
    log.info("收到消息：{}", user);
    try {
        //确认消费消息
        channel.basicAck(deliveryTag, false);
    } catch (IOException e) {
        e.printStackTrace();
    }

}
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15331319.html</id>
        <title type="text">MySQL Explain 详解-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-24T09:14:00Z</published>
        <updated>2021-09-24T09:14:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15331319.html" />
        <content type="text">explain能解释mysql如何处理SQL语句，表的加载顺序，表是如何连接，以及索引使用情况。是SQL优化的重要工具

在 SQL 语句前加 Explain 关键字就可以查看 SQL 的执行计划。

```sql
mysql&gt; explain select * from user;
+----+-------------+-------+------------+------+---------------+------+---------+------+---------+----------+-------+
| id | select_type | table | partitions | type | possible_keys | key  | key_len | ref  | rows    | filtered | Extra |
+----+-------------+-------+------------+------+---------------+------+---------+------+---------+----------+-------+
|  1 | SIMPLE      | user  | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 5302557 |   100.00 | NULL  |
+----+-------------+-------+------------+------+---------------+------+---------+------+---------+----------+-------+
1 row in set, 1 warning (0.00 sec)
```



各字段的含义：

| 字段         | 含义                                                         |
| ------------ | ------------------------------------------------------------ |
| id           | select查询的序号，一组数字，表示执行的select查询或操作表的顺序 |
| select_type  | 标识select的类型，常见的值有：`SIMPLE`(简单查询，不使用连接或子查询)、`PRIMARY`(主查询，外层的查询)、`UNION`(UNION中的第二个或者后面的查询语句)、`SUBQUERY`(子查询中的第一个select)等 |
| table        | 查询的表                                                     |
| type         | 表的连接类型，性能由高到低：`system`&gt;`const`&gt;`eq_ref`&gt;`ref`&gt;`ref_or_null`&gt;`index_merge`&gt;`index_subquery`&gt;`range`&gt;`index`&gt;`all` |
| possible_key | 查询时可能用到的索引                                         |
| key          | 用到的索引                                                   |
| key_len      | 索引字段的长度                                               |
| rows         | 估计值，查询扫描的行数                                       |
| extra        | 额外的信息                                                   |



## id

SELECT识别符。这是SELECT查询序列号。查询序号即为sql语句执行的顺序。

1. id相同，执行顺序从上之下
2. id不同，执行顺序从大到小
3. id有相同的和不同的，遵守1、2规则



## select_type

| select_type  | 含义                                                         |
| ------------ | ------------------------------------------------------------ |
| SIMPLE       | 简单的select查询，查询中不包含子查询或者UNION                |
| PRIMARY      | 若包含复杂的子查询，最外层查询标记为PRIMARY                  |
| SUBQUERY     | 在select或where列表中包含子查询                              |
| DERIVED      | 在from列表中包含的子查询，被标记为DERIVED(衍生)，临时表      |
| UNION        | 若在第二个select出现在union之后，则被标记为union；若union包含在from子句的子查询中，外层select被标记为DERIVED |
| UNION RESULT | 从union结果中获取结果的select                                |



## table

表示查询涉及的表或衍生表



## type

`type`  字段比较重要, 它提供了判断查询是否高效的重要依据依据. 通过 `type` 字段, 我们判断此次查询是 `全表扫描` 还是 `索引扫描` 等.

type 常用的取值有：

| type   | 含义                                                         |
| ------ | ------------------------------------------------------------ |
| system | 表中只有一条数据. 这个类型是特殊的 `const` 类型.             |
| const  | 针对主键或唯一索引的等值查询扫描, 最多只返回一行数据. const 查询速度非常快, 因为它仅仅读取一次即可。 |
| eq_ref | 此类型通常出现在多表的 join 查询, 表示对于前表的每一个结果, 都只能匹配到后表的一行结果。&lt;br/&gt;并且查询的比较操作通常是 `=`, 查询效率较高。 |
| ref    | 此类型通常出现在多表的 join 查询, 针对于非唯一或非主键索引, 或者是使用了 `最左前缀` 规则索引的查询。 |
| range  | 表示使用索引范围查询, 通过索引字段范围获取表中部分数据记录. 这个类型通常出现在 =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN, IN() 操作中. |
| index  | 表示全索引扫描                                               |
| ALL    | 表示全表扫描, 这个类型的查询是性能最差的查询之一             |



性能由高到低：`system`&gt;`const`&gt;`eq_ref`&gt;`ref`&gt;`ref_or_null`&gt;`index_merge`&gt;`index_subquery`&gt;`range`&gt;`index`&gt;`all`



## possible_keys

`possible_keys` 表示 MySQL 在查询时, 能够使用到的索引. 注意, 即使有些索引在 `possible_keys` 中出现, 但是并不表示此索引会真正地被 MySQL 使用到. MySQL 在查询时具体使用了哪些索引, 由 `key` 字段决定.



## key

此字段是 MySQL 在当前查询时所真正使用到的索引.



## key_len

表示查询优化器使用了索引的字节数. 这个字段可以评估组合索引是否完全被使用, 或只有最左部分字段被使用到.
key_len 的计算规则如下:

字段的NULL 属性 占用1个字节， 如果一个字段是 NOT NULL 的，则没有此属性。

不定长字符串 varchar 需要1个字节来保存字符串的长度，

字符串字节长度还和字符编码有关系，gbk下一个字符占2个字节，utf8下一个字符占3个字节，utf8mb4下一个字符占4字节

字符串

- char(n) null： utf8下字节长度：`n*3+1`；utf8mb4下字节长度：`n*4+1`
- char(n) not null： utf8下字节长度：`n*3`；utf8mb4下字节长度：`n*4`
- varchar(n) null：utf8下字节长度：`n*3+1+1`；utf8mb4下字节长度：`n*4+1+1`
- varchar(n) not null：utf8下字节长度：`n*3+1`；utf8mb4下字节长度：`n*4+1`

数值类型:

- TINYINT: 1字节
- SMALLINT: 2字节
- MEDIUMINT: 3字节
- INT: 4字节
- BIGINT: 8字节

时间类型
- DATE: 3字节
- TIMESTAMP: 4字节
- DATETIME: 8字节





## rows

rows 也是一个重要的字段. MySQL 查询优化器根据统计信息, 估算 SQL 要查找到结果集需要扫描读取的数据行数.
这个值非常直观显示 SQL 的效率好坏, 原则上 rows 越少越好.



## Extra

EXplain 中的很多额外的信息会在 Extra 字段显示, 常见的有以下几种内容:

| select_type     | 含义                                                         |
| --------------- | ------------------------------------------------------------ |
| Using filesort  | 表示 MySQL 需额外的排序操作, 不能通过索引顺序达到排序效果. 一般有 `Using filesort`, 都建议优化去掉, 因为这样的查询 CPU 资源消耗大. |
| Using temporary | 查询有使用临时表保存中间结果, MySQL在对查询结果排序的时候使用临时表，一般出现于order by和group by，查询效率不高, 建议优化 |
| Using index     | 覆盖索引扫描, 表示查询在索引树中就可查找所需数据, 不用扫描表数据文件，性能不错 |
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15331661.html</id>
        <title type="text">分页查询SQL优化-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-24T10:25:00Z</published>
        <updated>2021-09-24T10:25:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15331661.html" />
        <content type="text">MySQL的分页查询语句为：
```SQL
select table from column limit start pageSize; ``` `start`：偏移量 `currentPage`：当前页 `PageSize`：每页记录数 分页查询的公式：start=(currentPage-1)PageSize
```sql
select colum... from tableName limit (currentPage-1)pageSize PageSize ``` 当表中的数据量很大，分页查询后面的记录，速度就会特别慢，因为MySQL需要排序查询前面的记录，直到查询到需要的那一页，然后丢弃前面的记录，返回需要的那一页数据，查询排序的速度很慢 优化一：如果表中的id是连续自增的，根据查询的页数和查询的记录数可以算出查询的id的范围 比如说要查询第10页，查20条。id=(currentPage-1)pageSize=(10-1)*20+1=180
```sql
SELECT * FROM `user` WHERE `id`  between 180 and 20;
#或
select * from `user` where id &gt; 180 limit 20;
```


优化二：如果表中的id不是自增，在主键上完成排序分页操作，然后根据主键关联查询其他列数据
```sql
SELECT * FROM user a , (SELECT id FROM user ORDER BY id LIMIT 2000000 ,10) b WHERE a.id=b.id;
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15331784.html</id>
        <title type="text">Spring Boot 2.0 学习-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-24T10:47:00Z</published>
        <updated>2021-09-24T10:47:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15331784.html" />
        <content type="text"># Hello World
创建maven项目， 在pom.xml中添加依赖
```xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;version&gt;2.3.9.RELEASE&lt;/version&gt;
        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;
    &lt;/parent&gt;

    &lt;groupId&gt;com.orange&lt;/groupId&gt;
    &lt;artifactId&gt;springboot2.0&lt;/artifactId&gt;
    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
    &lt;name&gt;springboot2.0&lt;/name&gt;

    &lt;properties&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
    &lt;/properties&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;

&lt;/project&gt;
```
编写主程序`com.orange.boot2.Application`
```java
@SpringBootApplication
public class Application {

    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
    }

}
```
编写示例`com.orange.boot2.controller.Hello`
```java
@RestController
public class Hello {

    @RequestMapping("/hello")
    public String hello() {
        return "Hello World!";
    }
}
```
运行主程序启动示例，打开浏览器访问 http://localhost:8080/hello
# 组件添加
## @Configuration
`@configuration`注解标注的类是一个配置类，同时也是一个组件。配置类相当于一个配置文件
SpringBoot2.0之后该注解多了个布尔类型的属性`proxyBeanMethods`，默认值为true。默认情况下spring会检查配置类中方法返回的组件在容器中有没有，没有就创建。当`proxyBeanMethods`的值为false时，spring不会检查配置类中方法返回的实例是否存在容器中，主要为了提升性能。
```java
@Configuration(proxyBeanMethods = false)
public class MyConfig {

}
```

## @Bean
`@Bean`注解是给容器中添加一个组件，在配置类中使用`@Bean`注册的组件默认是单实例的
```java
@Configuration
public class MyConfig {

    @Bean
    public User user() {
        return new User();
    }

}
```

## @Import
该注解的作用是导入一些特殊的Bean，一般为配置类，Spring中的配置一般都是自动导入的，通常用来导入第三方jar包中的配置类。
```java
@Import({OuterConfig.class})
public class MyConfig {

    @Bean
    public User user() {
        User user = new User();
        user.setName("name");
        return user;
    }
```
外部配置（第三方配置）
```java
@Configuration
public class OuterConfig {

    @Bean
    public Person person() {
        return new Person();
    }
}
```

## @Conditional
条件装配，满足@Conditional指定的条件才装配组件
![](https://img2020.cnblogs.com/blog/1801000/202109/1801000-20210924184114426-1388836036.png)


## @ImportResource
导入资源文件
```java
@Configuration(proxyBeanMethods = true)
@ImportResource("classpath:bean.xml")
public class MyConfig {

    @Bean
    public User user() {
        return user;
    }

}
```


# 配置绑定
## @ConfigurationProperties
使用`@ConfigurationProperties`读取前缀为person的属性值， 并用`@Component`注解装配到容器中，使用的时候`@AutoWired`注入

application.yml
```yaml
person:
  name: cyan-orange
  age: 25
```
```java
@Component
@ConfigurationProperties(prefix = "person")
public class Person {
    private String name;
    private Integer age;

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public Integer getAge() {
        return age;
    }

    public void setAge(Integer age) {
        this.age = age;
    }
}
```


## @EnableConfigurationProperties+@ConfigurationProperties
@EnableConfigurationProperties注解标注在配置类上，会自动将组件注册到容器中，因此并不需要在组件上使用@Component注解
```java
@ConfigurationProperties(prefix = "person")
public class Person {
    private String name;
    private Integer age;

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name;
    }

    public Integer getAge() {
        return age;
    }

    public void setAge(Integer age) {
        this.age = age;
    }
}
```
配置类
```java
@EnableConfigurationProperties(Person.class)
@Configuration(proxyBeanMethods = true)
public class MyConfig {

}
```


# 自动配置
## @SpringBootApplication
```java
@SpringBootConfiguration
@EnableAutoConfiguration
@ComponentScan(
    excludeFilters = {@Filter(
    type = FilterType.CUSTOM,
    classes = {TypeExcludeFilter.class}
), @Filter(
    type = FilterType.CUSTOM,
    classes = {AutoConfigurationExcludeFilter.class}
)}
)
public @interface SpringBootApplication {
```
`@SpringBootApplication`是一个复合注解，主要包含`@SpringBootConfiguration`和`@EnableAutoConfiguration`两个 注解。


## @SpringBootConfiguration
`@SpringBootConfiguration`这个注解标识当前是一个配置类


## @EnableAutoConfiguration
```java
@AutoConfigurationPackage
@Import({AutoConfigurationImportSelector.class})
public @interface EnableAutoConfiguration {
```
`@EnableAutoConfiguration`注解主要包含`@AutoConfigurationPackage`和`@Import`


### @AutoConfigurationPackage
```java
@Import({Registrar.class})
public @interface AutoConfigurationPackage {
```
`@AutoConfigurationPackage`包含`@Import`注解，会获取主类所在的包名，然后将包下的所有组件导入到容器中


### @Import({AutoConfigurationImportSelector.class})
`@Import({AutoConfigurationImportSelector.class})`是导入`AutoConfigurationImportSelector`类，默认扫描当前系统的所有`META-INF/spring.factories`位置的文件，文件里写了SpringBoot启动时要加载的所有配置类，当SpringBoot启动时就将这些配置类全部加载，然后按照条件装配。

# 配置文件YAML

- key: value；kv之间有空格
- 大小写敏感
- 使用缩进表示层级关系
- 缩进不允许使用tab，只允许空格
- 缩进的空格数不重要，只要相同层级的元素左对齐即可
- '#'表示注释
- 字符串无需加引号，如果要加，''与""表示字符串内容 会被 转义/不转义



yaml配置示例，java类
```java
@Data
public class Person {

    private String userName;
    private Boolean boss;
    private Date birth;
    private Integer age;
    private Pet pet;
    private String[] interests;
    private List&lt;String&gt; animal;
    private Map&lt;String, Object&gt; score;
    private Set&lt;Double&gt; salarys;
    private Map&lt;String, List&lt;Pet&gt;&gt; allPets;
}

@Data
public class Pet {
    private String name;
    private Double weight;
}
```
yaml文件
```yaml
person:
  userName: zhangsan
  boss: false
  birth: 2019/12/12 20:12:33
  age: 18
  pet:
    name: tomcat
    weight: 23.4
  interests: [篮球,游泳]
  animal:
    - jerry
    - mario
  score:
    english:
      first: 30
      second: 40
      third: 50
    math: [131,140,148]
    chinese: {first: 128,second: 136}
  salarys: [3999,4999.98,5999.99]
  allPets:
    sick:
      - {name: tom}
      - {name: jerry,weight: 47}
    health: [{name: mario,weight: 47}]
```


## 配置提示
自定义的类和配置文件绑定一般没有提示，需要加上依赖spring-boot-configuration-processor
```xml
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;
    &lt;optional&gt;true&lt;/optional&gt;
&lt;/dependency&gt;
```
打包的时候再将依赖spring-boot-configuration-processor去掉，在maven插件中配置
```xml
&lt;project&gt;
    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;excludes&gt;
                        &lt;exclude&gt;
                            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                            &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;
                        &lt;/exclude&gt;
                    &lt;/excludes&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;
```


# web开发
## 静态资源
默认情况下，Spring Boot将静态资源放在类路径下：`/static` 、`/public`、`/resources`、`/META-INF/resources`，访问时使用项目名加静态资源名。


原理：请求来时先去找controller，如果controller不能处理，就交给静态资源处理器来处理，如果还是不能处理则返回404

可以通过配置来改变静态资源的位置，比如说放在类路径下的dist目录中
```yaml
spring:
  resources:
    static-locations: classpath:/dist
```


静态资源访问前缀：默认没有前缀，通过配置来添加前缀。
```yaml
spring:
  mvc:
    static-path-pattern: /resources/**
```


## 欢迎页

- 静态资源路径下  index.html
   - 可以配置静态资源路径
   - 但是不可以配置静态资源的访问前缀。否则导致index.html不能被默认访问



## favicon
favicon.ico 放在静态资源目录下即可。资源访问前缀也会导致favicon失效


## 请求处理
### Rest风格
SpringBoot支持Rest风格，但是需要手动开启，这种方式只适用于页面表单请求，前后端分离不需要配置。
```yaml
spring:
  mvc:
    hiddenmethod:
      filter:
        enabled: true
```
核心Filter是`HiddenHttpMethodFilter`，发送delete和put请求的时候需要在表单隐藏域中添加 _method=put（delete）


### 请求映射
SpringMVC功能分析都从 org.springframework.web.servlet.DispatcherServlet-&gt;doDispatch()

 ![](https://img2020.cnblogs.com/blog/1801000/202109/1801000-20210924184241806-1754528361.png)


```java
protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception {
        HttpServletRequest processedRequest = request;
        HandlerExecutionChain mappedHandler = null;
        boolean multipartRequestParsed = false;

        WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);

        try {
            ModelAndView mv = null;
            Exception dispatchException = null;

            try {
                processedRequest = checkMultipart(request);
                multipartRequestParsed = (processedRequest != request);

                // 找到当前请求使用哪个Handler（Controller的方法）处理
                mappedHandler = getHandler(processedRequest);
```
默认有五个HandlerMapping

 ![](https://img2020.cnblogs.com/blog/1801000/202109/1801000-20210924184308535-1911556344.png)


`RequestMappingHandlerMapping`：保存了所有@RequestMapping 和handler的映射规则。

 ![](https://img2020.cnblogs.com/blog/1801000/202109/1801000-20210924184325390-628428030.png)


所有的请求映射都在HandlerMapping中。

- SpringBoot自动配置欢迎页的 WelcomePageHandlerMapping 。访问 /能访问到index.html；
- SpringBoot自动配置了默认 的 RequestMappingHandlerMapping
- 请求进来，挨个尝试所有的HandlerMapping看是否有请求信息。
   - 如果有就找到这个请求对应的handler
   - 如果没有就是下一个 HandlerMapping



## 参数处理
### 注解：
@PathVariable、@RequestHeader、@ModelAttribute、@RequestParam、@MatrixVariable、@CookieValue、@RequestBody
```java
@RestController
public class ParameterTestController {


    //  car/2/owner/zhangsan
    @GetMapping("/car/{id}/owner/{username}")
    public Map&lt;String,Object&gt; getCar(@PathVariable("id") Integer id,
                                     @PathVariable("username") String name,
                                     @PathVariable Map&lt;String,String&gt; pv,
                                     @RequestHeader("User-Agent") String userAgent,
                                     @RequestHeader Map&lt;String,String&gt; header,
                                     @RequestParam("age") Integer age,
                                     @RequestParam("inters") List&lt;String&gt; inters,
                                     @RequestParam Map&lt;String,String&gt; params,
                                     @CookieValue("_ga") String _ga,
                                     @CookieValue("_ga") Cookie cookie){


        Map&lt;String,Object&gt; map = new HashMap&lt;&gt;();

//        map.put("id",id);
//        map.put("name",name);
//        map.put("pv",pv);
//        map.put("userAgent",userAgent);
//        map.put("headers",header);
        map.put("age",age);
        map.put("inters",inters);
        map.put("params",params);
        map.put("_ga",_ga);
        System.out.println(cookie.getName()+"===&gt;"+cookie.getValue());
        return map;
    }


    @PostMapping("/save")
    public Map postMethod(@RequestBody String content){
        Map&lt;String,Object&gt; map = new HashMap&lt;&gt;();
        map.put("content",content);
        return map;
    }


    //1、语法： 请求路径：/cars/sell;low=34;brand=byd,audi,yd
    //2、SpringBoot默认是禁用了矩阵变量的功能
    //      手动开启：原理。对于路径的处理。UrlPathHelper进行解析。
    //              removeSemicolonContent（移除分号内容）支持矩阵变量的
    //3、矩阵变量必须有url路径变量才能被解析
    @GetMapping("/cars/{path}")
    public Map carsSell(@MatrixVariable("low") Integer low,
                        @MatrixVariable("brand") List&lt;String&gt; brand,
                        @PathVariable("path") String path){
        Map&lt;String,Object&gt; map = new HashMap&lt;&gt;();

        map.put("low",low);
        map.put("brand",brand);
        map.put("path",path);
        return map;
    }

    // /boss/1;age=20/2;age=10

    @GetMapping("/boss/{bossId}/{empId}")
    public Map boss(@MatrixVariable(value = "age",pathVar = "bossId") Integer bossAge,
                    @MatrixVariable(value = "age",pathVar = "empId") Integer empAge){
        Map&lt;String,Object&gt; map = new HashMap&lt;&gt;();

        map.put("bossAge",bossAge);
        map.put("empAge",empAge);
        return map;

    }

}
```
### Servlet API：
WebRequest、ServletRequest、MultipartRequest、 HttpSession、javax.servlet.http.PushBuilder、Principal、InputStream、Reader、HttpMethod、Locale、TimeZone、ZoneId

**ServletRequestMethodArgumentResolver  以上的部分参数**
```java
@Override
	public boolean supportsParameter(MethodParameter parameter) {
		Class&lt;?&gt; paramType = parameter.getParameterType();
		return (WebRequest.class.isAssignableFrom(paramType) ||
				ServletRequest.class.isAssignableFrom(paramType) ||
				MultipartRequest.class.isAssignableFrom(paramType) ||
				HttpSession.class.isAssignableFrom(paramType) ||
				(pushBuilder != null &amp;&amp; pushBuilder.isAssignableFrom(paramType)) ||
				Principal.class.isAssignableFrom(paramType) ||
				InputStream.class.isAssignableFrom(paramType) ||
				Reader.class.isAssignableFrom(paramType) ||
				HttpMethod.class == paramType ||
				Locale.class == paramType ||
				TimeZone.class == paramType ||
				ZoneId.class == paramType);
	}
```


# 拦截器
拦截器需要实现**HandlerInterceptor**接口。 例如：写一个登录检查
```java
/**
 * 登录检查
 * 1、配置好拦截器要拦截哪些请求
 * 2、把这些配置放在容器中
 */
@Slf4j
public class LoginInterceptor implements HandlerInterceptor {

    /**
     * 目标方法执行之前
     * @param request
     * @param response
     * @param handler
     * @return
     * @throws Exception
     */
    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {

        String requestURI = request.getRequestURI();
        log.info("preHandle拦截的请求路径是{}",requestURI);

        //登录检查逻辑
        HttpSession session = request.getSession();

        Object loginUser = session.getAttribute("loginUser");

        if(loginUser != null){
            //放行
            return true;
        }

        //拦截住。未登录。跳转到登录页
        request.setAttribute("msg","请先登录");
//        re.sendRedirect("/");
        request.getRequestDispatcher("/").forward(request,response);
        return false;
    }

    /**
     * 目标方法执行完成以后
     * @param request
     * @param response
     * @param handler
     * @param modelAndView
     * @throws Exception
     */
    @Override
    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception {
        log.info("postHandle执行{}",modelAndView);
    }

    /**
     * 页面渲染以后
     * @param request
     * @param response
     * @param handler
     * @param ex
     * @throws Exception
     */
    @Override
    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception {
        log.info("afterCompletion执行异常{}",ex);
    }
}
```
配置拦截器
```java
/**
 * 1、编写一个拦截器实现HandlerInterceptor接口
 * 2、拦截器注册到容器中（实现WebMvcConfigurer的addInterceptors）
 * 3、指定拦截规则【如果是拦截所有，静态资源也会被拦截】
 */
@Configuration
public class AdminWebConfig implements WebMvcConfigurer {

    @Override
    public void addInterceptors(InterceptorRegistry registry) {
        registry.addInterceptor(new LoginInterceptor())
                .addPathPatterns("/**")  //所有请求都被拦截包括静态资源
                .excludePathPatterns("/","/login","/css/**","/fonts/**","/images/**","/js/**"); //放行的请求
    }
}
```
## 拦截器原理
1. 根据当前请求，找到 **HandlerExecutionChain** 可以处理请求的handler以及handler的所有 拦截器
2. 先来 **顺序执行**  所有拦截器的 preHandle方法
   1. 如果当前拦截器prehandler返回为true。则执行下一个拦截器的preHandle
   2. 如果当前拦截器返回为false。直接    倒序执行所有已经执行了的拦截器的  afterCompletion

3. 如果任何一个拦截器返回false。直接跳出不执行目标方法
4. 所有拦截器都返回True。执行目标方法
5. 倒序执行所有拦截器的postHandle方法。
6. 前面的步骤有任何异常都会直接倒序触发 afterCompletion
7. 页面成功渲染完成以后，也会倒序触发 afterCompletion

 ![](https://img2020.cnblogs.com/blog/1801000/202109/1801000-20210924184406980-559440127.png)



# 全局异常处理
执行Controller方法出现异常时触发
```java
@RestControllerAdvice
public class GlobalExceptionHandler {

    @ExceptionHandler(value = Exception.class)
    public String exceptionHandler(Exception e) {
        e.printStackTrace();
        return "系统错误:" + e.getMessage();
    }
}
```


# 指标监控
## SpringBoot Actuator
未来每一个微服务在云上部署以后，我们都需要对其进行监控、追踪、审计、控制等。SpringBoot就抽取了Actuator场景，使得我们每个微服务快速引用即可获得生产级别的应用监控、审计等功能。
```xml
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;
&lt;/dependency&gt;
```
配置
```yaml
management:
  endpoints:
    enabled-by-default: true #暴露所有端点信息
    web:
      exposure:
        include: '*'  #以web方式暴露
```
测试：
[http://localhost:8080/actuator](http://localhost:8080/actuator)

## Actuator Endpoint
最常用的Endpoint

- **Health：监控状况**
- **Metrics：运行时指标**
- **Loggers：日志记录**



### Health Endpoint
健康检查端点，我们一般用于在云平台，平台会定时的检查应用的健康状况，我们就需要Health Endpoint可以为平台返回当前应用的一系列组件健康状况的集合。
重要的几点：

- health endpoint返回的结果，应该是一系列健康检查后的一个汇总报告
- 很多的健康检查默认已经自动配置好了，比如：数据库、redis等
- 可以很容易的添加自定义的健康检查机制



配置显示详细信息
```yaml
management:
  endpoint:
    health:
      show-details: always
```
测试：[http://localhost:8080/actuator/health](http://localhost:8080/actuator/health)


### Metrics Endpoint
提供详细的、层级的、空间指标信息，这些信息可以被pull（主动推送）或者push（被动获取）方式得到；

- 通过Metrics对接多种监控系统
- 简化核心Metrics开发
- 添加自定义Metrics或者扩展已有Metrics



##  可视化监控
[https://github.com/codecentric/spring-boot-admin](https://github.com/codecentric/spring-boot-admin)


# Profile
为了方便多环境适配，springboot简化了profile功能。

- 默认配置文件  application.yaml；任何时候都会加载
- 指定环境配置文件  application-{env}.yaml
- 激活指定环境
   - 配置文件激活
   - 命令行激活：java -jar xxx.jar --**spring.profiles.active=prod --person.name=haha**
      - **修改配置文件的任意值，命令行优先**
- 默认配置与环境配置同时生效
- 同名配置项，profile配置优先



## 配置文件查找位置

1. classpath 根路径
1. classpath 根路径下config目录
1. jar包当前目录
1. jar包当前目录的config目录
1. /config子目录的直接子目录



## 配置文件加载顺序

1. 当前jar包内部的application.properties和application.yml
1. 当前jar包内部的application-{profile}.properties 和 application-{profile}.yml
1. 引用的外部jar包的application.properties和application.yml
1. 引用的外部jar包的application-{profile}.properties 和 application-{profile}.yml



# 自定义starter
自定义starter分为两个部分，分别是**启动器**和**配置包，**启动器依赖配置包。


启动器：**hello-spring-boot-starter**，只包含配置包，不写代码
pom.xml
```xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;

    &lt;groupId&gt;org.orange&lt;/groupId&gt;
    &lt;artifactId&gt;hello-spring-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;

    &lt;properties&gt;
        &lt;maven.compiler.source&gt;8&lt;/maven.compiler.source&gt;
        &lt;maven.compiler.target&gt;8&lt;/maven.compiler.target&gt;
    &lt;/properties&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.orange&lt;/groupId&gt;
            &lt;artifactId&gt;hello-spring-boot-starter-autoconfigure&lt;/artifactId&gt;
            &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

&lt;/project&gt;
```
配置包：**hello-spring-boot-starter-autoconfigure**，配置包有配置类、配置属性类、`META-INF/spring.factories`和业务代码
pom.xml
```xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;version&gt;2.3.9.RELEASE&lt;/version&gt;
        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;
    &lt;/parent&gt;
    &lt;groupId&gt;com.orange&lt;/groupId&gt;
    &lt;artifactId&gt;hello-spring-boot-starter-autoconfigure&lt;/artifactId&gt;
    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;

    &lt;properties&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
    &lt;/properties&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;
        &lt;/dependency&gt;

    &lt;/dependencies&gt;

&lt;/project&gt;

```
配置类：**HelloServiceAutoConfiguration**
```java
@Configuration
@EnableConfigurationProperties({HelloProperties.class})
public class HelloServiceAutoConfiguration {

    @Bean
    @ConditionalOnMissingBean({HelloService.class})
    public HelloService helloService() {
        HelloService helloService = new HelloService();
        return helloService;
    }
}
```
配置属性类：**HelloProperties**
```java
@ConfigurationProperties(prefix = "orange.hello")
public class HelloProperties {
    private String name;

    public String getName() {
        return name;
    }

    public void setName(String name) {
        this.name = name; } } ``` **META-INF/spring.factories文件** ```java org.springframework.boot.autoconfigure.EnableAutoConfiguration=\
com.orange.hello.auto.HelloServiceAutoConfiguration
```
业务类：**HelloService**
```java
@Service
public class HelloService {

    @Autowired
    private HelloProperties helloProperties;

    public String sayHello() {
        return "hello:" + helloProperties.getName();
    }
}
```
测试 ， 新建项目，引入自定义的starter，注入HelloService，在配置文件中配置`orange.hello.name`
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15331818.html</id>
        <title type="text">SpringBoot返回json数据的时间格式-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-24T11:00:00Z</published>
        <updated>2021-09-24T11:00:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15331818.html" />
        <content type="text">默认情况下spring boot返回的json时间格式带有时区, 并且是世界标准时间 , 和我们的时间差了八个小时

在`application.yml`中设置
```yaml
spring:
  jackson:
    date-format: yyyy-MM-dd HH:mm:ss
    time-zone: GMT+8
```</content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15331856.html</id>
        <title type="text">分布式事务和解决方案-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-24T11:16:00Z</published>
        <updated>2021-09-24T11:16:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15331856.html" />
        <content type="text"># 事务的基本性质
数据库事务的几个特性：原子性（Atomicity）、一致性（Consistency）、隔离性或独立性（Isolation）和持久性（Durability），简称ACID。

- 原子性：一系列操作整体不可拆分，要么同时成功，要么同时失败。
- 一致性：在事务完成时，数据都保持一致状态。
- 隔离性：指一个事务的执行不能被其他事务干扰，即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。
- 永久性：指一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的。



# 事务的并发问题
在实际应用中，数据库中的数据是要被多个用户共同访问的，在多个用户同时操作相同的数据时，可能就会出现一些事务的并发问题，具体如下。

**脏读**
指一个事务读取到另一个事务未提交的数据。
**不可重复读**
指一个事务对同一行数据重复读取两次，但得到的结果不同。
**虚读/幻读**
指一个事务执行两次查询，但第二次查询的结果包含了第一次查询中未出现的数据。
**丢失更新**
指两个事务同时更新一行数据，后提交（或撤销）的事务将之前事务提交的数据覆盖了。

丢失更新可分为两类，分别是第一类丢失更新和第二类丢失更新。

- 第一类丢失更新是指两个事务同时操作同一个数据时，当第一个事务撤销时，把已经提交的第二个事务的更新数据覆盖了，第二个事务就造成了数据丢失。
- 第二类丢失更新是指当两个事务同时操作同一个数据时，第一个事务将修改结果成功提交后，对第二个事务已经提交的修改结果进行了覆盖，对第二个事务造成了数据丢失。



# 事务的隔离级别
为了避免事务并发问题的出现，在标准的 SQL 规范中定义了四种事务隔离级别，不同的隔离级别对事务的处理有所不同。这四种事务的隔离级别如下。

**Read Uncommitted（读未提交）**
一个事务在执行过程中，既可以访问其他事务未提交的新插入的数据，又可以访问未提交的修改数据。如果一个事务已经开始写数据，则另外一个事务不允许同时进行写操作，但允许其他事务读此行数据。此隔离级别可防止丢失更新。

**Read Committed（读已提交）**
一个事务在执行过程中，既可以访问其他事务成功提交的新插入的数据，又可以访问成功修改的数据。读取数据的事务允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行。此隔离级别可有效防止脏读。

**Repeatable Read（可重复读取）**
一个事务在执行过程中，可以访问其他事务成功提交的新插入的数据，但不可以访问成功修改的数据。读取数据的事务将会禁止写事务（但允许读事务），写事务则禁止任何其他事务。此隔离级别可有效防止不可重复读和脏读。

**Serializable（可串行化）**
提供严格的事务隔离。它要求事务序列化执行，事务只能一个接着一个地执行，不能并发执行。此隔离级别可有效防止脏读、不可重复读和幻读。但这个级别可能导致大量的超时现象和锁竞争，在实际应用中很少使用。


一般来说，事务的隔离级别越高，越能保证数据库的完整性和一致性，但相对来说，隔离级别越高，对并发性能的影响也越大。因此，通常将数据库的隔离级别设置为 Read Committed，即读已提交数据，它既能防止脏读，又能有较好的并发性能。虽然这种隔离级别会导致不可重复读、幻读和第二类丢失更新这些并发问题，但可通过在应用程序中采用悲观锁和乐观锁加以控制。

# CAP定理
分布式系统有一个著名的CAP理论，即一个分布式系统要同时满足一致性（Consistency）、可用性（Availablility）和分区容错性（Partition Tolerance）。


**一致性（Consistency）：**一致性指的是数据的强一致性。每次的读操作都是读取的最新数据。即如果写入某个数据成功的话，之后的读取都应该读的是新写入的数据；如果写入失败的话，之后读取的都不应该是写入失败的数据。
**可用性（Availability）：**可用性指的是服务的可用性。即每个请求都能在合理的时间内获得符合预期的响应结果。
**分区容错性（Partition Tolerance）：**分区容错性指的是当节点之间的网络出现问题之后，系统仍然能够正常提供服务。


CAP原则指的是这三个要素最多能同时满足两个。不可能同时满足三个要素


CAP理论是由Eric Brewer在2000年的PODC会议上提出的，该理论在两年后被证明成立。


CAP理论告诉架构师不要妄想设计出同时满足三者的系统，应该有所取舍，设计出适合业务的系统。


 ![](https://img2020.cnblogs.com/blog/1801000/202109/1801000-20210924190819275-91228932.png)



在分布式的系统中，P是基本要求，而单体应用则是CA系统。微服务系统通常是一个AP系统，即同时满足可用性和分区容错性。这样就有了一个在分布式系统中保证数据强一致性的难题，这个难题的一个解决方案就是分布式事务。




# BASE 理论
BASE 是 Basically Available（基本可用）、Soft state（软状态）和 Eventually consistent （最终一致性）三个短语的缩写。BASE 理论是对 CAP 中 AP 的一个扩展，通过牺牲强一致性来获得可用性，当出现故障允许部分不可用但要保证核心功能可用，允许数据在一段时间内是不一致的，但最终达到一致状态。满足BASE理论的事务，我们称之为“**柔性事务**”。

**基本可用：**分布式系统在出现故障时，允许损失部分可用功能，保证核心功能可用。如电商网站交易付款出现问题了，商品依然可以正常浏览。
**软状态：**由于不要求强一致性，所以BASE允许系统中存在中间状态（也叫软状态），这个状态不影响系统可用性，如订单的"支付中"、“数据同步中”等状态，待数据最终一致后状态改为“成功”状态。
**最终一致：**最终一致是指经过一段时间后，所有节点数据都将会达到一致。如订单的"支付中"状态，最终会变 为“支付成功”或者"支付失败"，使订单状态与实际交易结果达成一致，但需要一定时间的延迟、等待。

# 分布式事务的解决方案
针对不同的分布式场景业界常见的解决方案有 2PC、3PC、TCC、可靠消息最终一致性、最大努力通知这几种。

## 2PC

2PC 即两阶段提交协议，是将整个事务流程分为两个阶段，准备阶段（Prepare phase）、提交阶段（commit phase），2 是指两个阶段，P 是指准备阶段，C 是指提交阶段。


举例：张三和李四好久不见，老友约起聚餐，饭店老板要求先买单，才能出票。这时张三和李四分别抱怨近况不如意，囊中羞涩，都不愿意请客，这时只能AA。只有张三和李四都付款，老板才能出票安排就餐。


准备阶段：老板要求张三付款，张三付款。老板要求李四付款，李四付款。
提交阶段：老板出票，两人拿票纷纷落座就餐。


整个事务过程由事务管理器和参与者组成，店老板就是事务管理器，张三、李四就是事务参与者，事务管理器负责决策整个分布式事务的提交和回滚，事务参与者负责自己本地事务的提交和回滚


在计算机中部分关系数据库如 Oracle、MySQL 支持两阶段提交协议，如下图：

**准备阶段（Prepare phase）：**事务管理器给每个参与者发送 Prepare 消息，每个数据库参与者在本地执行事务，并写本地的 Undo/Redo 日志，此时事务没有提交。（Undo 日志是记录修改前的数据，用于数据库回滚，Redo 日志是记录修改后的数据，用于提交事务后写入数据文件）
**提交阶段（commit phase）：**如果事务管理器收到了参与者的执行失败或者超时消息时，直接给每个参与者发送回滚（Rollback）消息；否则，发送提交（Commit）消息；参与者根据事务管理器的指令执行提交或者回滚操作，并释放事务处理过程中使用的锁资源。注意：必须在最后阶段释放锁资源。

##  XA 方案

2PC的传统方案是在数据库层面实现的，如 Oracle、MySQL 都支持 2PC 协议，为了统一标准减少行业内不必要的对接成本，需要制定标准化的处理模型及接口标准，国际开放标准组织 Open Group 定义了分布式事务处理模型**DTP**（Distributed Transaction Processing Reference Model）。


以新用户注册送积分为例来说明：

1. 应用程序（AP）持有用户库和积分库两个数据源。
1. 应用程序（AP）通过 TM 通知用户库 RM 新增用户，同时通知积分库RM为该用户新增积分，RM 此时并未提交事务，此时用户和积分资源锁定。
1. TM 收到执行回复，只要有一方失败则分别向其他 RM 发起回滚事务，回滚完毕，资源锁释放。
1. TM 收到执行回复，全部成功，此时向所有 RM 发起提交事务，提交完毕，资源锁释放。



DTP 模型定义如下角色：

- **AP**（Application Program）：即应用程序，可以理解为使用 DTP 分布式事务的程序。
- **RM**（Resource Manager）：即资源管理器，可以理解为事务的参与者，一般情况下是指一个数据库实例，通过资源管理器对该数据库进行控制，资源管理器控制着分支事务。
- **TM**（Transaction Manager）：事务管理器，负责协调和管理事务，事务管理器控制着全局事务，管理事务生命周期，并协调各个 RM。**全局事务**是指分布式事务处理环境中，需要操作多个数据库共同完成一个工作，这个工作即是一个全局事务。
- DTP 模型定义TM和RM之间通讯的接口规范叫 **XA**，简单理解为数据库提供的 2PC 接口协议，**基于数据库的 XA 协议来实现 2PC 又称为 XA 方案**


**总结**
整个 2PC 的事务流程涉及到三个角色 AP、RM、TM。AP 指的是使用 2PC 分布式事务的应用程序；RM 指的是资源管理器，它控制着分支事务；TM 指的是事务管理器，它控制着整个全局事务。
（1）在**准备阶段** RM 执行实际的业务操作，但不提交事务，资源锁定
（2）在**提交阶段** TM 会接受 RM 在准备阶段的执行回复，只要有任一个RM执行失败，TM 会通知所有 RM 执行回滚操作，否则，TM 将会通知所有 RM 提交该事务。提交阶段结束资源锁释放。

**XA方案的问题**

1. 需要本地数据库支持XA协议。
1. 资源锁需要等到两个阶段结束才释放，性能较差。

## TCC


TCC 是 Try、Conﬁrm、Cancel 三个词语的缩写，TCC 要求每个分支事务实现三个操作：预处理 Try、确认 Conﬁrm、撤销 Cancel。Try 操作做业务检查及资源预留，Conﬁrm 做业务确认操作，Cancel 实现一个与 Try 相反的操作即回滚操作。TM 首先发起所有的分支事务的 Try 操作，任何一个分支事务的Try操作执行失败，TM 将会发起所有分支事务的 Cancel 操作，若 Try 操作全部成功，TM 将会发起所有分支事务的 Conﬁrm 操作，其中 Conﬁrm/Cancel 操作若执行失败，TM 会进行重试。

TCC 分为三个阶段：

1. **Try** 阶段是做完业务检查（一致性）及资源预留（隔离），此阶段仅是一个初步操作，它和后续的 Conﬁrm 一起才能真正构成一个完整的业务逻辑。
1. **Confirm** 阶段是做确认提交，Try 阶段所有分支事务执行成功后开始执行 Conﬁrm。通常情况下，采用 TCC 则认为 Conﬁrm 阶段是不会出错的。即：只要 Try 成功，Conﬁrm 一定成功。若 Conﬁrm 阶段真的出错了，需引入重试机制或人工处理。
1. **Cancel** 阶段是在业务执行错误需要回滚的状态下执行分支事务的业务取消，预留资源释放。通常情况下，采用 TCC 则认为 Cancel 阶段也是一定成功的。若 Cancel 阶段真的出错了，需引入重试机制或人工处理。




**TM 事务管理器**
TM事务管理器可以实现为独立的服务，也可以让**全局事务发起方**充当 TM 的角色，TM 独立出来是为了成为公 用组件，是为了考虑系统结构和软件复用。
TM 在发起全局事务时生成全局事务记录，全局事务 ID 贯穿整个分布式事务调用链条，用来记录事务上下文， 追踪和记录状态，由于 Conﬁrm 和 Cancel 失败需进行重试，因此需要实现为幂等，幂等性是指同一个操作无论请求多少次，其结果都相同。


**TCC 异常处理**
TCC需要注意三种异常处理分别是**空回滚**、**幂等**、**悬挂**

**空回滚**
在没有调用 TCC 资源 Try 方法的情况下，调用了二阶段的 Cancel 方法，Cancel 方法需要识别出这是一个空回滚，然后直接返回成功。
出现原因是当一个分支事务所在服务宕机或网络异常，分支事务调用记录为失败，这个时候其实是没有执行 Try 阶段，当故障恢复后，分布式事务进行回滚则会调用二阶段的 Cancel 方法，从而形成空回滚。
解决思路是关键就是要识别出这个空回滚。思路很简单就是需要知道一阶段是否执行，如果执行了，那就是正常回滚；如果没执行，那就是空回滚。前面已经说过 TM 在发起全局事务时生成全局事务记录，全局事务 ID 贯穿整个分布式事务调用链条。再额外增加一张分支事务记录表，其中有全局事务 ID 和分支事务 ID，第一阶段 Try 方法里会插入一条记录，表示一阶段执行了。Cancel 接口里读取该记录，如果该记录存在，则正常回滚；如果该记录不存在，则是空回滚。

**幂等**
通过前面介绍已经了解到，为了保证 TCC 二阶段提交重试机制不会引发数据不一致，要求 TCC 的二阶段 Try、Conﬁrm 和 Cancel 接口保证幂等，这样不会重复使用或者释放资源。如果幂等控制没有做好，很有可能导致数据不一致等严重问题。
解决思路在上述"分支事务记录"中增加执行状态，每次执行前都查询该状态。

**悬挂**
悬挂就是对于一个分布式事务，其二阶段 Cancel 接口比 Try 接口先执行。
出现原因是在 RPC 调用分支事务 Try 时，先注册分支事务，再执行 RPC 调用，如果此时 RPC 调用的网络发生拥堵，通常 RPC 调用是有超时时间的，RPC 超时以后，TM 就会通知 RM 回滚该分布式事务，可能回滚完成后，RPC 请求才到达参与者真正执行，而一个 Try 方法预留的业务资源，只有该分布式事务才能使用，该分布式事务第一阶段预留的业务资源就再也没有人能够处理了，对于这种情况，我们就称为悬挂，即业务资源预留后没法继续处理。
解决思路是如果二阶段执行完成，那一阶段就不能再继续执行。在执行一阶段事务时判断在该全局事务下，"分支事务记录"表中是否已经有二阶段事务记录，如果有则不执行 Try。


**举例，场景为 A 转账 30 元给 B，A 和 B 账户在不同的服务。**
**方案**
账户 A
```
try:
    检查余额是否够30元
    扣减30元
confirm:
    空
cancel:
    增加30元
```
账户 B
```
try:
    增加30元
confirm:
    空
cancel:
    减少30元
```

**方案说明**
（1）账户 A，这里的余额就是所谓的业务资源，按照前面提到的原则，在第一阶段需要检查并预留业务资源，因此，我们在扣钱 TCC 资源的 Try 接口里先检查 A 账户余额是否足够，如果足够则扣除 30 元。 Conﬁrm 接口表示正式提交，由于业务资源已经在 Try 接口里扣除掉了，那么在第二阶段的 Conﬁrm 接口里可以什么都不用做。Cancel 接口的执行表示整个事务回滚，账户A回滚则需要把 Try 接口里扣除掉的 30 元还给账户。
（2）账号B，在第一阶段 Try 接口里实现给账户 B 加钱，Cancel 接口的执行表示整个事务回滚，账户 B 回滚则需要把 Try 接口里加的 30 元再减去。

**方案问题分析**

1. 如果账户 A 的 Try 没有执行在 Cancel 则就多加了 30 元。
1. 由于 Try、Cancel、Conﬁrm 都是由单独的线程去调用，且会出现重复调用，所以都需要实现幂等。
1. 账号 B 在 Try 中增加 30 元，当 Try 执行完成后可能会其它线程给消费了。
1. 如果账户 B 的 Try 没有执行在 Cancel 则就多减了 30 元。

**问题解决**

1. 账户 A 的 Cancel 方法需要判断 Try 方法是否执行，正常执行 Try 后方可执行 Cancel。
1. Try、Cancel、Conﬁrm方法实现幂等。
1. 账号 B 在 Try 方法中不允许更新账户金额，在 Conﬁrm 中更新账户金额。
1. 账户 B 的 Cancel 方法需要判断 Try 方法是否执行，正常执行 Try 后方可执行 Cancel。

**优化方案**
账户 A
```
try:
    try幂等校验
    try悬挂处理
    检查余额是否够30元
    扣减30元
confirm:
    空
cancel:
    cancel幂等校验
    cancel空回滚处理
    增加可用余额30元
```
账户 B
```
try:
    空
confirm:
    confirm幂等校验
    正式增加30元
cancel:
    空
```


**小结**
如果拿 TCC 事务的处理流程与 2PC 两阶段提交做比较，2PC 通常都是在跨库的 DB 层面，而 TCC 则在应用层面的处理，需要通过业务逻辑来实现。这种分布式事务的实现方式的优势在于，可以让**应用自己定义数据操作的粒度，使得降低锁冲突、提高吞吐量成为可能**。


而不足之处则在于对应用的侵入性非常强，业务逻辑的每个分支都需要实现 Try、Conﬁrm、Cancel 三个操作。此外，其实现难度也比较大，需要按照网络状态、系统故障等不同的失败原因实现不同的回滚策略。



# 最大努力通知


最大努力通知也是一种解决分布式事务的方案，下边是一个是充值的例子：

1. 账户系统调用充值系统接口
1. 充值系统完成支付处理向账户发起充值结果通知，若通知失败，则充值系统按策略进行重复通知
1. 账户系统接收到充值结果通知修改充值状态
1. 账户系统未接收到通知会主动调用充值系统的接口查询充值结果



通过上边的例子我们总结最大努力通知方案的目标：发起通知方通过一定的机制最大努力将业务处理结果通知到接收方。

具体包括：

1. 有一定的消息重复通知机制。因为接收通知方可能没有接收到通知，此时要有一定的机制对消息重复通知
1. 消息校对机制。如果尽最大努力也没有通知到接收方，或者接收方消费消息后要再次消费，此时可由接收方主动向通知方查询消息信息来满足需求。



## 方案
通过对最大努力通知的理解，采用 MQ 的 ack 机制就可以实现最大努力通知。


**方案一**

1. 发起通知方将通知发给 MQ。使用普通消息机制将通知发给MQ。如果消息没有发出去可由接收通知方主动请求发起通知方查询业务执行结果。

1. 接收通知方监听 MQ。

1. 接收通知方接收消息，业务处理完成回应 ack。

1. 接收通知方若没有回应 ack 则 MQ 会重复通知。
MQ会按照间隔 1min、5min、10min、30min、1h、2h、5h、10h的方式，逐步拉大通知间隔，直到达到通知要求的时间窗口上限。

1. 接收通知方可通过消息校对接口来校对消息的一致性。



**方案二**

1. 发起通知方将消息发给 MQ。
使用可靠消息一致方案中的事务消息保证本地事务和消息的原子性，最终将通知先发给 MQ。

1. 通知程序监听 MQ，接收 MQ 的消息。
方案 1 中接收通知方直接监听 MQ，方案 2 中由通知程序监听 MQ。
通知程序若没有回应 ack 则 MQ 会重复通知。

1. 通知程序通过互联网接口协议（如 http、webservice）调用接收通知方案接口，完成通知。
通知程序调用接收通知方案接口成功就表示通知成功，即消费 MQ 消息成功，MQ 将不再向通知程序投递通知消息。

1. 接收通知方可通过消息校对接口来校对消息的一致性。



**方案1和方案2的不同点**：

1. 方案 1 中接收通知方与 MQ 接口，即接收通知方案监听 MQ，此方案主要应用与内部应用之间的通知。
1. 方案 2 中由通知程序与 MQ 接口，通知程序监听 MQ，收到 MQ 的消息后由通知程序通过互联网接口协议调用接收通知方。此方案主要应用于外部应用之间的通知，例如支付宝、微信的支付结果通知。




# 可靠消息最终一致性


可靠消息最终一致性方案是指当事务发起方执行完成本地事务后并发出一条消息，事务参与方（消息消费者）一定能够接收消息并处理事务成功，此方案强调的是只要消息发给事务参与方最终事务要达到一致


 ![](https://img2020.cnblogs.com/blog/1801000/202109/1801000-20210924191025590-960593895.png)


事务发起方（消息生产方）将消息发给消息中间件，事务参与方从消息中间件接收消息，事务发起方和消息中间件之间，事务参与方（消息消费方）和消息中间件之间都是通过网络通信，由于网络通信的不确定性会导致分布式事务问题。


因此可靠消息最终一致性方案要解决以下几个问题：

1. **本地事务与消息发送的原子性问题**
本地事务与消息发送的原子性问题即：事务发起方在本地事务执行成功后消息必须发出去。即实现本地事务和消息发送的原子性，要么都成功，要么都失败。本地事务与消息发送的原子性问题是实现可靠消息最终一致性方案的关键问题。



2. **事务参与方接收消息的可靠性**
事务参与方必须能够从消息队列接收到消息，如果接收消息失败可以重复接收消息。



3. **消息重复消费的问题**
由于网络2的存在，若某一个消费节点超时但是消费成功，此时消息中间件会重复投递此消息，就导致了消息的重复消费。
要解决消息重复消费的问题就要实现事务参与方的方法幂等性。




**最大努力通知与可靠消息一致性有什么不同？**

**解决方案思想不同**
可靠消息一致性，发起通知方需要保证将消息发出去，并且将消息发到接收通知方，消息的可靠性关键由发起通知方来保证。最大努力通知，发起通知方尽最大的努力将业务处理结果通知为接收通知方，但是可能消息接收不到，此时需要接 收通知方主动调用发起通知方的接口查询业务处理结果，通知的可靠性关键在接收通知方。



**两者的业务应用场景不同**
可靠消息一致性关注的是交易过程的事务一致，以异步的方式完成交易。最大努力通知关注的是交易后的通知事务，即将交易结果可靠的通知出去。



**技术解决方向不同**
可靠消息一致性要解决消息从发出到接收的一致性，即消息发出并且被接收到。最大努力通知无法保证消息从发出到接收的一致性，只提供消息接收的可靠性机制。可靠机制是，最大努力的将消息通知给接收方，当消息无法被接收方接收时，由接收方主动查询消息（业务处理结果）

# 总结


**2PC** 最大的诟病是一个阻塞协议。RM 在执行分支事务后需要等待 TM 的决定，此时服务会阻塞并锁定资源。由于其阻塞机制和最差时间复杂度高，因此，这种设计不能适应随着事务涉及的服务数量增加而扩展的需要，很难用于并发较高以及子事务生命周期较长（long-running transactions） 的分布式服务中。


如果拿**TCC**事务的处理流程与2PC两阶段提交做比较，2PC 通常都是在跨库的 DB 层面，而 TCC 则在应用层面的处理，需要通过业务逻辑来实现。这种分布式事务的实现方式的优势在于，可以让**应用自己定义数据操作的粒度，使得降低锁冲突、提高吞吐量成为可能**。而不足之处则在于对应用的侵入性非常强，业务逻辑的每个分支都需要实现 Try、Conﬁrm、Cancel 三个操作。此外，其实现难度也比较大，需要按照网络状态、系统故障等不同的失败原因实 现不同的回滚策略。典型的使用场景：满减，登录送优惠券等。

**可靠消息最终一致性**事务适合执行周期长且实时性要求不高的场景。引入消息机制后，同步的事务操作变为基于消息执行的异步操作, 避免了分布式事务中的同步阻塞操作的影响，并实现了两个服务的解耦。典型的使用场景：注册送积分，登录送优惠券等。

**最大努力通知**是分布式事务中要求最低的一种,适用于一些最终一致性时间敏感度低的业务；允许发起通知方处理业务失败，在接收通知方收到通知后积极进行失败处理，无论发起通知方如何处理结果都会不影响到接收通知方的后续处理；发起通知方需提供查询执行情况接口，用于接收通知方校对结果。典型的使用场景：银行通知、支付结果通知等。
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15331873.html</id>
        <title type="text">Redis缓存和分布式锁-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-24T11:28:00Z</published>
        <updated>2021-09-24T11:28:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15331873.html" />
        <content type="text">

为了系统性能的提升，一般会将部分数据放入缓存中，加速访问。


# 使用redis产生内存溢出问题


使用redis作缓存，在压力测试中会产生堆外内存溢出异常


原因：spring boot2.0以后默认使用lettuce作为操作redis的客户端。它使用netty进行网络通信。lettuce的bug导致netty的堆外内存溢出。


解决办法：将操作redis底层客户端的lettuce切换为jedis


```xml
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
    &lt;exclusions&gt;
        &lt;exclusion&gt;
            &lt;groupId&gt;io.lettuce&lt;/groupId&gt;
            &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt;
        &lt;/exclusion&gt;
    &lt;/exclusions&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
    &lt;groupId&gt;redis.clients&lt;/groupId&gt;
    &lt;artifactId&gt;jedis&lt;/artifactId&gt;
&lt;/dependency&gt;
```


# 缓存击穿、穿透、雪崩


高并发情况下缓存失效产生的问题


## 缓存穿透


查询一个一定不存在的数据，由于缓存中没有这个数据，然后就去数据库里面查，但是数据库也没有这个数据，并且没有将查询到的null写到缓存，导致了每次都要到数据库中去查


**风险**


利用不存在的数据进行攻击，数据库瞬时压力增大，最后导致崩溃


**解决方案**


把null结果缓存，加入短暂的缓存时间。


## 缓存雪崩


缓存雪崩指的是设置缓存时key使用的相同的过期时间，导致缓存在某一时刻同时失效，请求同时去查询数据库，数据库瞬时压力过大崩溃


**解决方案**


在原有的过期时间上增加一个随机值，比如1~5分钟，这样缓存的过期时间重复率就会降低


## 缓存击穿


如果一个key在大量的请求进来时正好失效，这些请求同时去访问数据库，这样被称为缓存击穿


**解决方案**


加锁，大量并发进来只让一个去查数据库 ，其他人等着，查到以后释放锁，其他人获取锁先查缓存就会有数据，不用去查数据库。


# redis+lua脚本做分布式锁


1. 保证加锁和设置锁的过期时间是一个原子操作，避免加锁后还没来得及设置锁的过期时间，系统就挂掉，然后变成死锁。
2. 保证业务代码在锁的有效期内执行完毕，避免业务还没完成锁就失效其他线程就进来。
3. 保证解锁的操作是一个原子操作：获取值，对比值，删除。需要使用lua脚本完成。



```java
public void getServiceLock() {
    //线程进来先去查缓存，直接返回

    //如果缓存没有，尝试占锁去查数据库
    String uuid = UUID.randomUUID().toString();
    //去redis占锁,占到锁并设置过期时间30s
    Boolean lock = redisTemplate.opsForValue().setIfAbsent("lock", uuid, 30, TimeUnit.SECONDS);
    //抢到锁
    if (lock) {

        try {
            //执行业务
        } finally {
            //解锁
            String script = "if redis.call('get',KEYS[1]) == ARGV[1] then return redis.call('del',KEYS[1]) else return 0 end";
            redisTemplate.execute(new DefaultRedisScript&lt;Long&gt;(script, Long.class), Arrays.asList("lock"), uuid);
        }
    } else {
        //100ms再次去获取锁，自旋
        try {
            Thread.sleep(100);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        getServiceLock();
    }
}
```


# Redisson分布式锁


Redisson分布式锁文档 [https://github.com/redisson/redisson/wiki/1.-概述](https://github.com/redisson/redisson/wiki/1.-%E6%A6%82%E8%BF%B0)


加入redisson依赖


```xml
&lt;dependency&gt;
    &lt;groupId&gt;org.redisson&lt;/groupId&gt;
    &lt;artifactId&gt;redisson&lt;/artifactId&gt;
    &lt;version&gt;3.12.0&lt;/version&gt;
&lt;/dependency&gt;
```


配置redisson


```java
@Configuration
public class RedissonConfig {

    @Bean
    public RedissonClient redissonClient() {
        Config config = new Config();
        //单节点模式
        config.useSingleServer().setAddress("redis://127.0.0.1:6379");
        RedissonClient redisson = Redisson.create(config);
        return redisson;
    }
}
```


使用锁


```java
@Autowired
private RedissonClient redisson;

public void redissonLock() {
    RLock lock = redisson.getLock("lock");
    //加锁，一般指定锁的过期时间，秒
    lock.lock(30, TimeUnit.SECONDS);
    try {
        //执行业务代码
    } finally {
        lock.unlock();
    }
}
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15332461.html</id>
        <title type="text">SpringBoot+JWT登录认证-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-24T12:13:00Z</published>
        <updated>2021-09-24T12:13:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15332461.html" />
        <content type="text"># JWT是什么
JSON Web Token (JWT)是一个开放标准(RFC 7519)，它定义了一种紧凑的、自包含的方式，用于作为JSON对象在各方之间安全地传输信息。该信息可以被验证和信任，因为它是数字签名的。

JSON Web Token由三部分组成，头部、载荷与签名,它们之间用点`.`连接
- Header
- Payload
- Signature

## Header
Header典型的由两部分组成：token的类型（“JWT”）和算法名称（比如：HMAC SHA256或者RSA等等）
```json
{
  "alg": "HS256",
  "typ": "JWT"
}
```
Header会被Base64Url编码为JWT的第一部分

## Payload
Payload是有关实体（通常是用户）和其他数据的声明，它包含三部分
**（1）注册声明**
这些是一组预定义的权利要求，不是强制性的，而是建议使用的，以提供一组有用的可互操作的权利要求。其中一些是： iss（JWT的签发者）， exp（expires,到期时间）， sub（主题）， aud（JWT接收者），iat(issued at，签发时间)等。

**（2）公开声明**
公共的声明可以添加任何的信息，一般添加用户的相关信息或其他业务需要的必要信息.但不建议添加敏感信息，因为该部分在客户端可解密。

**（3）私有声明**
私有声明是提供者和消费者所共同定义的声明，一般不建议存放敏感信息，因为base64是对称解密的，意味着该部分信息可以归类为明文信息。

```json
{ "iat": 1593955943,
  "exp": 1593955973,
  "uid": 10,
  "username": "test",
  "scopes": [ "admin", "user" ]
}
```
Payload会被Base64Url编码为JWT的第二部分

## Signature
Signature由base64加密后的header和base64加密后的payload使用.连接组成的字符串，然后通过header中声明的加密方式进行加盐secret组合加密而成

将这三个部分用`.`连接就构成了JWT

# 使用JWT
加入依赖
```xml
&lt;dependency&gt;
    &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt;
    &lt;artifactId&gt;jjwt&lt;/artifactId&gt;
    &lt;version&gt;0.9.0&lt;/version&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
    &lt;artifactId&gt;fastjson&lt;/artifactId&gt;
    &lt;version&gt;1.2.47&lt;/version&gt;
&lt;/dependency&gt;
```


jwt工具类
```java
package com.zkzx.zkconsult.util;

import io.jsonwebtoken.*;
import org.springframework.util.StringUtils;

import java.util.Date;

public class JwtUtil {
    //过期时间单位毫秒ms
    private static final long tokenExpiration = 24 * 60 * 60 * 1000;//一天
    //签名密钥
    private static final String tokenSignKey = "83c85bd9-e97a-479f-96f4-b347f5490bcb";

    private static final String USER_ID = "userId";
    private static final String USERNAME = "username";

    /**
     * 根据用户信息生成token
     *
     * @param userId
     * @param username
     * @return token
     */
    public static String createToken(Long userId, String username) {
        JwtBuilder builder = Jwts.builder();
        builder
                /*设置标识*/
                .setId("orange")
                /*主体*/
                .setSubject("lemon")
                /*签发时间*/
                .setIssuedAt(new Date())
                /*设置密钥*/
                .signWith(SignatureAlgorithm.HS256, tokenSignKey)
                /*过期时间*/
                .setExpiration(new Date(System.currentTimeMillis() + tokenExpiration))
                /*设计用户信息*/
                .claim(USER_ID, userId)
                .claim(USERNAME, username);

        String token = builder.compact();

        return token;

    }

    /**
     * 获取Claims 部分内容（即要传的信息）
     *
     * @param token
     * @return
     */
    public static Claims getClaim(String token) {
        Claims claims = null;
        try {
            claims = Jwts.parser()
                    .setSigningKey(tokenSignKey)
                    .parseClaimsJws(token)
                    .getBody();
        } catch (Exception e) {
            return null;
        }
        return claims;
    }

    /**
     * 根据token字符串返回用户ID
     *
     * @param token
     * @return userId
     */
    public static Long getUserId(String token) {
        if (StringUtils.isEmpty(token)) {
            return null;
        }
        Claims claims = getClaim(token);
        if (claims == null) {
            return null;
        }
        Long userId = Long.valueOf(String.valueOf(claims.get(USER_ID)));
        return userId;
    }

    /**
     * 根据token字符串返回用户名 username
     *
     * @param token
     * @return username
     */
    public static String getUsername(String token) {
        if (StringUtils.isEmpty(token)) {
            return null;
        }
        Claims claims = getClaim(token);
        if (claims == null) {
            return null;
        }
        String username = String.valueOf(claims.get(USERNAME));
        return username;
    }


    /**
     * 验证token是否有效
     *
     * @param token
     * @return true:有效   false:无效
     */
    public static boolean validation(String token) {
        if (StringUtils.isEmpty(token)) {
            return false;
        }
        Claims claims = getClaim(token);
        if (claims == null) {
            return false;
        }
        return true;
    }

    public static String flushedToken(String token) {
        return createToken(getUserId(token), getUsername(token));
    }

}
```


拦截器
```java
package com.zkzx.zkconsult.interceptor;

import com.alibaba.fastjson.JSON;
import com.zkzx.zkconsult.constant.CodeMessageEnum;
import com.zkzx.zkconsult.dto.response.ResponseData;
import com.zkzx.zkconsult.util.JwtUtil;
import lombok.extern.slf4j.Slf4j;
import org.springframework.web.servlet.HandlerInterceptor;
import org.springframework.web.servlet.ModelAndView;

import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import java.io.PrintWriter;

@Slf4j
public class MyLoginInterceptor implements HandlerInterceptor {
    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
        String token = request.getHeader("X-Token");
        log.info("token：{}", token);

        response.setCharacterEncoding("UTF-8");
        if (JwtUtil.validation(token)) {
            return true;
        }
        response.setContentType("application/json; charset=utf-8");
        Object json = JSON.toJSON(new ResponseData&lt;Void&gt;(CodeMessageEnum.TOKEN_ERROR));
        PrintWriter writer = response.getWriter();
        writer.write(json.toString());
        return false;
    }

    @Override
    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception {

    }

    @Override
    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception {

    }
}
```


配置拦截器
```java
package com.zkzx.zkconsult.config;

import com.zkzx.zkconsult.interceptor.MyLoginInterceptor;
import org.springframework.context.annotation.Configuration;
import org.springframework.web.servlet.config.annotation.InterceptorRegistry;
import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;

@Configuration
public class WebConfig implements WebMvcConfigurer {

    @Override
    public void addInterceptors(InterceptorRegistry registry) {
        registry.addInterceptor(new MyLoginInterceptor())
                .addPathPatterns("/**")  //所有请求都被拦截包括静态资源
                .excludePathPatterns("/user/login", "/user/getPassword/**"); //放行的请求
    }
}
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15333081.html</id>
        <title type="text">SpringCloud常用组件-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-24T15:24:00Z</published>
        <updated>2021-09-24T15:24:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15333081.html" />
        <content type="text"># Spring Cloud Alibaba

Spring Cloud Alibaba 致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用微服务的必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。

引入依赖，在 `dependencyManagement` 中添加如下配置。

```
&lt;dependencyManagement&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt;
            &lt;version&gt;2.2.6.RELEASE&lt;/version&gt;
            &lt;type&gt;pom&lt;/type&gt;
            &lt;scope&gt;import&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/dependencyManagement&gt;
```

# Nacos 服务注册与发现

Nacos 是阿里巴巴开源的一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。

首先需要获取 Nacos Server，[Nacos Server 下载页](https://github.com/alibaba/nacos/releases)

修改 pom.xml 文件，引入 Nacos Discovery Starter。
```xml
 &lt;dependency&gt;
     &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
     &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt;
 &lt;/dependency&gt;
```


在配置文件中配置 Nacos Server 地址
```yaml
server:
  port: 8082

spring:
  application:
    name: service-provider
  cloud:
    nacos:
      server-addr: 127.0.0.1:8848
```


使用 @EnableDiscoveryClient 注解开启服务注册与发现功能
```java
 @SpringBootApplication
 @EnableDiscoveryClient
 public class ProviderApplication {

 	public static void main(String[] args) {
 		SpringApplication.run(ProviderApplication.class, args);
 	}
 }
```



# Nacos 分布式配置管理

首先，修改 pom.xml 文件，引入 Nacos Config Starter。
```xml
 &lt;dependency&gt;
     &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
     &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt;
 &lt;/dependency&gt;
```


在应用的 `/src/main/resources/bootstrap.yml` 配置文件中配置 Nacos Config 元数据
```yaml
spring:
  application:
    name: service-provider

  cloud:
    nacos:
      config:
        server-addr: 127.0.0.1:8848
        namespace: d1c63875-be0c-46db-81d5-bd037567f9c1
        file-extension: yaml
```


完成上述两步后，应用会从 Nacos Config 中获取相应的配置，并添加在 Spring Environment 的 PropertySources 中。这里我们使用 [@Value ](/Value ) 注解来将对应的配置注入到 SampleController 的 userName 和 age 字段，并添加 [@RefreshScope ](/RefreshScope ) 打开动态刷新功能
```java
 @RefreshScope
 class SampleController {

 	@Value("${user.name}")
 	String userName;

 	@Value("${user.age}")
 	int age;
 }
```


在Nacos控制台的配置列表中添加配置，Data ID: service-provider.yaml，Group: DEFAULT_GROUP，内容如下
```yaml
user:
  name: orange
  age: 23
```



# OpenFeign 服务调用

OpenFeign 是Spring Cloud 的组件，所以要加入spring cloud 的依赖管理

```xml
&lt;dependencyManagement&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt;
            &lt;version&gt;2.2.6.RELEASE&lt;/version&gt;
            &lt;type&gt;pom&lt;/type&gt;
            &lt;scope&gt;import&lt;/scope&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
            &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt;
            &lt;version&gt;Hoxton.SR12&lt;/version&gt;
            &lt;type&gt;pom&lt;/type&gt;
            &lt;scope&gt;import&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/dependencyManagement&gt;
```

Nacos Discovery Starter 默认集成了 Ribbon ，所以对于使用了 Ribbon 做负载均衡的组件，可以直接使用 Nacos 的服务发现。

首先，修改 pom.xml 文件，引入 OpenFeign Starter。
```xml
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;
&lt;/dependency&gt;
```


使用注解 `@EnableFeignClients` 开启服务调用
```java
@EnableFeignClients
@EnableDiscoveryClient
@SpringBootApplication
public class ConsumerApplication {

    public static void main(String[] args) {
        SpringApplication.run(ConsumerApplication.class, args);
    }

}
```


FeignClient 已经默认集成了 Ribbon ，此处演示如何配置一个 FeignClient。
```java
 @FeignClient(name = "service-provider")
 public interface EchoService {
     @GetMapping(value = "/echo/{str}")
     String echo(@PathVariable("str") String str);
 }
```


# Gateway 网关

简单使用

修改 pom.xml 文件，引入 Sentinel Starter

```xml
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt;
&lt;/dependency&gt;
```

网关配置

```yaml
server:
  port: 8080

spring:
  application:
    name: service-gateway

  cloud:
    nacos:
      discovery:
        server-addr: 127.0.0.1:8848

    gateway:
      routes:
        - id: service-provider
          uri: lb://service-provider
          predicates:
            - Path=/provider/**
        - id: service-consumer
          uri: lb://service-consumer
          predicates:
            - Path=/consumer/**
```


# Sentinel 流量控制、熔断降级

随着微服务的流行，服务和服务之间的稳定性变得越来越重要。Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。

如何在Spring Cloud Alibaba中使用Sentinel

1. 首先下载 Sentinel 控制台 jar 包：https://github.com/alibaba/Sentinel/releases
启动Sentinel控制台
```
java -jar sentinel-dashboard-1.8.1.jar --server.port=9090
```
访问localhost:9090，默认用户名密码都是sentinel


2. 修改 pom.xml 文件，引入 Sentinel Starter
```xml
&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
    &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;
&lt;/dependency&gt;
```

3. 配置 Sentinel 控制台地址信息
application.yml
```
spring:
  cloud:
    sentinel:
      transport:
        port: 8719
        dashboard: localhost:9090
```
这里的 `spring.cloud.sentinel.transport.port` 端口配置会在应用对应的机器上启动一个 Http Server，该 Server 会与 Sentinel 控制台做交互。比如 Sentinel 控制台添加了一个限流规则，会把规则数据 push 给这个 Http Server 接收，Http Server 再将规则注册到 Sentinel 中。


## sentinel 流量控制

给请求上流控规则
比如现在有个资源路径 `GET:http://service-provider/provider/hello/{name}`，设置每秒只接收一个请求
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211023184942300-1239874095.png)
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211023185118437-349344288.png)

访问这个加上流控规则的路径时，每秒大于一个请求就会返回失败信息
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211023185617882-1603721581.png)

这个时sentinel默认的返回信息，可以自定返回信息
```java
@Configuration
public class SentinelConfig {

    @Bean
    public BlockExceptionHandler blockExceptionHandler() {
        return new BlockExceptionHandler() {
            @Override
            public void handle(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, BlockException e) throws Exception {
                httpServletResponse.setContentType("application/json;charset=utf-8");
                ResponseData responseData = new ResponseData(5001, "活动火爆，请稍后再试");
                String s = new ObjectMapper().writeValueAsString(responseData);
                httpServletResponse.getWriter().write(s);
            }
        };
    }

}
```

## Sentinel 支持 Endpoint

在使用 Endpoint 特性之前需要在 Maven 中添加 spring-boot-starter-actuator 依赖，并在配置中允许 Endpoints 的访问。

Spring Boot 1.x 中添加配置 `management.security.enabled=false`。暴露的 endpoint 路径为 `/sentinel`

Spring Boot 2.x 中添加配置 `management.endpoints.web.exposure.include=*`。暴露的 endpoint 路径为 `/actuator/sentinel`

Sentinel Endpoint 里暴露的信息非常有用。包括当前应用的所有规则信息、日志目录、当前实例的 IP，Sentinel Dashboard 地址，Block Page，应用与 Sentinel Dashboard 的心跳频率等等信息。

## Sentinel支持Feign服务熔断

Sentinel 适配了 Feign 组件。如果想使用，除了引入 `spring-cloud-starter-alibaba-sentinel`，只需要在配置文件打开 Sentinel 对 Feign 的支持
```yaml
feign:
  sentinel:
    enabled: true
```


```java
@FeignClient(value = "service-provider",fallback = ProviderOuterServiceFallback.class)
public interface ProviderOuterService {

    @GetMapping("provider/hello/{name}")
    String hello(@PathVariable String name);
}
```

```java
@Component
public class ProviderOuterServiceFallback implements ProviderOuterService {
    @Override
    public String hello(String name) {
        return "系统错误";
    }
}
```


## Sentinel-Gateway网关限流

从 1.6.0 版本开始，Sentinel 提供了 Spring Cloud Gateway 的适配模块，可以提供两种资源维度的限流：

- route 维度：即在 Spring 配置文件中配置的路由条目，资源名为对应的 routeId
- 自定义 API 维度：用户可以利用 Sentinel 提供的 API 来自定义一些 API 分组

使用时在网关服务添加sentinel适配gateway的依赖

```xml
&lt;dependency&gt;
	&lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;
	&lt;artifactId&gt;spring-cloud-alibaba-sentinel-gateway&lt;/artifactId&gt;
&lt;/dependency&gt;
```

来个使用案例，所有的请求都会经过网关服务，限制每个IP每秒最多能请求三次；
API管理 &gt; 新增API分组
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211024005533898-2101250412.png)
匹配串`/**` 表示所有的请求
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211024005840944-1638330733.png)

流控规则 &gt; 新增网关流控规则
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211024010340288-1178813007.png)
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211024010707686-522003956.png)

当单个相同的IP每秒请求次数超过3次就会返回失败信息
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211024010952992-1006899848.png)

这个是Sentinel默认的返回信息，可以自定义
```java
@Configuration
public class SentinelGatewayConfig {

    @Bean
    public BlockRequestHandler blockRequestHandler() {
        return new BlockRequestHandler() {
            @Override
            public Mono&lt;ServerResponse&gt; handleRequest(ServerWebExchange serverWebExchange, Throwable throwable) {
                ResponseData responseData = new ResponseData(4001, "请稍后再试");
                String res = null;
                try {
                    res = new ObjectMapper().writeValueAsString(responseData);
                } catch (JsonProcessingException e) {
                    e.printStackTrace();
                }
                Mono&lt;ServerResponse&gt; body = ServerResponse.ok().body(Mono.just(res), String.class);
                return body;
            }
        };
    }
}
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15333152.html</id>
        <title type="text">Redis入门学习-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-26T07:39:00Z</published>
        <updated>2021-09-26T07:39:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15333152.html" />
        <content type="text"># Redis是什么
Redis是由意大利人Salvatore Sanfilippo（网名：antirez）开发的一款内存高速缓存数据库。Redis全称为：Remote Dictionary Server（远程数据服务），该软件使用C语言编写，Redis是一个key-value存储系统，它支持丰富的数据类型，如：string、list、set、zset(sorted set)、hash。

# Redis的特点
Redis以内存作为数据存储介质，所以读写数据的效率极高，远远超过数据库。以设置和获取一个256字节字符串为例，它的读取速度可高达110000次/s，写速度高达81000次/s。

Redis跟memcache不同的是，储存在Redis中的数据是持久化的，断电或重启后，数据也不会丢失。因为Redis的存储分为内存存储、磁盘存储和log文件三部分，重启后，Redis可以从磁盘重新将数据加载到内存中，这些可以通过配置文件对其进行配置，正因为这样，Redis才能实现持久化。

# 安装Redis
1. 去官网下载[redis源文件 ](https://redis.io/download) ,上传到Linux服务器上 , 解压到安装目录
2. 进入到安装目录执行`make`命令编译源文件
3. 执行命令`make install` 安装配置redis环境变量

# 启动Redis
前台启动方式


```bash
redis-server
```


后台启动方式


```bash
redis-server &amp;
```


查看redis进程 `ps -ef | grep redis`


```bash
[root@lemon ~]# ps -ef | grep redis
root      11719   7346  0 19:47 pts/0    00:00:00 redis-server *:6379
root      11724   7346  0 19:48 pts/0    00:00:00 grep --color=auto redis
```


使用redis的命令行客户端连接redis服务器`redis-cli`


```bash
[root@lemon ~]# redis-cli
127.0.0.1:6379&gt;
```

# 关闭Redis

关闭方式一 : 使用redis客户端向服务器发送命令关闭 (推荐使用)
```bash
redis-cli shutdown
```

关闭方式二 : 先用 命令`ps -ef | grep redis`查出进程号, 再用 `kill pid`关闭
```bash
[root@lemon ~]# ps -ef | grep redis
root      11798   7346  0 20:06 pts/0    00:00:00 redis-server *:6379
root      11803   7346  0 20:06 pts/0    00:00:00 grep --color=auto redis
[root@lemon ~]# kill 11798
[root@lemon ~]# 11798:signal-handler (1560082112) Received SIGTERM scheduling shutdown...
11798:M 09 Jun 2019 20:08:32.240 # User requested shutdown...
11798:M 09 Jun 2019 20:08:32.240 * Saving the final RDB snapshot before exiting.
11798:M 09 Jun 2019 20:08:32.241 * DB saved on disk
11798:M 09 Jun 2019 20:08:32.241 # Redis is now ready to exit, bye bye...
```

# Redis的数据类型

**字符串String**
字符串类型是redis 中最基本的数据类型 ,  它能存储任何形式的字符串 , 包括二进制数据, 序列化后的数据 , JSON化的对象甚至是一张图片 ,  最大512M

**哈希hash**
redis hash 是一个String类型的field 和 value 的映射表 , hash特别适合用于存储对象.

**列表list**
Redis 列表是简单的字符串列表 , 按照插入的顺序排序 ,  你可以添加一个元素到列表的头部(左边) 或者尾部 (右边)

**集合set**
Redis 的set 是String类型的无序集合 , 集合成员是唯一的, 即集合中不能出现重复的数据

**有序集合zset**
redis 有序集合zset 和集合 set 一样也是String类型元素的集合, 且不允许重复的成员 .  不同的是 zset 的每个元素都会关联一个分数 ( 分数可以重复) , redis 通过分数来为集合中的成员进行从小到大的排序 .

# String的常用命令

## SET

SET key value [EX seconds] [PX milliseconds] [NX|XX]

将字符串值 value 关联到 key 。

如果 key 已经持有其他值， SET 就覆写旧值， 无视类型。

当 SET 命令对一个带有生存时间（TTL）的键进行设置之后， 该键原有的 TTL 将被清除。

**可选参数**
从 Redis 2.6.12 版本开始， SET 命令的行为可以通过一系列参数来修改：

`EX seconds` ： 将键的过期时间设置为 seconds 秒。 执行 SET key value EX seconds 的效果等同于执行 SETEX key seconds value 。

`PX milliseconds` ： 将键的过期时间设置为 milliseconds 毫秒。 执行 SET key value PX milliseconds 的效果等同于执行 PSETEX key milliseconds value 。

`NX` ： 只在键不存在时， 才对键进行设置操作。 执行 SET key value NX 的效果等同于执行 SETNX key value 。

`XX` ： 只在键已经存在时， 才对键进行设置操作。

&gt;注意
&gt;因为 SET 命令可以通过参数来实现 SETNX 、 SETEX 以及 PSETEX 命令的效果， 所以 Redis 将来的版本可能会移除并废弃 SETNX 、 SETEX 和 PSETEX 这三个命令。



**返回值**
在 Redis 2.6.12 版本以前， SET 命令总是返回 OK 。

从 Redis 2.6.12 版本开始， SET 命令只在设置操作成功完成时才返回 OK ； 如果命令使用了 NX 或者 XX 选项， 但是因为条件没达到而造成设置操作未执行， 那么命令将返回空批量回复（NULL Bulk Reply）。

**代码示例**

使用 EX 选项：
```bash
redis&gt; SET key-with-expire-time "hello" EX 10086
OK

redis&gt; GET key-with-expire-time
"hello"

redis&gt; TTL key-with-expire-time
(integer) 10069
```

使用 PX 选项：
```bash
redis&gt; SET key-with-pexpire-time "moto" PX 123321
OK

redis&gt; GET key-with-pexpire-time
"moto"

redis&gt; PTTL key-with-pexpire-time
(integer) 111939
```

使用 NX 选项：
```bash
redis&gt; SET not-exists-key "value" NX
OK      # 键不存在，设置成功

redis&gt; GET not-exists-key
"value"

redis&gt; SET not-exists-key "new-value" NX
(nil)   # 键已经存在，设置失败

redis&gt; GEt not-exists-key
"value" # 维持原值不变
```

使用 XX 选项：
```bash
redis&gt; EXISTS exists-key
(integer) 0

redis&gt; SET exists-key "value" XX
(nil)   # 因为键不存在，设置失败

redis&gt; SET exists-key "value"
OK      # 先给键设置一个值

redis&gt; SET exists-key "new-value" XX
OK      # 设置新值成功

redis&gt; GET exists-key
"new-value"
```

## GET

GET key

返回与键 key 相关联的字符串值。

**返回值**
如果键 key 不存在， 那么返回特殊值 nil ； 否则， 返回键 key 的值。

如果键 key 的值并非字符串类型， 那么返回一个错误， 因为 GET 命令只能用于字符串值。

**代码示例**
对不存在的键 key 或是字符串类型的键 key 执行 GET 命令：
```bash
redis&gt; GET db
(nil)

redis&gt; SET db redis
OK

redis&gt; GET db
"redis"
```


对不是字符串类型的键 key 执行 GET 命令：
```bash
redis&gt; DEL db
(integer) 1

redis&gt; LPUSH db redis mongodb mysql
(integer) 3

redis&gt; GET db
(error) ERR Operation against a key holding the wrong kind of value
```

# hash的常用命令

## HSET

HSET hash field value

将哈希表 hash 中域 field 的值设置为 value 。

如果给定的哈希表并不存在， 那么一个新的哈希表将被创建并执行 HSET 操作。

如果域 field 已经存在于哈希表中， 那么它的旧值将被新值 value 覆盖。

**返回值**
当 HSET 命令在哈希表中新创建 field 域并成功为它设置值时， 命令返回 1 ； 如果域 field 已经存在于哈希表， 并且 HSET 命令成功使用新值覆盖了它的旧值， 那么命令返回 0 。

**代码示例**
设置一个新域：
```bash
redis&gt; HSET website google "www.g.cn"
(integer) 1

redis&gt; HGET website google
"www.g.cn"
```

对一个已存在的域进行更新：
```bash
redis&gt; HSET website google "www.google.com"
(integer) 0

redis&gt; HGET website google
"www.google.com"
```

## HGET

HGET hash field

返回哈希表中给定域的值。

**返回值**
HGET 命令在默认情况下返回给定域的值。

如果给定域不存在于哈希表中， 又或者给定的哈希表并不存在， 那么命令返回 nil 。

**代码示例**
域存在的情况：
```bash
redis&gt; HSET homepage redis redis.com
(integer) 1

redis&gt; HGET homepage redis
"redis.com"
```

域不存在的情况：
```bash
redis&gt; HGET site mysql
(nil)
```

## HMSET

HMSET key field value [field value …]

同时将多个 field-value (域-值)对设置到哈希表 key 中。

此命令会覆盖哈希表中已存在的域。

如果 key 不存在，一个空哈希表被创建并执行 HMSET 操作。

**返回值**
如果命令执行成功，返回 OK 。
当 key 不是哈希表(hash)类型时，返回一个错误。
```bash
redis&gt; HMSET website google www.google.com yahoo www.yahoo.com
OK

redis&gt; HGET website google
"www.google.com"

redis&gt; HGET website yahoo
"www.yahoo.com"
```

## HMGET

HMGET key field [field …]

返回哈希表 key 中，一个或多个给定域的值。

如果给定的域不存在于哈希表，那么返回一个 nil 值。

因为不存在的 key 被当作一个空哈希表来处理，所以对一个不存在的 key 进行 HMGET 操作将返回一个只带有 nil 值的表。


**返回值**
一个包含多个给定域的关联值的表，表值的排列顺序和给定域参数的请求顺序一样。

```bash
redis&gt; HMSET pet dog "doudou" cat "nounou"    # 一次设置多个域
OK

redis&gt; HMGET pet dog cat fake_pet             # 返回值的顺序和传入参数的顺序一样
1) "doudou"
2) "nounou"
3) (nil)
```


## HGETALL

HGETALL key

返回哈希表 key 中，所有的域和值。

在返回值里，紧跟每个域名(field name)之后是域的值(value)，所以返回值的长度是哈希表大小的两倍。


**返回值**
以列表形式返回哈希表的域和域的值。
若 key 不存在，返回空列表。
```bash
redis&gt; HSET people jack "Jack Sparrow"
(integer) 1

redis&gt; HSET people gump "Forrest Gump"
(integer) 1

redis&gt; HGETALL people
1) "jack"          # 域
2) "Jack Sparrow"  # 值
3) "gump"
4) "Forrest Gump"
```

## HDEL

HDEL key field [field …]

删除哈希表 key 中的一个或多个指定域，不存在的域将被忽略。


**返回值:**
被成功移除的域的数量，不包括被忽略的域。
```
# 测试数据

redis&gt; HGETALL abbr
1) "a"
2) "apple"
3) "b"
4) "banana"
5) "c"
6) "cat"
7) "d"
8) "dog"


# 删除单个域

redis&gt; HDEL abbr a
(integer) 1


# 删除不存在的域

redis&gt; HDEL abbr not-exists-field
(integer) 0


# 删除多个域

redis&gt; HDEL abbr b c
(integer) 2

redis&gt; HGETALL abbr
1) "d"
2) "dog"
```


# list常用命令


## lpush

语法 : lpush key value [value ...]


作用: 将一个或多个值 value 插入到列表 key 的表头(最左边) , 从左边开始加入值,从左到右的顺序依次插入到表头


返回值 : 数字,新列表的长度


rpush 和 lpush 相对应


## lrange

语法 : lrange key start stop


作用 : 获取列表 key 中指定区间内的元素 , 0 表示列表的第一个元素, 以 1 表示列表的第二个元素; start, stop 是列表的下标值, 也可以负数的下标, -1表示列表的最后一个元素 ,-2 表示列表的倒数第二个元素, 以此类推 . start, stop 超出列表的范围不会出现错误.


返回值 : 指定区间的列表


## lindex

语法 : lindex key index

作用: 获取列表 key 中下标为指定 index 的元素 , 列表元素不删除, 只是查询, 0表示列表的第一个元素,  -1表示列表的最后一个元素

返回值 : 指定下标的元素 ; index不在列表范围, 返回nil


## llen

语法 : llen key

作用 : 获取列表 key 的长度

返回值: 数值, 列表的长度; key 不存在返回 0

## lrem

语法 : lrem key count value

作用 : 根据参数 count 的值 , 移除 列表中与参数 value相等的元素. count&gt;0 , 从列表的左侧向右开始移除; count &lt; 0 从列表的尾部开始移除; count=0 移除表中所有与value 相等的值


## lset

语法 : lset key index value

作用 : 将列表key 下标为 index 的元素的值设置为value

返回值 : 设置成功返回 ok , key不存在或者 index 超出范围返回错误信息


## linsert

语法 : linsert key Before|Alfter pivot value

作用 : 将值 value 插入到列表 key 当中位于 pivot之前或之后的位置 . key 不存在, pivot不存在列表中, 不执行任何操作

返回值 : 命令执行成功, 返回新列表的长度. 没有找到pivot 返回 -1 , key不存在返回 0

# set常用命令

## sadd

语法 : sadd key member [member...]

作用 : 将一个或多个 member 元素加入到集合 key 当中 , 已经存在于集合的member元素将被忽略 ,不会再添加.

返回值 : 加入到集合的新元素的个数 . 不包括被忽略的元素.

## smembers

语法 : smembers key

作用 : 获取集合 key 中的所有成员元素, 不存在的 key 视为空集合

## sismember

语法 : sismember key member

作用 : 判断member 元素是否是集合 key 的成员

返回值 : member 是集合成员返回**1**, 其他返回 **0**

## scard

语法 : scard key

作用 : 获取集合里面的元素个数

返回值 : 数字, key 的元素个数 . 其他情况返回 0


## srem

语法 : srem key member [member...]

作用 : 删除集合 key 中的一个或多个 member 元素 , 不存在的元素被忽略 ;

返回值 : 数字,成功删除的元素个数 , 不包含忽略的元素

## srandmember

语法 : srandmember key [count]

作用 : 只提供key , 随机返回集合中一个元素 , 元素不删除,依然再集合中 ; 提供了count 整正数, 返回包含count 个数元素的集合,  集合元素各不相同 ; count 是负数 ,返回一个count 绝对值的长度的集合 ,集合中元素可能会重复多次

返回值 : 一个元素 , 多个元素的集合


## spop

语法 : spop key [count]

作用 : 随机从集合中删除一个元素, count 是删除元素的个数.

返回值 : 被删除的元素, key 不存在或空集合返回nil
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15333168.html</id>
        <title type="text">Maven配置JDK和镜像仓库-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-24T16:08:00Z</published>
        <updated>2021-09-24T16:08:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15333168.html" />
        <content type="text"># 配置JDK版本

配置为JDK1.8

修改settings.xml ,添加如下内容

```xml
&lt;profile&gt;
  &lt;id&gt;jdk-1.8&lt;/id&gt;
  &lt;activation&gt;
      &lt;activeByDefault&gt;true&lt;/activeByDefault&gt;
      &lt;jdk&gt;1.8&lt;/jdk&gt;
  &lt;/activation&gt;

  &lt;properties&gt;
    &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;
    &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;
    &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt;
  &lt;/properties&gt;
&lt;/profile&gt;
```

# 配置Maven镜像源

配置为阿里云镜像
修改settings.xml ,添加如下内容

```xml
&lt;!-- 阿里云仓库 --&gt;
&lt;mirror&gt;
   &lt;id&gt;nexus-aliyun&lt;/id&gt;
   &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;
   &lt;name&gt;Nexus aliyun&lt;/name&gt;
   &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt;
&lt;/mirror&gt;

&lt;!-- 中央仓库1 --&gt;
&lt;mirror&gt;
   &lt;id&gt;repo1&lt;/id&gt;
   &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;
   &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt;
   &lt;url&gt;http://repo1.maven.org/maven2/&lt;/url&gt;
&lt;/mirror&gt;

&lt;!-- 中央仓库2 --&gt;
&lt;mirror&gt;
   &lt;id&gt;repo2&lt;/id&gt;
   &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;
   &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt;
   &lt;url&gt;http://repo2.maven.org/maven2/&lt;/url&gt;
&lt;/mirror&gt;
```

# 配置Maven本地仓库位置

修改settings.xml ,添加如下内容

```xml
&lt;localRepository&gt;E:/repository&lt;/localRepository&gt;
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15335072.html</id>
        <title type="text">Java线程的创建和同步-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-25T10:24:00Z</published>
        <updated>2021-09-25T10:24:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15335072.html" />
        <content type="text"># 线程的基本概念

多线程的基本概念：程序、进程、线程。

程序(program)是为完成特定任务、用某种语言编写的一组指令的集合。即指一段静态的代码，静态对象。

进程(process)是程序的一次执行过程，或是正在运行的一个程序。是一个动态的过程：有它自身的产生、存在和消亡的过程。这就是生命周期。进程作为资源分配的单位，系统在运行时会为每个进程分配不同的内存区域。

线程(thread)，进程可进一步细化为线程，是一个程序内部的一条执行路径。 线程作为调度和执行的单位，每个线程拥有独立的运行栈和程序计数器(pc)，线程切换的开销小。一个进程中的多个线程共享相同的内存单元（内存地址空间），它们从同一堆中分配对象，可以访问相同的变量和对象。这就使得线程间通信更简便、高效。但多个线程操作共享的系统资源可能就会带来安全的隐患。

一个Java应用程序java.exe，其实至少有三个线程：main()主线程，gc()垃圾回收线程，异常处理线程。当然如果发生异常，会影响主线程。

# 三种创建线程的方式

三种创建线程的方式：
1. 继承`Thread`类
2. 实现`Runnable`接口
3. 使用Callable和Future创建线程

## 继承Thread类

Thread类的构造器
1. `Thread()`：创建新的Thread对象
2. `Thread(String threadname)`：创建线程并指定线程实例名
3. `Thread(Runnable target)`：指定创建线程的目标对象，它实现了Runnable接口中的run方法
3. `Thread(Runnable target, String name)`：创建新的Thread对象

Thread类的常用方法
1. `void start()`: 启动线程，并执行对象的run()方法
2. `String getName()`: 返回线程的名称
3. `void setName(String name)`:设置该线程名称
4. `static Thread currentThread()`: 返回当前线程
5. `static void yield()`：暂停当前正在执行的线程，把执行机会让给优先级相同或更高的线程，若队列中没有同优先级的线程，忽略此方法
6. `static void sleep(long millis)`：令当前活动线程在指定时间段内放弃对CPU控制,使其他线程有机会被执行,时间到后重排队。
7. `boolean isAlive()`：返回boolean，判断线程是否还活着
8. `join()`：当某个程序执行流中调用其他线程的 join() 方法时，调用线程将被阻塞，直到 join() 方法加入的 join 线程执行完为止

继承Thread类创建线程如下：
```java
public class ThradTest extends Thread{

    @Override
    public void run() {
        System.out.println("继承Thread的多线程!");
    }

    public static void main(String[] args) {
        ThradTest t=new ThradTest();
        t.start();
    }
}
```

## 实现Runnable接口
实现Runnable接口创建多线程
```java
class RunnableTest implements Runnable {

    @Override
    public void run() {
        System.out.println("实现Runnable接口的多线程");
    }

    public static void main(String[] args) {
        RunnableTest t = new RunnableTest ();
        Thread thread = new Thread(t);
        thread.start();
    }
}
```

## 使用Callable和Future创建线程

与使用Runnable相比， Callable功能更强大
1. 相比run()方法，可以有返回值
2. 方法可以抛出异常
3. 支持泛型的返回值
4. 需要借助`FutureTask`类，比如获取返回结果

Future接口
1. 可以对具体Runnable、Callable任务的执行结果进行取消、查询是否完成、获取结果等。
2. FutrueTask是Futrue接口的唯一的实现类
3. FutureTask 同时实现了Runnable, Future接口。它既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值

使用Runnable呢Funtrue创建线程
```java
//1.创建一个实现Callable的实现类
class NumThread implements Callable{
    //2.实现call方法，将此线程需要执行的操作声明在call()中
    @Override
    public Object call() throws Exception {
        return 1+1;
    }
}


public class ThreadNew {
    public static void main(String[] args) {
        //3.创建Callable接口实现类的对象
        NumThread numThread = new NumThread();
        //4.将此Callable接口实现类的对象作为传递到FutureTask构造器中，创建FutureTask的对象
        FutureTask futureTask = new FutureTask(numThread);
        //5.将FutureTask的对象作为参数传递到Thread类的构造器中，创建Thread对象，并调用start()
        new Thread(futureTask).start();

        try {
            //6.获取Callable中call方法的返回值
            //get()返回值即为FutureTask构造器参数Callable实现类重写的call()的返回值。
            Object sum = futureTask.get();
            System.out.println("总和为：" + sum);
        } catch (InterruptedException e) {
            e.printStackTrace();
        } catch (ExecutionException e) {
            e.printStackTrace();
        }
    }

}
```

# 线程的生命周期

1. 新建： 当一个Thread类或其子类的对象被声明并创建时，新生的线程对象处于新建状态
2. 就绪：处于新建状态的线程被start()后，将进入线程队列等待CPU时间片，此时它已具备了运行的条件，只是没分配到CPU资源
3. 运行：当就绪的线程被调度并获得CPU资源时,便进入运行状态
4. 阻塞：在某种特殊情况下，比如执行了sleep()方法，将让出CPU并暂时停止自己的运行，进入阻塞状态。
5. 死亡：线程完成了它的全部工作或线程被提前强制性地中止或出现异常导致结束

## yield()和sleep()方法

yield()方法和sleep()方法有点相似，它也是Thread类提供的一个静态的方法，它也可以让当前正在执行的线程暂停，让出cpu资源给其他的线程。但是和sleep()方法不同的是，它不会进入到阻塞状态，而是进入到就绪状态。yield()方法只是让当前线程暂停一下，重新进入就绪的线程池中，让系统的线程调度器重新调度器重新调度一次，完全可能出现这样的情况：当某个线程调用yield()方法之后，线程调度器又将其调度出来重新进入到运行状态执行。

## wait()、notify()、notifyAll()

- `wait()`：令当前线程挂起并放弃CPU，前线程排队等候其他线程调用notify()或notifyAll()方法唤醒，唤醒后等待重新获得对监视器的所有权后才能继续执行。
- `notify()`：唤醒正在排队等待同步资源的线程中优先级最高者结束等待
- `notifyAll ()`：唤醒正在排队等待资源的所有线程结束等待.

这三个方法只有在synchronized方法或synchronized代码块中才能使用，否则会报`java.lang.IllegalMonitorStateException`异常。

因为这三个方法必须有锁对象调用，而任意对象都可以作为synchronized的同步锁，因此这三个方法只能在Object类中声明。

# 线程同步

当多条语句在操作同一个线程共享数据时，一个线程对多条语句只执行了一部分，还没有执行完，另一个线程参与进来执行。导致共享数据的错误。

解决办法：
对多条操作共享数据的语句，只能让一个线程都执行完，在执行过程中，其他线程不可以参与执行。

线程同步的方式有：
1. 同步方法
2. 同步代码块
3. Lock(锁)

同步方法：
```java
public synchronized void methodName(){

}
```

同步代码块：
```java
synchronized (Object){
// 需要被同步的代码；
}
```

synchronized的锁是什么？
在同步方法中，静态同步方法的锁是class（类名.class），非静态方法的锁是当前对象（this）
在同步代码块中，锁由自己指定，很多时候也是指定为this或类名.class

## Lock

从JDK 5.0开始，Java提供了更强大的线程同步机制，通过显式定义同步锁对象来实现同步。
`java.util.concurrent.locks.Lock`接口是控制多个线程对共享资源进行访问的工具。锁提供了对共享资源的独占访问，每次只能有一个线程对`Lock`对象加锁，线程开始访问共享资源之前应先获得`Lock`对象。
在实现线程安全的控制中，比较常用的是`ReentrantLock` 该类类实现了 `Lock`，它拥有与 `synchronized` 相同的并发性和内存语义，可以显式加锁、释放锁。

案例：模拟三个窗口卖100张票
```java
public class Window implements Runnable {
    int ticket = 100;
    private final ReentrantLock lock = new ReentrantLock();

    public void run() {

        while (true) {
            //加锁
            lock.lock();
            try {
                if (ticket &gt; 0) {
                    try {
                        Thread.sleep(10);
                    } catch (InterruptedException e) {
                        e.printStackTrace();
                    }
                    System.out.println(ticket--);
                } else {
                    break;
                }
            } finally {
                lock.unlock();//解锁
            }
        }
    }
}

public class ThreadLock {
    public static void main(String[] args) {
        Window w = new Window();
        Thread t1 = new Thread(t);
        Thread t2 = new Thread(t);
        Thread t3 = new Thread(t);

        t1.start();
        t2.start();
        t3.start();
    }
}
```

## synchronized和Lock比较
1. Lock是显式锁（手动开启和关闭锁），synchronized是隐式锁，出了作用域自动释放
2. Lock只有代码块锁，synchronized有代码块锁和方法锁
3. 使用Lock锁，JVM将花费较少的时间来调度线程，性能更好。并且具有更好的扩展性（提供更多的子类）
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15335106.html</id>
        <title type="text">Git常用命令-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-25T10:36:00Z</published>
        <updated>2021-09-25T10:36:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15335106.html" />
        <content type="text">每天使用 Git ，但是很多命令记不住
 ![](https://img2020.cnblogs.com/blog/1801000/202109/1801000-20210925183258916-380131722.png)


- Workspace：工作区
- Index / Stage：暂存区
- Repository：仓库区（或本地仓库）
- Remote：远程仓库



# 新建代码仓库


在当前目录新建一个Git代码库
```bash
git init
```
新建一个目录，将其初始化为Git代码库
```bash
git init [project-name]
```
下载一个项目和它的整个代码历史
```bash
git clone [url]
```


# 配置
```bash
# 显示当前的Git配置
git config --list

# 编辑Git配置文件
git config -e [--global]

# 设置提交代码时的用户信息
git config [--global] user.name "[name]"
git config [--global] user.email "[email address]"
```

# 查看信息
```bash
# 显示有变更的文件
git status

# 显示当前分支的版本历史
git log

# 显示commit历史，以及每次commit发生变更的文件
git log --stat

# 显示commit历史，以及每次commit发生变更的文件
git log --stat

# 搜索提交历史，根据关键词
git log -S [keyword]

# 显示所有提交过的用户，按提交次数排序
git shortlog -sn

显示指定文件是什么人在什么时间修改过
git blame [file]

# 显示暂存区和上一个commit的差异
git diff --cached [file]

# 显示工作区与当前分支最新commit之间的差异
git diff HEAD [file]

# 显示今天你写了多少行代码
git diff --shortstat "@{0 day ago}"

# 显示某次提交发生变化的文件
git show --name-only [commit]

# 显示某次提交时，某个文件的内容
git show [commit]:[filename]

# 显示两次提交之间的差异
git diff [first-commit] [second-commit] [file]
```

# 版本管理


显示有变更的文件
```bash
git status
```


工作区查看文件的修改
```bash
git diff &lt;file&gt;
```


清除工作区所有的修改
```bash
git checkout .
```


将工作区的修改添加到暂存区
```bash
git add &lt;file&gt;...
```


清除暂存区所有的修改
```bash
git reset .
```


将暂存区的修改提交到本地库
```bash
git commit -m "这是必填的提交信息"
```


查看提交记录
```bash
git log
```


撤销本次提交
```bash
git reset --hard HEAD~1
```


回退到指定版本 reset后的参数说明

- `mixed`：不删除工作空间改动代码，撤销commit，并且撤销git add . 操作这个为默认参数,git reset --mixed HEAD^ 和 git reset HEAD^ 效果是一样的。
- `soft`：不删除工作空间改动代码，撤销commit，不撤销git add .
- `hard`：删除工作空间改动代码，撤销commit，撤销git add . 注意完成这个操作后，就恢复到了上一次的commit状态

```bash
git reset --hard 版本号
```


# 分支管理


列出本地所有分支


```bash
git branch
```


列出远程所有分支


```bash
git branch -a
```


创建分支并切换


```bash
git checkout -b 分支名
```


合并分支
比如 `master` 分支要合并 `dev` 分支,首先要切换到 `master` 分支


```bash
git merge dev
```

推送分支到远程库，如果在主分支上可以直接省略 `origin` 及 `master`，直接 `git push`


```bash
git push origin 分支名
```


删除本地分支


```bash
git branch -d 分支名
```


删除远程分支


```bash
git push origin -d 分支名
```

# 标签管理
```
# 列出所有tag
$ git tag

# 新建一个tag在当前commit
$ git tag [tag]

# 新建一个tag在指定commit
$ git tag [tag] [commit]

# 删除本地tag
$ git tag -d [tag]

# 删除远程tag
$ git push origin :refs/tags/[tagName]

# 查看tag信息
$ git show [tag]

# 提交指定tag
$ git push [remote] [tag]

# 提交所有tag
$ git push [remote] --tags

# 新建一个分支，指向某个tag
$ git checkout -b [branch] [tag]
```


# 撤销


```bash
# 恢复暂存区的指定文件到工作区
$ git checkout [file]

# 恢复某个commit的指定文件到暂存区和工作区
$ git checkout [commit] [file]

# 恢复暂存区的所有文件到工作区
$ git checkout .

# 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变
$ git reset [file]

# 重置暂存区与工作区，与上一次commit保持一致
$ git reset --hard

# 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变
$ git reset [commit]

# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致
$ git reset --hard [commit]

# 重置当前HEAD为指定commit，但保持暂存区和工作区不变
$ git reset --keep [commit]

# 新建一个commit，用来撤销指定commit
# 后者的所有变化都将被前者抵消，并且应用到当前分支
$ git revert [commit]

# 暂时将未提交的变化移除，稍后再移入
$ git stash
$ git stash pop
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15335122.html</id>
        <title type="text">Java Stream API-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-25T10:44:00Z</published>
        <updated>2021-09-25T10:44:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15335122.html" />
        <content type="text"># Stream API介绍
Stream API是Java8中处理集合的关键概念，它可以对集合执行非常复杂的操作：查找、过滤、映射等数据操作。

当我们使用一个流的时候，通常包括三个基本步骤：
1. 获取一个数据源（source）
1. 数据转换
1. 执行操作获取想要的结果。

每次转换原有 Stream 对象不改变，返回一个新的 Stream 对象（可以有多次转换），这就允许对其操作可以像链条一样排列。


# Stream实例化
一般常见创建Stream的三种方式


第一种：使用`Collection`下的`stream()`方法
```java
List&lt;String&gt; strings = new ArrayList&lt;&gt;();
Stream&lt;String&gt; stream = strings.stream();
```


第二种：使用**Arrays** 中的 **stream()** 静态方法，将数组转成流。
```java
int[] ints = new int[]{1, 3, 2, 6, 4};
IntStream stream = Arrays.stream(ints);
```


第三种：通过**Stream**类的静态方法**of()**。接收任意数量的参数。
```java
Stream&lt;Integer&gt; integerStream = Stream.of(1, 2, 3, 4, 5);
```


# 中间操作
Stream操作分为**中间**操作和**终止**操作，中间操作返回Stream
## 筛选与切片
**filter**：过滤流中的某些元素
**limit(n)**：获取n个元素
**skip(n)**：跳过n元素，配合limit(n)可实现分页
**distinct**：通过流中元素的 hashCode() 和 equals() 去除重复元素
```java
List&lt;Integer&gt; list = Arrays.asList(6, 4, 6, 7, 3, 9, 8, 10, 12, 14, 14);

//filter过滤去掉集合中小于7的数
list.stream().filter(integer -&gt; integer &gt;= 7).forEach(System.out::println);

//去掉重复元素
list.stream().distinct().forEach(integer -&gt; System.out.println(integer));

//跳过前两个元素
list.stream().skip(2).forEach(System.out::println);

//获取三个元素
list.stream().limit(3).forEach(System.out::println);
```


## 映射
**map**：接收一个函数作为参数，将元素转换成其他形式或提取信息，该函数会被应用到每一个元素上，并将其映射成一个新的元素。**
```java
        List&lt;Integer&gt; list = Arrays.asList(1,2,3,4,5);

        //将集合中的每一个数加1
        list.stream().map(integer -&gt; integer+1).forEach(System.out::println);
```
**flatMap**：接收一个函数作为参数，将流中的每一个值都换成一个流，然后把所有流连接成一个流。
```java
public class StreamAPI {

    public static void main(String[] args) {

        List&lt;String&gt; strings = Arrays.asList("abc", "def", "hij");

        //List&lt;Character&gt; collect = strings.stream().flatMap(StreamAPI::forStrToStream).collect(Collectors.toList());
        List&lt;Character&gt; characterList = strings.stream().flatMap(s -&gt; forStrToStream(s)).collect(Collectors.toList());
        System.out.println(characterList);//[a, b, c, d, e, f, h, i, j]
    }

    //将字符串中的每一个字符构成的集合转换成Stream实例
    public static Stream&lt;Character&gt; forStrToStream(String str) {
        ArrayList&lt;Character&gt; characters = new ArrayList&lt;&gt;();
        for (Character c : str.toCharArray()) {
            characters.add(c);
        }
        return characters.stream();
    }
}
```


## 排序
**sorted()**：自然排序，流中元素需实现Comparable接口
**sorted(Comparator com)**：定制排序，自定义Comparator排序器
```java
List&lt;Integer&gt; list = Arrays.asList(6, 3, 4, 9);

//自然排序 Integer类自身已实现Compareable接口，所以可以自然排序
list.stream().sorted().forEach(integer -&gt; System.out.println(integer));

//定制排序
list.stream().sorted((i1, i2) -&gt; i1 - i2).forEach(System.out::println);
```


# 终止操作


## 匹配、聚合操作


**allMatch**：接收一个 Predicate 函数，当流中每个元素都符合该断言时才返回true，否则返回false
**noneMatch**：接收一个 Predicate 函数，当流中每个元素都不符合该断言时才返回true，否则返回false
**anyMatch**：接收一个 Predicate 函数，只要流中有一个元素满足该断言则返回true，否则返回false
**findFirst**：返回流中第一个元素
**findAny**：返回流中的任意元素
**count**：返回流中元素的总个数
**max**：返回流中元素最大值
**min**：返回流中元素最小值
```java
List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5);

boolean allMatch = list.stream().allMatch(e -&gt; e &gt; 10); //false
boolean noneMatch = list.stream().noneMatch(e -&gt; e &gt; 10); //true
boolean anyMatch = list.stream().anyMatch(e -&gt; e &gt; 4);  //true

Integer findFirst = list.stream().findFirst().get(); //1
Integer findAny = list.stream().findAny().get(); //1

long count = list.stream().count(); //5
Integer max = list.stream().max(Integer::compareTo).get(); //5
```


## 规约
Optional&lt;T&gt; reduce(BinaryOperator&lt;T&gt; accumulator)：有初始值，可以将流中的元素反复结合起来，得到一个值，返回一个T
T reduce(T identity, BinaryOperator&lt;T&gt; accumulator)：可以将流中的元素反复结合起来，得到一个值，返回一个T

```java
List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10);

//初始值为10
Integer v1 = list.stream().reduce(10, (x1, x2) -&gt; x1 + x2);
System.out.println(v1);  //65

//没有初始值
Integer v = list.stream().reduce((x1, x2) -&gt; x1 + x2).get();
System.out.println(v);   // 55

```


## 收集


**collect(Collector)**：将Stream转换为其他形式。接收一个Collector接口的实现，用于给Stream中元素做汇总的方法
```java
List&lt;Integer&gt; list = Arrays.asList(6, 4, 6, 7, 3, 9, 8, 10, 12, 14, 14);

//收集为list集合
List&lt;Integer&gt; toList = list.stream().filter(integer -&gt; integer &gt;= 7).collect(Collectors.toList());

//收集为set集合
Set&lt;Integer&gt; toSet = list.stream().distinct().collect(Collectors.toSet());
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15335219.html</id>
        <title type="text">Mybatis入门学习-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-25T11:22:00Z</published>
        <updated>2021-09-25T11:22:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15335219.html" />
        <content type="text"># #{ } 和 ${ } 取值的区别


```
#{} : 是以预编译的形式，将参数设置到sql语句中，防止sql注入；

${} : 取出的值会直接拼接在sql语句中，会有安全问题；
```

# resultMap自定义结果

`resultType` 和 `resultMap` 只能同时用一个
```xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE mapper
 PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
 "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;

&lt;mapper namespace="com.garcon.dao.StudentMapper"&gt;

	&lt;!--自定义某个javaBean的封装规则

	type：自定义规则的Java类型

	id:唯一id方便引用
	  --&gt;
	&lt;resultMap type="com.garcon.bean.Student" id="myStudent"&gt;

		&lt;!--指定主键列的封装规则

		id定义主键会底层有优化

		column：指定哪一列

		property：指定对应的javaBean属性
		  --&gt;
		&lt;id column="sid" property="sid"/&gt;

		&lt;!-- 定义普通列封装规则 --&gt;
		&lt;result column="last_name" property="lastName"/&gt;

		&lt;!-- 其他不指定的列会自动封装：我们只要写resultMap就把全部的映射规则都写上。 --&gt;
		&lt;result column="gender" property="gender"/&gt;
		&lt;result column="hobby" property="hobby"/&gt;
	&lt;/resultMap&gt;

	&lt;!-- resultMap:自定义结果集映射规则；  --&gt;
	&lt;select id="getStudentById" resultMap="myStudent"&gt;
		select * from student where sid=#{sid}
	&lt;/select&gt;

&lt;/mapper&gt;
```


# 关联查询

查询 `学生信息` 的时候把对应的 `班级信息` 也查询出来

学生信息
```java
package com.garcon.bean;

public class Student {

	private Integer sid;
	private String lastName;
	private String gender;
	private String hobby;
	private Sclass sclass;//班级信息

	...
	}
```


班级信息
```
package com.garcon.bean;

public class Sclass {

	private Integer cid;//班级id
	private String cName;//班级名称

	...
	}
```


Mapper接口
```java
package com.garcon.dao;

public interface StudentMapper {

    //以sid查询学生信息
    public Student getStudentById(Integer sid);
}
```


`resultMap` 级联属性
```xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE mapper
 PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
 "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;

&lt;mapper namespace="com.garcon.dao.StudentMapper"&gt;

    &lt;!--联合查询：级联属性封装结果集 --&gt;
	&lt;resultMap type="com.garcon.bean.Student" id="mystudent"&gt;
		&lt;id column="sid" property="sid"/&gt;
		&lt;result column="last_name" property="lastName"/&gt;
		&lt;result column="gender" property="gender"/&gt;
		&lt;result column="hobby" property="hobby"/&gt;
		&lt;!--关联列用级联属性--&gt;
		&lt;result column="cid" property="sclass.cid"/&gt;
		&lt;result column="cname" property="sclass.name"/&gt;
	&lt;/resultMap&gt;

	&lt;!--级联查询--&gt;
	&lt;select id="getStudentById" resultMap="myStudent"&gt;
		SELECT
    		s.sid,
    		s.last_name,
    		s.gender,
    		s.hobby,
    		c.cid,
    		c.cname
		FROME
		    student s,
		    sclass c
		WHERE s.sid=c.cid
		  AND sid=#{sid}
	&lt;/select&gt;

&lt;/mapper&gt;
```

或 以下
`resultMap` 的 `association` 属性
```xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE mapper
 PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
 "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;

&lt;mapper namespace="com.garcon.dao.StudentMapper"&gt;

    &lt;!--使用association定义关联的单个对象的封装规则--&gt;
	&lt;resultMap type="com.garcon.bean.Student" id="myStudent"&gt;
		&lt;id column="sid" property="sid"/&gt;
		&lt;result column="last_name" property="lastName"/&gt;
		&lt;result column="gender" property="gender"/&gt;
		&lt;result column="hobby" property="hobby"/&gt;

		&lt;!--
		association:可以指定联合的javaBean对象 property="sclass"：指定哪个属性是联合的对象
		    javaType:指定这个属性对象的类型[不能省略]
		--&gt;
		&lt;association property="sclass" javaType="com.garcon.bean.Sclass"&gt;
			&lt;id column="cid" property="cid"/&gt;
			&lt;result column="cname" property="cname"/&gt;
		&lt;/association&gt;
	&lt;/resultMap&gt;

	&lt;!--关联查询--&gt;
	&lt;select id="getStudentById" resultMap="myStudent"&gt;
		SELECT
    		s.sid,
    		s.last_name,
    		s.gender,
    		s.hobby,
    		c.cid,
    		c.cname
		FROME
		    student s,
		    sclass c
		WHERE s.sid=c.cid
		  AND sid=#{sid}
	&lt;/select&gt;

&lt;/mapper&gt;
```


# 关联查询 collection

查询班级信息的同时查出班级所对应的学生信息

学生类
```java
package com.garcon.bean;

public class Student {

	private Integer sid;
	private String lastName;
	private String gender;
	private String hobby;
	private Sclass sclass;//班级信息

	...
	}
```


班级类
```java
package com.garcon.bean;

public class Sclass {

	private Integer cid;//班级id
	private String cName;//班级名称
	private List&lt;Student&gt; students;

	...
	}
```


Mapper班级接口
```java
package com.garcon.dao;

public interface SclassMapper {

    //以班级id查询班级
    public Sclass getSclassById(Integer cid);
}
```


sclassMapper.xml
```xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE mapper
 PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
 "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;

&lt;mapper namespace="com.garcon.dao.SclassMapper"&gt;

 &lt;!--嵌套结果集的方式，使用collection标签定义关联的集合类型的属性封装规则  --&gt;
	&lt;resultMap type="com.garcon.bean.Sclass" id="Mysclass"&gt;
		&lt;id column="cid" property="cid"/&gt;
		&lt;result column="cname" property="cName"/&gt;
		&lt;!--
			collection定义关联集合类型的属性的封装规则
			ofType:指定集合里面元素的类型
		--&gt;
		&lt;collection property="students" ofType="com.garcon.bean.Student"&gt;
			&lt;!-- 定义这个集合中元素的封装规则 --&gt;
			&lt;id column="sid" property="sid"/&gt;
			&lt;result column="last_name" property="lastName"/&gt;
			&lt;result column="gender" property="gender"/&gt;
			&lt;result column="hobby" property="hobby"/&gt;
		&lt;/collection&gt;
	&lt;/resultMap&gt;

	&lt;select id="getSclassById" resultMap="Mysclass"&gt;
		SELECT
	        s.sid,
	        s.last_name,
	        s.gender,
	        s.hobyy,
	        c.cid
	        c.cname
		FROM
		    student s
		LEFT JOIN
		    sclass c
		ON s.cid=c.cid
		WHERE c.cid=#{cid}
	&lt;/select&gt;

&lt;/mapper&gt;
```


# 分步查询 association

先以学生的 `学号` 查询学生信息，再以 `学生信息中的班级编号` 查询班级信息

班级接口
```java
package com.garcon.dao;

public interface Sclass {

    //以班级id查询班级信息
    public Sclass getSclasstById(Integer cid);
}
```


- `StudentMapper.java` 学生接口



```java
package com.garcon.dao;

public interface StudentMapper {

    //以sid查询学生信息
    public Student getStudentById(Integer sid);
}
```

sclassMapper.xml
```xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE mapper
 PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
 "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;

&lt;mapper namespace="com.garcon.dao.SclassMapper"&gt;

	&lt;!--以班级号查询班级信息--&gt;
	&lt;select id="getSclassById" resultType="com.garcon.bean.Sclass"&gt;
        SELECT * FROM sclass WHERE cid=#{cid}
	&lt;/select&gt;

&lt;/mapper&gt;
```


studentMapper.xml
```xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE mapper
 PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
 "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;

&lt;mapper namespace="com.garcon.dao.StudentMapper"&gt;

    &lt;!--
        使用association进行分步查询：
		    1、先按照学生id查询学生工信息
	    	2、根据查询学生信息中的cid值去班级表查出班级信息
	    	3、班级设置到学生中；
	 --&gt;

	 &lt;resultMap type="com.garcon.bean.Student" id="Mystudent"&gt;
	 	&lt;id column="sid" property="sid"/&gt;
	 	&lt;result column="last_name" property="lastName"/&gt;
	 	&lt;result column="gender" property="gender"/&gt;
	 	&lt;result column="hobby" property="hobby"/&gt;

	 	&lt;!--
	 	    association:定义关联对象的封装规则
	 	    	select:表明当前属性是调用select指定的方法查出的结果
	 	    	column:指定将哪一列的值传给这个方法

	 	   	流程：使用select指定的方法（传入column指定的这列参数的值）查出对象，并封装给property指定的属性
	 	 --&gt;
 		&lt;association property="dept" select="com.garcon.dao.SclassMapper.getSclassById" column="cid"&gt;
 		&lt;/association&gt;
	 &lt;/resultMap&gt;

	 &lt;select id="getStudentById" resultMap="Mystudent"&gt;
	 	SELECT * FROM student WHERE sid=#{sid}
	 &lt;/select&gt;

&lt;/mapper&gt;
```


# 分步查询 collection

先以 `班级编号` 查询班级信息，再以 `班级编号` 查询班级的所有学生信息

SclassMapper班级接口
```java
package com.garcon.dao;

public interface Sclass {

    //以班级id查询班级信息
    public Sclass getSclasstById(Integer cid);
}
```


StudentMapper学生接口
```java
package com.garcon.dao;

public interface StudentMapper {

    //以班级编号查询学生信息
    public List&lt;Student&gt; getStudentByClassId(Integer sid);
}
```

sclassMapper.xml
```xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE mapper
 PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
 "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;

&lt;mapper namespace="com.garcon.dao.SclassMapper"&gt;

    &lt;!-- collection：分段查询 --&gt;
	&lt;resultMap type="com.garcon.bean.Sclass" id="mySclass"&gt;
		&lt;id column="cid" property="cid"/&gt;
		&lt;id column="cname" property="cName"/&gt;
		&lt;collection property="students" select="com.garcon.dao.StudentMapper.getStudentByClassId" column="cid" fetchType="lazy"&gt;&lt;/collection&gt;
	&lt;/resultMap&gt;

	&lt;select id="getSclasstById" resultMap="mySclass"&gt;
		select cid,cName from sclass where cid=#{cid}
	&lt;/select&gt;

	&lt;!--
	    扩展： 多列的值传递过去： 将多列的值封装map传递； column="{key1=column1,key2=column2}"
			如：
			&lt;collection property="" select="" column="{key1=column1,key2=column2}" fetchType="lazy"&gt;
    		&lt;/collection&gt; fetchType="lazy"：表示使用延迟加载；

				- lazy：延迟
				- eager：立即

	 --&gt;

&lt;/mapper&gt;
```


studentMapper.xml
```xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE mapper
 PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
 "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;

&lt;mapper namespace="com.garcon.dao.StudentMapper"&gt;

	&lt;!--以班级编号查询所有学生--&gt;
	 &lt;select id="getStudentById" resultType="com.garcon.bean.Student"&gt;
	 	SELECT * FROM student WHERE class_id=#{class_id}
	 &lt;/select&gt;

&lt;/mapper&gt;
```


# 分步查询 延迟加载

适用情况：假如查看学生信息的时候不加载班级信息，当需要查看学生的班级信息的时候再加载班级信息


- 在分步查询的基础上，在mybatis的全局配置文件的settings设置项中添加如下设置即可



```xml
&lt;settings&gt;
		&lt;!--显示的指定每个我们需要更改的配置的值，即使他是默认的。防止版本更新带来的问题  --&gt;
		&lt;setting name="lazyLoadingEnabled" value="true"/&gt;
		&lt;setting name="aggressiveLazyLoading" value="false"/&gt;
&lt;/settings&gt;
```


# 鉴别器 discriminator


鉴别器：mybatis可以使用discriminator判断某列的值，然后根据某列的值改变封装行为


-  如果查出的是女生：就把班级信息查询出来，否则不查询；如果是男生，把last_name这一列的值赋值给 hobby;
-  `studentMapper.xml`



```xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE mapper
 PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
 "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;

&lt;mapper namespace="com.garcon.dao.StudentMapper"&gt;
    &lt;!--
		鉴别器：mybatis可以使用discriminator判断某列的值，然后根据某列的值改变封装行为
		封装Student：
			如果查出的是女生：就把班级信息查询出来，否则不查询；
			如果是男生，把last_name这一列的值赋值给 hobby;
	 --&gt;
	 &lt;resultMap type="com.garcon.bean.Student" id="mystudent"&gt;
	 	&lt;id column="sid" property="sid"/&gt;
	 	&lt;result column="last_name" property="lastName"/&gt;
	 	&lt;result column="gender" property="gender"/&gt;
	 	&lt;result column="hobby" property="hobby"/&gt;

	 	&lt;!--
	 		column：指定判定的列名
	 		javaType：列值对应的java类型
	 		--&gt;
	 	&lt;discriminator javaType="string" column="gender"&gt;
	 		&lt;!--女生  resultType:指定封装的结果类型；不能缺少。/resultMap--&gt;
	 		&lt;case value="女" resultType="com.garcon.bean.Student"&gt;
	 			&lt;association property="sclass" select="com.garcon.dao.SclassMapper.getSclasstById" column="class_id"&gt;
		 		&lt;/association&gt;
	 		&lt;/case&gt;
	 		&lt;!--男生 ;如果是男生，把last_name这一列的值赋值给hobby; --&gt;
	 		&lt;case value="男" resultType="com.garcon.bean.Student"&gt;
		 		&lt;id column="id" property="id"/&gt;
			 	&lt;result column="last_name" property="lastName"/&gt;
			 	&lt;result column="last_name" property="hobby"/&gt;
			 	&lt;result column="gender" property="gender"/&gt;
	 		&lt;/case&gt;
	 	&lt;/discriminator&gt;
	 &lt;/resultMap&gt;
```


- `sclassMapper.xml`



```xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE mapper
 PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
 "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;

&lt;mapper namespace="com.garcon.dao.SclassMapper"&gt;

	&lt;!--以班级号查询班级信息--&gt;
	&lt;select id="getSclassById" resultType="com.garcon.bean.Sclass"&gt;
        SELECT * FROM sclass WHERE cid=#{cid}
	&lt;/select&gt;

&lt;/mapper&gt;
```


# 动态SQL


## if


```xml
&lt;!--test:判断表达式(OGNL)--&gt;
&lt;if test=""&gt;&lt;/if&gt;

&lt;!--
    应用场境：按条件查询学生，
        如果参数中有sid则查询条件带上sid
        如果参数中有last_name则查询条件带上last_name
        如果参数中有gender则查询条件带上gender
--&gt;

&lt;select id="getStudent" resultType="com.garcon.dao.StudentMapper"&gt;
	 	select * from student
	 	&lt;!-- where --&gt;
	 	&lt;where&gt;
		 	&lt;if test="sid!=null"&gt; sid=#{sid}
		 	&lt;/if&gt;
		 	&lt;if test="lastName!=null AND lastName!=''"&gt;
		 		and last_name like #{lastName}
		 	&lt;/if&gt;
		 	&lt;if test="hobby!=null and hobby.trim()!=''"&gt;
		 		and hobby=#{hobby}
		 	&lt;/if&gt;
		 	&lt;!-- ognl会进行字符串与数字的转换判断  "0"==0 --&gt;
		 	&lt;if test="gender==0 or gender==1"&gt;
		 	 	and gender=#{gender}
		 	&lt;/if&gt;
	 	&lt;/where&gt;
&lt;/select&gt;
```


## where


- 去除查询条件中多余的第一个 `and` 或 `or`



```xml
&lt;!--
    检查以下sql语句
--&gt;
&lt;select id="getStudent" resultType="com.garcon.dao.StudentMapper"&gt;
	 	select * from student
	 	where
		 	&lt;if test="sid!=null"&gt; sid=#{sid}
		 	&lt;/if&gt;
		 	&lt;if test="lastName!=null AND lastName!=''"&gt;
		 		and last_name like #{lastName}
		 	&lt;/if&gt;
&lt;/select&gt;
&lt;!--
    可以发现，当以上参数 sid 为空时，sql语句就变成了：
        select * from student where and last_name=?
        多出的 and 语法错误;
    解决以上情况可以加标签&lt;where&gt;&lt;/where&gt;:
    把所有的&lt;if&gt;&lt;/if&gt;条件都放在&lt;where&gt;&lt;/where&gt;标签中，可以去除第一个 and 和 or 如下：
--&gt;
&lt;select id="getStudent" resultType="com.garcon.dao.StudentMapper"&gt;
	 	select * from student
	 	&lt;where&gt;
		 	&lt;if test="sid!=null"&gt; sid=#{sid}
		 	&lt;/if&gt;
		 	&lt;if test="lastName!=null AND lastName!=''"&gt;
		 		and last_name like #{lastName}
		 	&lt;/if&gt;
		 &lt;/where&gt;
&lt;/select&gt;
```


## trim


```xml
&lt;!--
    检查以下sql语句
--&gt;
&lt;select id="getStudent" resultType="com.garcon.dao.StudentMapper"&gt;
	 	select * from student
	 	where
		 	&lt;if test="sid!=null"&gt; sid=#{sid} and
		 	&lt;/if&gt;
		 	&lt;if test="lastName!=null AND lastName!=''"&gt;
		 		last_name like #{lastName}
		 	&lt;/if&gt;
&lt;/select&gt;

&lt;!--
    可以发现，当以上参数 lastName 为空时，sql语句就变成了：
        select * from student where sid=? and
        结尾多出的 and 语法错误;
    解决以上情况可以加标签&lt;trim&gt;&lt;/trim&gt;:

        &lt;trim prefix="" suffixOverrides="" suffix="" suffixOverrides=""&gt;&lt;/trim&gt;

        后面多出的and或者or where标签不能解决 prefix="":前缀：trim标签体中是整个字符串拼串 后的结果。
    	 			prefix给拼串后的整个字符串加一个前缀 prefixOverrides="":
    	 			前缀覆盖： 去掉整个字符串前面多余的字符 suffix="":后缀
    	 			suffix给拼串后的整个字符串加一个后缀 suffixOverrides=""
    	 			后缀覆盖：去掉整个字符串后面多余的字符
    如下：
--&gt;
&lt;select id="getStudent" resultType="com.garcon.dao.StudentMapper"&gt;
	 	select * from student
	 	&lt;trim prefix="where" suffixOverrides="and"&gt;
		 	&lt;if test="sid!=null"&gt; sid=#{sid} and
		 	&lt;/if&gt;
		 	&lt;if test="lastName!=null AND lastName!=''"&gt;
		 		last_name like #{lastName}
		 	&lt;/if&gt;
		 &lt;/trim&gt;
&lt;/select&gt;
```


## choose


```xml
&lt;!--
    使用场景：
        如果参数中的id不为空就以id为条件查询，如果name不为空就已以name做查询条件
        如下：
--&gt;
&lt;select id="getStudent" resultType="com.garcon.dao.StudentMapper"&gt;
	 	select * from student
    &lt;where&gt;
	 	&lt;!-- 如果带了id就用id查，如果带了lastName就用lastName查;只会进入其中一个 --&gt;
        &lt;choose&gt;
	 		&lt;when test="id!=null"&gt; sid=#{sid}
	 		&lt;/when&gt;
	 		&lt;when test="lastName!=null"&gt;
	 				last_name like #{lastName}
	 		&lt;/when&gt;
	 		&lt;when test="hobby!=null"&gt;
	 				hobby = #{hobby}
	 		&lt;/when&gt;
	 			&lt;!--如果以上条件都不满足，使用如下条件--&gt;
	 		&lt;otherwise&gt;
	 				gender = '女'
            &lt;/otherwise&gt;
        &lt;/choose&gt;
    &lt;/where&gt;
&lt;/select&gt;
```


## update-set


如果javaBean中哪个属性带了值就更新那个字段


```xml
&lt;update id="updateStudent"&gt;
	 	&lt;!-- Set标签的使用 --&gt;
	 	update student
		&lt;set&gt;
			&lt;if test="lastName!=null"&gt; last_name=#{lastName},
			&lt;/if&gt;
			&lt;if test="hobby!=null"&gt; hobby=#{hobby},
			&lt;/if&gt;
			&lt;if test="gender!=null"&gt; gender=#{gender}
			&lt;/if&gt;
		&lt;/set&gt;
		where id=#{id}
&lt;/update&gt;
```


## update-trim


```xml
&lt;update id="updateStudent"&gt;
		update student
		&lt;trim prefix="set" suffixOverrides=","&gt;
			&lt;if test="lastName!=null"&gt; last_name=#{lastName},
			&lt;/if&gt;
			&lt;if test="email!=null"&gt; email=#{email},
			&lt;/if&gt;
			&lt;if test="gender!=null"&gt; gender=#{gender}
			&lt;/if&gt;
		&lt;/trim&gt;
		where id=#{id}
	 &lt;/update&gt;
```


## select-foreach


```xml
&lt;select id="getStudent" resultType="com.garcon.bean.Student"&gt;
	 	select * from student
	 	&lt;!--
	 		collection：指定要遍历的集合：
	 			list类型的参数会特殊处理封装在map中，map的key就叫list
	 		item：将当前遍历出的元素赋值给指定的变量
	 		separator:每个元素之间的分隔符
	 		open：遍历出所有结果拼接一个开始的字符
	 		close:遍历出所有结果拼接一个结束的字符
	 		index:索引。遍历list的时候是index就是索引，item就是当前值
	 				      遍历map的时候index表示的就是map的key，item就是map的值

	 		#{变量名}就能取出变量的值也就是当前遍历出的元素
	 	  --&gt;
	 	&lt;foreach collection="ids" item="item_id" separator="," open="where id in(" close=")"&gt;
	 		#{item_id}
	 	&lt;/foreach&gt;
	 &lt;/select&gt;
```


## insert-foreach


批量插入


```xml
&lt;!--
	 MySQL下：
	 第一种方法
	 可以foreach遍历   mysql支持values(),(),()语法--&gt;
	&lt;insert id="addStudents"&gt;
	 	insert into student(last_name,gender,hobby,class_id)
		values
		&lt;foreach collection="students" item="student" separator=","&gt;
			(#{student.lastName},#{student.gender},#{student.hobby},#{student.sclass.cid})
		&lt;/foreach&gt;
	 &lt;/insert&gt;

&lt;!--
    第二种方法 这种方式需要数据库连接属性allowMultiQueries=true；
	 	这种分号分隔多个sql可以用于其他的批量操作（删除，修改） --&gt;
    &lt;insert id="addEmps"&gt;
	 	&lt;foreach collection="emps" item="emp" separator=";"&gt;
	 		insert into student(last_name,gender,hobby,class_id)
	 		values((#{student.lastName},#{student.gender},#{student.hobby},#{student.sclass.cid})
	 	&lt;/foreach&gt;
	 &lt;/insert&gt;



&lt;!--
    Oracle数据库批量保存：
	 	Oracle不支持values(),(),()
	 	Oracle支持的批量方式
	 	1、多个insert放在begin - end里面
	 		begin
			    insert into employees(employee_id,last_name,email)
			    values(employees_seq.nextval,'test_001','test_001@atguigu.com');
			    insert into employees(employee_id,last_name,email)
			    values(employees_seq.nextval,'test_002','test_002@atguigu.com');
			end;

		2、利用中间表：
			insert into employees(employee_id,last_name,email)
		       select employees_seq.nextval,lastName,email from(
		              select 'test_a_01' lastName,'test_a_e01' email from dual
		              union
		              select 'test_a_02' lastName,'test_a_e02' email from dual
		              union
		              select 'test_a_03' lastName,'test_a_e03' email from dual
		       )

		 oracle第一种批量方式
	 --&gt;
	 &lt;insert id="addEmps" databaseId="oracle"&gt;
	 	&lt;foreach collection="emps" item="emp" open="begin" close="end;"&gt;
	 		insert into employees(employee_id,last_name,email)
			    values(employees_seq.nextval,#{emp.lastName},#{emp.email});
	 	&lt;/foreach&gt;
	 &lt;/insert&gt;

	 	&lt;!-- oracle第二种批量方式  --&gt;
	 &lt;insert id="addEmps" databaseId="oracle"&gt;
	 	insert into employees(employee_id,last_name,email)
            &lt;foreach collection="emps" item="emp" separator="union" open="select employees_seq.nextval,lastName,email from(" close=")"&gt;
	 				select #{emp.lastName} lastName,#{emp.email} email from dual
	 		&lt;/foreach&gt;
	 &lt;/insert&gt;
```


# 获取自增主键的值


方式一 : 使用insert标签的属性`useGeneratedKeys="true" keyProperty="id"`


```xml
&lt;insert id="addUser" useGeneratedKeys="true" keyProperty="id"&gt;
        insert into user(username,password,email) values(#{username},#{password},#{email})
&lt;/insert&gt;
```


方式二 : 插入时先查询将要插入数据的自增id值


```xml
 &lt;insert id="addUser" useGeneratedKeys="true" keyProperty="id"&gt;
        &lt;selectKey order="AFTER" keyProperty="id" resultType="int"&gt;
            select last_insert_id()
        &lt;/selectKey&gt;
        insert into user(username,password,email) values(#{username},#{password},#{email})
    &lt;/insert&gt;
```


# 参数处理


## 单个参数

可以接受基本类型，对象类型，集合类型的值。这种情况 MyBatis可直接使用这个参数，不需要经过任何处理。


## 多个参数


任意多个参数，都会被MyBatis重新包装成一个Map传入。Map的key是param1，param2，0，1…，值就是参数的值。


## 命名参数


为参数使用@Param起一个名字，MyBatis就会将这些参数封装进map中，key就是我们自己指定的名字


## POJO


当这些参数属于我们业务POJO时，我们直接传递POJO


## Map

我们也可以封装多个参数为map，直接传递

**注意 :** 当参数是一个Connection , List , Array数组时, 参数会封装成一个Map , key值为 : connection , list , array .
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15335247.html</id>
        <title type="text">MyBatis-Plus学习使用-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-25T11:33:00Z</published>
        <updated>2021-09-25T11:33:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15335247.html" />
        <content type="text"># MyBatis-Plus简介


MyBatis-Plus（简称 MP）是一个 MyBatis 的增强工具，在 MyBatis 的基础上只做增强不做改变，为简化开发、提高效率而生。


# 特性


-  **无侵入**：只做增强不做改变，引入它不会对现有工程产生影响，如丝般顺滑
-  **损耗小**：启动即会自动注入基本 CURD，性能基本无损耗，直接面向对象操作
-  **强大的 CRUD 操作**：内置通用 Mapper、通用 Service，仅仅通过少量配置即可实现单表大部分 CRUD 操作，更有强大的条件构造器，满足各类使用需求
-  **支持 Lambda 形式调用**：通过 Lambda 表达式，方便的编写各类查询条件，无需再担心字段写错
-  **支持主键自动生成**：支持多达 4 种主键策略（内含分布式唯一 ID 生成器 - Sequence），可自由配置，完美解决主键问题
-  **支持 ActiveRecord 模式**：支持 ActiveRecord 形式调用，实体类只需继承 Model 类即可进行强大的 CRUD 操作
-  **支持自定义全局通用操作**：支持全局通用方法注入（ Write once, use anywhere ）
-  **内置代码生成器**：采用代码或者 Maven 插件可快速生成 Mapper 、 Model 、 Service 、 - - Controller 层代码，支持模板引擎，更有超多自定义配置等您来使用
-  **内置分页插件**：基于 MyBatis 物理分页，开发者无需关心具体操作，配置好插件之后，写分页等同于普通 List 查询
-  **分页插件支持多种数据库**：支持 MySQL、MariaDB、Oracle、DB2、H2、HSQL、SQLite、Postgre、SQLServer 等多种数据库
-  **内置性能分析插件**：可输出 Sql 语句以及其执行时间，建议开发测试时启用该功能，能快速揪出慢查询
-  **内置全局拦截插件**：提供全表 delete 、 update 操作智能分析阻断，也可自定义拦截规则，预防误操作



# 开始使用


通过一个简单的 Demo 来阐述 MyBatis-Plus 的强大功能


现有一张 User 表，其表结构如下：


```sql
DROP TABLE IF EXISTS user;

CREATE TABLE user
(
	id BIGINT(20) NOT NULL COMMENT '主键ID',
	name VARCHAR(30) NULL DEFAULT NULL COMMENT '姓名',
	age INT(11) NULL DEFAULT NULL COMMENT '年龄',
	email VARCHAR(50) NULL DEFAULT NULL COMMENT '邮箱',
	PRIMARY KEY (id)
);
```


其对应的数据库 Data 脚本如下：


```sql
DELETE FROM user;

INSERT INTO user (id, name, age, email) VALUES
(1, 'Jone', 18, 'test1@baomidou.com'),
(2, 'Jack', 20, 'test2@baomidou.com'),
(3, 'Tom', 28, 'test3@baomidou.com'),
(4, 'Sandy', 21, 'test4@baomidou.com'),
(5, 'Billie', 24, 'test5@baomidou.com');
```


pom.xml 如下


```xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;version&gt;2.3.4.RELEASE&lt;/version&gt;
        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;
    &lt;/parent&gt;
    &lt;groupId&gt;com.example&lt;/groupId&gt;
    &lt;artifactId&gt;demo-mybatis-plus&lt;/artifactId&gt;
    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
    &lt;name&gt;demo-mybatis-plus&lt;/name&gt;
    &lt;description&gt;Demo project for Spring Boot&lt;/description&gt;

    &lt;properties&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
    &lt;/properties&gt;

    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;mysql&lt;/groupId&gt;
            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;optional&gt;true&lt;/optional&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;com.baomidou&lt;/groupId&gt;
            &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;
            &lt;version&gt;3.4.0&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
            &lt;exclusions&gt;
                &lt;exclusion&gt;
                    &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt;
                    &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt;
                &lt;/exclusion&gt;
            &lt;/exclusions&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;

&lt;/project&gt;
```
###
添加配置
application.yml


```yml
# 数据源配置
spring:
  datasource:
    username: root
    password: root123
    url: jdbc:mysql://localhost:3306/test?serverTimezone=GMT%2B8&amp;characterEncoding=utf-8
    driver-class-name: com.mysql.cj.jdbc.Driver

# MyBatis-plus配置
mybatis-plus:
  mapper-locations: classpath*:mapper/*Mapper.xml
  type-aliases-package: com.example.demo.dataobject
```


在 Spring Boot配置类中添加 `@MapperScan` 注解，扫描 Mapper 包：


```java
@SpringBootApplication
@MapperScan("com.baomidou.mybatisplus.samples.quickstart.mapper")
public class Application {

    public static void main(String[] args) {
        SpringApplication.run(QuickStartApplication.class, args);
    }

}
```


编写实体类 `User.java`（此处使用了 [Lombok](https://www.projectlombok.org/) 简化代码）


```java
@Data
public class User {
    private Long id;
    private String name;
    private Integer age;
    private String email;
}
```


编写Mapper类 `UserMapper.java`


```java
public interface UserMapper extends BaseMapper&lt;User&gt; {

}
```


添加测试类，进行功能测试：


```java
@SpringBootTest
public class SampleTest {

    @Autowired
    private UserMapper userMapper;

    @Test
    public void testSelect() {
        System.out.println(("----- selectAll method test ------"));
        List&lt;User&gt; userList = userMapper.selectList(null);
        Assert.assertEquals(5, userList.size());
        userList.forEach(System.out::println);
    }

}
```


# 主键生成策略


MyBatis-Plus如果不做任何主键策略配置，默认使用的是雪花算法。


snowflake算法是Twitter开源的分布式ID生成算法，结果是一个long类型的ID 。其核心思想：使用41bit作为毫秒数，10bit作为机器的ID（5bit数据中心，5bit的机器ID），12bit作为毫秒内的流水号（意味着每个节点在每个毫秒可以产生4096个ID），最后还有一个符号位，永远是0。


针对主键设置主键策略使用注解方式为


```java
@TableId(value = "id", type = IdType.ID_WORKER)
private Long id;
```


# 自动填充功能


像 **创建时间** 和 **修改时间** 这样的表字段是不需要手动插入, 可以设置为自动填充


在需要自动填充的字段上添加注解: `@TableField(fill = FieldFill.INSERT)`


```java
@Data
public class User {
    private Long id;
    private String name;
    private Integer age;
    private String email;

    @TableField(fill = FieldFill.INSERT)
    private Date createTime;

    @TableField(fill = FieldFill.INSERT_UPDATE)
    private Date updateTime;
}
```


自定义实现类 MyMetaObjectHandler


```java
@Slf4j
@Component
public class MyMetaObjectHandler implements MetaObjectHandler {

    @Override
    public void insertFill(MetaObject metaObject) {
        this.setFieldValByName("createTime",new Date(),metaObject);
        this.setFieldValByName("updateTime",new Date(),metaObject);
    }

    @Override
    public void updateFill(MetaObject metaObject) {
        this.setFieldValByName("updateTime",new Date(),metaObject);
    }
}
```


注意事项：


- 填充原理是直接给`entity`的属性设置值!!!
- 注解则是指定该属性在对应情况下必有值,如果无值则入库会是`null`
- `MetaObjectHandler`提供的默认方法的策略均为:如果属性有值则不覆盖,如果填充值为`null`则不填充
- 字段必须声明`TableField`注解,属性`fill`选择对应策略,该声明告知`Mybatis-Plus`需要预留注入`SQL`字段
- 填充处理器`MyMetaObjectHandler`在 Spring Boot 中需要声明`@Component`或`@Bean`注入
- 要想根据注解`FieldFill.xxx`和`字段名`以及`字段类型`来区分必须使用父类的`strictInsertFill`或者`strictUpdateFill`方法
- 不需要根据任何来区分可以使用父类的`fillStrategy`方法



```java
public enum FieldFill {
    /**
     * 默认不处理
     */
    DEFAULT,
    /**
     * 插入填充字段
     */
    INSERT,
    /**
     * 更新填充字段
     */
    UPDATE,
    /**
     * 插入和更新填充字段
     */
    INSERT_UPDATE
}
```


# 乐观锁插件


意图：


当要更新一条记录的时候，希望这条记录没有被别人更新


乐观锁实现方式：


- 取出记录时，获取当前version
- 更新时，带上这个version
- 执行更新时， set version = newVersion where version = oldVersion
- 如果version不对，就更新失败



## 配置乐观锁插件


```java
@Bean
public OptimisticLockerInterceptor optimisticLockerInterceptor() {
    return new OptimisticLockerInterceptor();
}
```


添加注解


实体类和数据表都要加上**version**字段


在实体类的**version**字段上加上注解


`@Version`


```java
@Version
private Integer version;
```


特别说明:


- **支持的数据类型只有:int,Integer,long,Long,Date,Timestamp,LocalDateTime**
- 整数类型下 `newVersion = oldVersion + 1`
- `newVersion` 会回写到 `entity` 中
- 仅支持 `updateById(id)` 与 `update(entity, wrapper)` 方法
- **在 **`**update(entity, wrapper)**`** 方法下, **`**wrapper**`** 不能复用**



## 测试乐观锁


**注意**:


测试乐观锁的时候必须先查询再修改


```java
@Test
public void update() {
	//先查询
    User user = userMapper.selectById(1315944359069253633L);
    user.setAge(25);
    user.setEmail("lemonxe@qq.com");
    //在修改
    int update = userMapper.updateById(user);
    System.out.println("成功修改:" + update);
}
```


# 分页插件


配置分页插件


```java
@Bean
public PaginationInterceptor paginationInterceptor() {
    PaginationInterceptor paginationInterceptor = new PaginationInterceptor();
    // 设置请求的页面大于最大页后操作， true调回到首页，false 继续请求  默认false
    // paginationInterceptor.setOverflow(false);
    // 设置最大单页限制数量，默认 500 条，-1 不受限制
    // paginationInterceptor.setLimit(500);
    // 开启 count 的 join 优化,只针对部分 left join
    paginationInterceptor.setCountSqlParser(new JsqlParserCountOptimize(true));
    return paginationInterceptor;
}
```


# 逻辑删除


**说明**:


只对自动注入的sql起效:


- 插入: 不作限制
- 查找: 追加where条件过滤掉已删除数据,且使用 wrapper.entity 生成的where条件会忽略该字段
- 更新: 追加where条件防止更新到已删除数据,且使用 wrapper.entity 生成的where条件会忽略该字段
- 删除: 转变为 更新



例如:


- 删除: `update user set deleted=1 where id = 1 and deleted=0`
- 查找: `select id,name,deleted from user where deleted=0`



字段类型支持说明:


- 支持所有数据类型(推荐使用 `Integer`,`Boolean`,`LocalDateTime`)
- 如果数据库字段使用`datetime`,逻辑未删除值和已删除值支持配置为字符串`null`,另一个值支持配置为函数来获取值如`now()`



附录:


- 逻辑删除是为了方便数据恢复和保护数据本身价值等等的一种方案，但实际就是删除。
- 如果你需要频繁查出来看就不应使用逻辑删除，而是以一个状态去表示。



## 添加逻辑删除字段


表中添加逻辑删除字段 , 对应实体类添加属性


## 添加注解


在实体类的逻辑删除属性上添加注解


`@TableLogic`


```java
@TableLogic
private Integer deleted;
```


## 配置逻辑删除插件


application.yml


```yml
mybatis-plus:
  global-config:
    db-config:
      logic-delete-field: deleted  # 全局逻辑删除的实体字段名(since 3.3.0,配置后可以不用再字段上加注解@TableLogic)
      logic-delete-value: 1 # 逻辑已删除值(默认为 1)
      logic-not-delete-value: 0 # 逻辑未删除值(默认为 0)
```


## 常见问题


### 如何 insert ?


&gt;
&gt; 1. 字段在数据库定义默认值(推荐)
&gt; 1. insert 前自己 set 值
&gt; 1. 使用自动填充功能
&gt;




###  删除接口自动填充功能失效


&gt;
&gt; 1. 使用 `update` 方法并: `UpdateWrapper.set(column, value)`(推荐)
&gt; 1. 使用 `update` 方法并: `UpdateWrapper.setSql("column=value")`
&gt; 1. 使用[Sql注入器](https://baomidou.com/guide/sql-injector.html)注入`LogicDeleteByIdWithFill`并使用(推荐)
&gt;




# 条件构造器

[条件构造器官方文档](https://baomidou.com/guide/wrapper.html#abstractwrapper)


# 代码生成器


AutoGenerator 是 MyBatis-Plus 的代码生成器，通过 AutoGenerator 可以快速生成 Entity、Mapper、Mapper XML、Service、Controller 等各个模块的代码，极大的提升了开发效率。



MyBatis-Plus 从 `3.0.3` 之后移除了代码生成器与模板引擎的默认依赖，需要手动添加相关依赖：


代码生成器依赖


```xml
&lt;dependency&gt;
    &lt;groupId&gt;com.baomidou&lt;/groupId&gt;
    &lt;artifactId&gt;mybatis-plus-generator&lt;/artifactId&gt;
    &lt;version&gt;3.4.0&lt;/version&gt;
&lt;/dependency&gt;
```


模板引擎 依赖，MyBatis-Plus 支持 Velocity（默认）、Freemarker、Beetl


```xml
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt;
    &lt;artifactId&gt;velocity-engine-core&lt;/artifactId&gt;
    &lt;version&gt;2.2&lt;/version&gt;
&lt;/dependency&gt;
```


示例代码


```java
//代码生成器
@Test
public void run() {
    AutoGenerator mpg = new AutoGenerator();

    // 全局配置
    GlobalConfig gc = new GlobalConfig();
    String projectPath = System.getProperty("user.dir");
    gc.setOutputDir(projectPath + "/src/main/java");
    gc.setAuthor("xiejinchi");
    gc.setOpen(false); //生成后是否打开资源管理器
    gc.setFileOverride(false); //重新生成时是否覆盖
    gc.setServiceName("%sService"); //去掉service接口的首字母I
    gc.setIdType(IdType.ID_WORKER); //主键策略
    gc.setDateType(DateType.ONLY_DATE); //定义生成的实体类中日期类型
    gc.setSwagger2(true); //开启 Swagger2 模式
    mpg.setGlobalConfig(gc);

    // 数据源配置
    DataSourceConfig dsc = new DataSourceConfig();
    dsc.setUrl("jdbc:mysql://localhost:3306/mybatis_plus?serverTimezone=GMT%2B8");
    dsc.setDriverName("com.mysql.cj.jdbc.Driver");
    dsc.setUsername("root");
    dsc.setPassword("garcon");
    mpg.setDataSource(dsc);

    // 包配置
    PackageConfig pc = new PackageConfig();
    pc.setParent("com.example.demo");
    pc.setModuleName("user"); //模块名
    pc.setEntity("entity");
    pc.setMapper("mapper");
    pc.setService("service");
    pc.setController("controller");
    mpg.setPackageInfo(pc);

    // 策略配置
    StrategyConfig strategy = new StrategyConfig();
    //表名，多个英文逗号分割
    strategy.setInclude("user".split(","));
    //数据库映射到实体类的命名策略
    strategy.setNaming(NamingStrategy.underline_to_camel);
    //数据库表映射到实体类的命名策略
    strategy.setColumnNaming(NamingStrategy.underline_to_camel);
    //生成实体时去掉表前缀
    strategy.setTablePrefix(pc.getModuleName() + "_");
    //你自己的父类实体,没有就不用设置!
    //strategy.setSuperEntityClass("");
    //Lombok模型
    strategy.setEntityLombokModel(true);
    //reset ful api风格控制器
    strategy.setRestControllerStyle(true);
    // 你自己的父类控制器,没有就不用设置!
    //strategy.setSuperControllerClass("");
    //url中驼峰转连接字符
    strategy.setControllerMappingHyphenStyle(true);
    mpg.setStrategy(strategy);
    //执行
    mpg.execute();
}
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15337469.html</id>
        <title type="text">MySQL基础-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-26T04:05:00Z</published>
        <updated>2021-09-26T04:05:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15337469.html" />
        <content type="text"># 去重查询


在需要去重的查询字段前加上`distinct`


# 模糊查询


模糊查询通配符:


- % : 表示任意多个字符,包含0个字符.
- _ : 任意单个字符



查询员工名中包含 'a' 的员工信息

```sql
select * from employees  where last_name like '%a%';
```




查询员工名中第二个字母为_的员工信息


```sql
#转移字符
select * from employees  where last_name like '_\_%';

#或 自定义转移字符
select * from employees  where last_name like '_$_%' escape '$';
```


# between and


- 包含临界值
- 两个临界值不可调换顺序



查询员工编号在100到200之间的员工信息


```sql
select * from employees
where employees_id between 100 and 200;
```


# in


- 判断字段的值是否属于in列表中的某一项
- in列表中值的类型必须一致



查询员工部门编号为1,3,5,7的员工姓名和部门编号


```sql
select employee_name dpt_id
from employees
where dpt_id in(1,3,5,7);
```


# is null 和 is not null


- =或&lt;&gt;不能判断null值



查询有奖金的员工信息


```sql
select * from employees
where bonus is not null;
```


# 排序查询


- 升序: ASC(默认)
- 降序: DESC



排序条件可以为`表达式`,`别名`,`函数`,还可以按多个字段排序


注意: `ORDER BY` 必须放在`WHERE`条件之后


查询员工信息,要求工资从高到底


```sql
select * from employees ORDER BY salary DESC;
```



查询员工信息,要求先按`工资升序`,再按员工`编号降序`


```sql
select * from employees
ORDER BY salary ASC,employess_id DESC;
```


# 常见函数


- 字符函数
- 数学函数
- 日期函数
- 流程控制函数
- 分组函数



## 字符函数


1. `length(agrs)`： 获取参数值的字节个数
2. `concat(agrs,agrs1,...)`: 拼接字符串
3. `upper(agrs)`: 将字母变大写
4. `lower(agrs)`: 将字母变小写
5. `substr(str,opt),substr(str,opt,length)`: 字符串截取,`str`表示字符,`opt`表示索引,从1开始,`length`表示长度
6. `instr(str,substr)`: 返回字串第一次出现的索引,如果找不到字串返回0;
7. `trim(str)`:去前后空格,`trim(substr FROM str)`: 去除字符substr
8. `lpad(str,len,padstr)`: 左填充; 将指定字符`pad`填充到字符str左边满长度`len`
9. `repad(str,len,padstr)` : 右填充
10. `replace(str,form_str,to_str)` : 将`str`字符串中的字串`from_str`替换成`to_str`字符串



## 数字函数


1. `round(ages)`, `round(args,number)`:四舍五入; 当只有一个参数时,就是将小数四舍五入; 两个参数时,将保留小数位number
2. `ceil(number)`: 向上取整.
3. `floor(number)`:向下取整.
4. `truncat(double,number)` : 去小数点number位后去掉.
5. `mod(num1,num2)`:取余=&gt;num%num2



## 日期函数


1. `now()` : 返回当前系统日期+时间

2. `curdate()`: 返回当前系统日期,不包含时间

3. `curtime()`:返回当前系统时间,不包含日期

4. `str_to_date(str)`: 将日期格式的字符转换成指定格式的日期

   ```sql
   STR_TO_DATE('2019-4-19','%Y-%m-%d')
   ```


5. `date_format(date)`:将日期转换成字符

   ```sql
   DATE_FORMAT('2019/4/19','%Y年%m月%d日')
   ```




## 流程控制函数


1. `if(expre1,expre2,expre3)`: `expre1`表示表达式,当条件成立时,选择值`expre2`,当条件不成立时选择值`expre3`

2. `case` : 用法一

   ```sql
   case dept_id #部门编号
   when 1 then salary*1.2 #如果是1号部门工资1.2倍
   when 2 then salary*1.3 #如果是2号部门工资1.3被
   when 3 then salary*1.4 #如果是2号部门工资1.4被
   else salary  #否则为原工资
   ```


3. `case` : 用法二

   ```sql
   case
   when 表达式1 then 要显示的值1或表达式1
   when 表达式2 then 要显示的值2或表达式2
   when 表达式3 then 要显示的值3或表达式3
   else 要显示的值n或表达式n
   ```




## 分组函数


1. `sum` : 求和,计算时忽略null值
2. `avg` : 平均值,计算时忽略null值
3. `max` : 最大值,计算时忽略null值
4. `min` : 最小值,计算时忽略null值
5. `count`:计算个数,计算时忽略null值



# 分组查询


语法


```sql
select 分组函数,列(要求出现在group by的后面)
from 表
[where 筛选条件]
group by 分组的列表
[order by 子句]
```

**注意:** `查询列表`是`分组函数`和`group by` 后出现的字段

案例：查询学生的男生和女生人数各是多少

```sql
SELECT gender, COUNT(*) 人数 FROM student  GROUP BY gender
```



## 分组后筛选: `having`

案例：查询学生年各龄人数大于2的各年龄人数

```sql
SELECT
	gender,
	COUNT(*) 人数
FROM
	student
GROUP BY
	gender
HAVING
	COUNT(*)&gt;2
```



`group by` 和 `having` 都支持别名


# 分页查询

---

查询返回的记录太多了，查看起来很不方便， 所谓分页显示，就是将数据库中的结果集，一段一段显示 出来需要的条件

**注意：** limit子句必须放在整个查询语句的最后！

```sql
select table from column limit start pageSize;
```



**start：** 就是当前页的起始索引

**pageSize：** 就是每页的条数

**currentPage：** 就是当前页

公式：

```sql
select  tableName from column... limit (currentPage-1)*pageSize pageSize
```


# 连接查询


连接查询又称为多表查询

1. 内连接
   1. 等值连接
   2. 非等值连接
   3. 自连接
2. 外连接
   1. 左外连接
   2. 右外连接
   3. 全外连接(MySQL不支持)
3. 交叉连接



**语法：**

```sql
select 查询列表
from 表1 别名
&lt;连接类型&gt; join 表2 别名
on 连接条件
[where 筛选条件]
[group by 分组]
[having 筛选条件]
[order by 排序列表]
```


## 笛卡尔集
笛卡尔集会在下面条件下产生

- 省略连接条件
- 连接条件无效
- 所有表中的所有行互相连接



## 内连接
特点：

1. 添加排序、分组、筛选
2. inner可以省略
3.  筛选条件放在where后面，连接条件放在on后面，提高分离性，便于阅读




分类：

1. 等值
1. 非等值
1. 自连接



语法：
```sql
select 查询列表
from 表1 别名
inner join 表2 别名
on 连接条件;
```



### 等值连接

案例1.查询员工名、部门名
```sql
SELECT last_name,department_name
FROM departments d
JOIN  employees e
ON e.`department_id` = d.`department_id`;
```



案例2.查询名字中包含e的员工名和工种名（添加筛选）

```sql
SELECT last_name,job_title
FROM employees e
INNER JOIN jobs j
ON e.job_id=  j.job_id
WHERE e.last_name LIKE '%e%';
```



案例3. 查询部门个数&gt;3的城市名和部门个数，（添加分组+筛选）

1. 查询每个城市的部门个数
2. 在1结果上筛选满足条件的

```sql
SELECT city,COUNT(*) 部门个数
FROM departments d
INNER JOIN locations l
ON d.location_id=l.location_id
GROUP BY city
HAVING COUNT(*)&gt;3;
```



案例4.查询哪个部门的员工个数&gt;3的部门名和员工个数，并按个数降序（添加排序）

1. 查询每个部门的员工个数

```sql
SELECT COUNT(*),department_name
FROM employees e
INNER JOIN departments d
ON e.department_id=d.department_id
GROUP BY department_name
```


2. 在1结果上筛选员工个数&gt;3的记录，并排序

```sql
SELECT COUNT(*) 个数,department_name
FROM employees e
INNER JOIN departments d
ON e.department_id=d.department_id
GROUP BY department_name
HAVING COUNT(*)&gt;3
ORDER BY COUNT(*) DESC;
```



案例5.查询员工名、部门名、工种名，并按部门名降序（添加三表连接）

```sql
SELECT last_name,department_name,job_title
FROM employees e
INNER JOIN departments d ON e.department_id=d.department_id
INNER JOIN jobs j ON e.job_id = j.job_id
ORDER BY department_name DESC;
```



### 非等值连接

查询员工的工资级别
```sql
SELECT salary,grade_level
FROM employees e
 JOIN job_grades g
 ON e.`salary` BETWEEN g.`lowest_sal` AND g.`highest_sal`;
```



 查询工资级别的个数&gt;20的个数，并且按工资级别降序

```sql
SELECT COUNT(*),grade_level
FROM employees e
 JOIN job_grades g
 ON e.`salary` BETWEEN g.`lowest_sal` AND g.`highest_sal`
 GROUP BY grade_level
 HAVING COUNT(*)&gt;20
 ORDER BY grade_level DESC;
```



### 自连接

 查询员工的名字、上级的名字
```sql
SELECT e.last_name,m.last_name
 FROM employees e
 JOIN employees m
 ON e.`manager_id`= m.`employee_id`;
```


 查询姓名中包含字符k的员工的名字、上级的名字
```sql
SELECT e.last_name,m.last_name
 FROM employees e
 JOIN employees m
 ON e.`manager_id`= m.`employee_id`
 WHERE e.`last_name` LIKE '%k%';
```



## 外连接

 应用场景：用于查询一个表中有，另一个表没有的记录

 特点：

1. 外连接的查询结果为主表中的所有记录，如果从表中有和它匹配的，则显示匹配的值，如果从表中没有和它匹配的，则显示null，外连接查询结果=内连接结果+主表中有而从表没有的记录
1. 左外连接，left join左边的是主表，右外连接，right join右边的是主表
1. 左外和右外交换两个表的顺序，可以实现同样的效果
1. 全外连接=内连接的结果+表1中有但表2没有的+表2中有但表1没有的



### 左外连接
 查询哪个部门没有员工
```sql
SELECT d.*,e.employee_id
 FROM departments d
 LEFT OUTER JOIN employees e
 ON d.`department_id` = e.`department_id`
 WHERE e.`employee_id` IS NULL;
```



### 右外
 查询哪个部门没有员工
```sql
SELECT d.*,e.employee_id
 FROM employees e
 RIGHT OUTER JOIN departments d
 ON d.`department_id` = e.`department_id`
 WHERE e.`employee_id` IS NULL;
```



### 全外

```sql
USE girls;
 SELECT b.*,bo.*
 FROM beauty b
 FULL OUTER JOIN boys bo
 ON b.`boyfriend_id` = bo.id;
```



## 交叉连接

```sql
SELECT b.*,bo.*
 FROM beauty b
 CROSS JOIN boys bo;
```




# 子查询

子查询出现的位置
select后面：仅仅支持标量（一列一行）子查询
from后面：支持表子查询
where或having后面：标量子查询、列子查询（一列多行）、行子查询（一行多列）
exists后面：表子查询（多列多行）




# 数据库的创建和删除


### 创建数据库


创建数据库的语法


```sql
CREATE DATABASE  database_name;
```


如果不确定要创建的数据库是否存在,可以先使用`创建时判断`或者`查看有哪些数据库`


```sql
-- 如果数据库不存在才创建
create database if not exists database_name;

-- 查看有那些数据库
show databases;
```


### 删除数据库


删除数据库的语法


```sql
drop database  database_name;
```


# 创建表


创建表的语法


```sql
CREATE TABLE  table_name（column_name column_type ...）;

-- 创建时判断表是否存在 if not exists
CREATE TABLE if not exists  table_name（column_name column_type ...）;
```



例 : 在这里，我们将在数据库“customers”中创建一个名为“cus_tbl”的表。


```sql
CREATE TABLE cus_tbl(
   cus_id INT NOT NULL AUTO_INCREMENT,
   cus_firstname VARCHAR(100) NOT NULL,
   cus_surname VARCHAR(100) NOT NULL,
   PRIMARY KEY ( cus_id )
);
```



### 查看已创建的表


```sql
show tables;
```



### 查看数据表的结构


```sql
describe table_name;
```


# 修改表


### 修改表名


```sql
ALTER TABLE  table_name
RENAME  TO  new_table_name;
```


### 添加字段


添加字段的语法


```sql
ALTER TABLE table_name
ADD new_column_name column_definition
[ FIRST | AFTER column_name ];  -- 在某列之前或之后
```


参数的含义 :


- **table_name：**指定要修改的表的名称。
- **new_column_name：**它指定要添加到表中的新列的名称。
- **column_definition：**它指定列的数据类型和定义（NULL或NOT NULL等）。
- **FIRST | AFTER column_name：**它是可选的。它告诉MySQL在表中创建列的位置。如果未指定此参数，则新列将添加到表的末尾。



添加多个字段


```sql
ALTER TABLE table_name
ADD new_column_name column_definition
[ FIRST | AFTER column_name ],
ADD new_column_name column_definition
[ FIRST | AFTER column_name ],
...
;
```


### 修改字段


`MODIFY` 修改某个字段的定义,比如说修改字段的`数据类型`和`约束`


```sql
ALTER TABLE  table_name
MODIFY  column_name column_definition
[  FIRST  | AFTER  column_name];
```


`CHANGE` 修改某个字段的`字段名`,和`数据类型`或`约束`


```sql
ALTER TABLE  table_name
CHANGE  COLUMN  old_name new_name
column_definition
[  FIRST  | AFTER  column_name]
```


### 删除字段


```sql
ALTER TABLE  table_name
DROP COLUMN  column_name;
```


# 删除表


### 删除表中所有的数据


删除全部数据的两种方式


1. DELETE
1. TRUNCATE



两个删除的区别 : delete是删除表中的记录 , truncate是删除表然后在创建表


```sql
TRUNCATE TABLE table_name;

-- 或者
delete TABLE table_name
```


### 删除表


```sql
DROP TABLE   table_name;
```


# 插入数据


### 插入一条数据


```sql
-- 指定字段插入
INSERT INTO  table_name（field1，field2，... fieldN）
VALUES
（value1，value2，... valueN）;

-- 全字段插入
INSERT INTO  table_name  VALUES  （value1，value2，... valueN）;
```


### 插入多条记录


```sql
INSERT INTO  cus_tbl
（cus_id，cus_firstname，cus_surname）
VALUES
（5，  'Ajeet' ，  'Maurya' ），
（6，  'Deepika' ，  'Chopra' ），
（7，  'Vimal' ，  'Jaiswal' ）;
```


# 更新数据


UPDATE语句用于更新数据库中MySQL表的数据。


```sql
UPDATE table_name SET field1=new-value1, field2=new-value2
[WHERE Clause]
```


**注意：**


- 可以完全更新一个或多个字段。
- 可以使用WHERE子句指定任何条件。
- 您可以一次更新单个表中的值。
- WHERE子句用于更新表中的选定行。



# 删除数据


删除指定数据-行


```sql
DELETE FROM table_name
WHERE
(Condition specified);
```


# MySQL的约束
约束是用来限定表中数据准确性、完整性、一致性、联动性的一套规则。在Mysql中，约束保存在`information_schema`数据库的`table_constraints`中，可以通过该表查询约束信息。
MySQL的约束种类 :

1. 非空约束(not null)

1. 唯一性约束(unique)

1. 主键约束(primary key) PK

1. 外键约束(foreign key) FK

1. 检查约束(目前MySQL不支持、Oracle支持)

## not null
**创建**NOT NULL约束
```sql
CREATE TABLE emp(
id INT(10) NOT NULL,
NAME VARCHAR(20) NOT NULL DEFAULT 'abc',
sex CHAR NULL
);
```


**增加**NOT NULL约束
```sql
ALTER TABLE emp
MODIFY sex VARCHAR(30) NOT NULL;
```


取消NOT NULL约束
```sql
ALTER TABLE emp
MODIFY sex VARCHAR(30) NULL;
```


取消 not null 约束，增加默认值
```sql
ALTER TABLE emp
MODIFY NAME VARCHAR(15) DEFAULT 'abc' NULL;
```
## UNIQUE
同一个表可以有多个唯一约束，多个列组合的约束。 在创建唯一约束的时候，如果不给唯一约束名称，就 默认和列名相同。
MySQL会给唯一约束的列上默认创建一个唯一索引


使用表级约束语法
```sql
CREATE TABLE USER(
id INT NOT NULL,
NAME VARCHAR(25),
PASSWORD VARCHAR(16),
#使用表级约束语法
CONSTRAINT uk_name_pwd UNIQUE(NAME,PASSWORD)
);
```


添加唯一约束
```sql
#方式一
ALTER TABLE USER
ADD UNIQUE(NAME,PASSWORD);

#方式二
ALTER TABLE USER
ADD CONSTRAINT uk_name_pwd UNIQUE(NAME,PASSWORD);

#方式三
ALTER TABLE USER
MODIFY NAME VARCHAR(20) UNIQUE;
```


删除唯一约束
```sql
ALTER TABLE USER
DROP INDEX uk_name_pwd;
```


## PRIMARY KEY

1. 主键约束相当于唯一约束+非空约束的组合，主 键约束列不允许重复，也不允许出现空值
1. 如果是多列组合的主键约束，那么这些列都不允 许为空值，并且组合的值不允许重复。
1. 每个表最多只允许一个主键，建立主键约束可以 在列级别创建，也可以在表级别上创建。
1. MySQL的主键名总是PRIMARY，当创建主键约束 时，系统默认会在所在的列和列组合上建立对应的 唯一索引。



创建主键约束
表级模式
```sql
CREATE TABLE emp5(
id INT NOT NULL AUTO_INCREMENT,
NAME VARCHAR(20),
pwd VARCHAR(15),
CONSTRAINT emp5_id_pk PRIMARY KEY(id)
);
```
列级模式
```sql
CREATE TABLE emp4(
id INT AUTO_INCREMENT PRIMARY KEY,
NAME VARCHAR(20)
);
```
组合模式
```sql
CREATE TABLE emp6(
id INT NOT NULL,
NAME VARCHAR(20),
pwd VARCHAR(15),
CONSTRAINT emp7_pk PRIMARY KEY(NAME,pwd)
);
```


添加主键约束
```sql
ALTER TABLE emp5
ADD PRIMARY KEY(NAME,pwd);
```


修改主键约束
```sql
ALTER TABLE emp5
MODIFY id INT PRIMARY KEY;
```


删除主键约束
```sql
ALTER TABLE emp5
DROP PRIMARY KEY;
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15337524.html</id>
        <title type="text">Vue入门学习-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-26T04:25:00Z</published>
        <updated>2021-09-26T04:25:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15337524.html" />
        <content type="text"># 模板语法


模板语法分为：插值语法、指令语法


插值语法使用 {{}}


指令语法 v-bind


```
&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;

&lt;head&gt;
    &lt;meta charset="UTF-8"&gt;
    &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt;
    &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt;
    &lt;title&gt;Document&lt;/title&gt;
    &lt;script src="../js/vue.js"&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body&gt;
&lt;div id="root"&gt;
    &lt;p&gt;我的名字：{{name}}&lt;/p&gt;
    &lt;a v-bind:href="url"&gt;百度一下&lt;/a&gt;
&lt;/div&gt;

&lt;Script&gt;
    Vue.config.productionTip = false;
    new Vue({
        el: '#root',
        data: {
            name: '青橙',
            url: 'https://www.baidu.com'
        }
    })
&lt;/Script&gt;
&lt;/body&gt;

&lt;/html&gt;
```


# 数据绑定


单项数据绑定 (v-bind)：数据只能从data流向页面。


&gt; v-bind 可以简写为  ：



双向数据绑定（v-model）：数据可以从data流向页面，也可以从页面流向data。


&gt; v-model只能作用在表单元素上。v-model:vue可以简写成 v-model，因为v-model默认收集的就是value的值。



```
&lt;body&gt;
    &lt;div id="root"&gt;
        单向数据绑定：&lt;input type="text" v-bind:value="name" /&gt;{{name}}


        双向数据绑定：&lt;input type="text" v-model:value="age" /&gt;{{age}}
    &lt;/div&gt;
    &lt;script&gt;
        new Vue({
            el: '#root',
            data: {
                name: '青橙',
                age: 25
            }
        });

    &lt;/script&gt;
&lt;/body&gt;
```


# el和data的两种写法


el 的第一种写法


```
&lt;body&gt;
    &lt;div id="root"&gt;

    &lt;/div&gt;
    &lt;script&gt;
        new Vue({
            el:'#root',
            data:{

            }
        });
    &lt;/script&gt;
&lt;/body&gt;
```


el 的第二种写法


```
&lt;body&gt;
    &lt;div id="root"&gt;

    &lt;/div&gt;
    &lt;script&gt;
        const v = new Vue({
            data: {
                name: 'hello'
            }
        });

        v.$mount('#root');
    &lt;/script&gt;
&lt;/body&gt;
```


data 的第一种写法: 对象式


```
&lt;script&gt;
    const v = new Vue({
        el:'#root',
        data: {
            name: 'hello'
        }
    });
&lt;/script&gt;
```


data 的第二种写法: 函数式


```
&lt;script&gt;
    const v = new Vue({
        el: '#root',
        data() {
            return {
                name: 'hello'
            }
        }
    });
&lt;/script&gt;
```


# 事件处理


## v-on


&gt; 点击显示信息
&gt;
&gt; 或
&gt;
&gt; &lt;button @click="showInfo()"&gt;点击显示信息



```
&lt;body&gt;
    &lt;div id='root'&gt;
        &lt;button v-on:click="showInfo()"&gt;点击显示信息&lt;/button&gt;
    &lt;/div&gt;
    &lt;script&gt;
        new Vue({
            el: '#root',
            data() {
                return {
                    name: '青橙'
                }
            },
            methods: {
                showInfo() {
                    alert('hello,' + this.name)
                }
            }
        })
    &lt;/script&gt;
&lt;/body&gt;
```


## 事件修饰符


vue中的事件修饰符


1. prevent：阻止默认事件
2. stop：阻止事件冒泡
3. once：事件只触发一次
4. capture：使用事件的捕获模式
5. self：只有event.target是当前操作的元素才触发事件
6. passive：事件的默认行为立即执行，无需等待事件回调执行完毕



```
&lt;body&gt;
    &lt;div id="root"&gt;
        &lt;!-- a标签的默认行为被阻止 --&gt;
        &lt;a href="http://www.baidu.com" v-on:click.prvent='showInfo'&gt;点击我&lt;/a&gt;
    &lt;/div&gt;
    &lt;script&gt;
        Vue.config.productionTip = false;
        new Vue({
            el: '#root',
            data() {
                return {

                }
            },
            methods: {
                showInfo() {
                    alert('hello....')
                }
            }
        })
    &lt;/script&gt;
&lt;/body&gt;
```


## 键盘事件


keyup 和 keydown的区别：


keyup：按键弹起时被触发。keydown：按键被按下的时候被触发。


vue中常用的按键别名


- 回车：enter
- 删除：delete
- 退出：esc
- 空格：space
- 换行：tab
- 上：up
- 下：down
- 左：left
- 右：right



```
&lt;body&gt;
    &lt;div id="root"&gt;
        &lt;!-- 输入之后按回车键触发 控制台输出value值--&gt;
        &lt;input type="text" v-on:keyup.enter='showInfo' /&gt;
    &lt;/div&gt;
    &lt;script&gt;
        Vue.config.productionTip = false;
        new Vue({
            el: '#root',
            data() {
                return {

                }
            },
            methods: {
                showInfo(e) {
                    console.log(e.target.value);
                }
            }
        })
    &lt;/script&gt;
&lt;/body&gt;
```


# 计算属性-computed


计算属性和方法的区别：计算属性的结果会被缓存，只有当依赖的属性发生改变时会被调用。


```
&lt;body&gt;
    &lt;div id="root"&gt;
        &lt;input type="text" v-model="fristname"&gt;

        &lt;input type="text" v-model="lastname"&gt;

        全名：{{fullname}}
    &lt;/div&gt;
    &lt;script&gt;
        new Vue({
            el: '#root',
            data: {
                fristname: '张',
                lastname: '三'
            },
            computed: {
                fullname: {
                    get() {
                        return this.fristname + '-' + this.lastname
                    }
                }
            }
        })
    &lt;/script&gt;
&lt;/body&gt;
```


完整形式,， 当要修改计算属性时，计算属性要加上 set()


```
computed: {
    fullname: {
        get() {
            return this.fristname + '-' + this.lastname
        },
        set(value){

        }
    }
}
```


简写形式，没有 set()，默认就是get()


```
computed: {
    fullname() {
        return this.fristname + '-' + this.lastname
    }
}
```


# 侦听器-watch


监听某一个属性的变化， 当监听的属性变化时被调用。


```
&lt;body&gt;
    &lt;div id="root"&gt;
        &lt;h3&gt;今天心情很好！&lt;/h3&gt;
        &lt;button @click='changeMood'&gt;改变心情&lt;/button&gt;
    &lt;/div&gt;
    &lt;script&gt;
        new Vue({
            el: '#root',
            data: {
                isGood: true
            },
            methods: {
                changeMood() {
                    console.log("执行changeMood");
                    this.isGood = !this.isGood;
                }
            },
            watch:{
                isGood:{

                    handler(newValue,oldValue){
                        console.log('isGood的值改变了,改变前：',oldValue,'，改变后',newValue);
                    }
                }
            }
        })
    &lt;/script&gt;
&lt;/body&gt;
```


watch完整写法


```
    vm.$watch('isGood', {
        immediate: true, //初始化的时候调用handler
        deep: true, //深度监听，比如说对象中的属性改变
        handler(newValue, oldValue) {
            console.log('isGood的值改变了,改变前：', oldValue, '，改变后', newValue);
        }
    });
```


watch简写


```
vm.$watch('isGood', function (newValue, oldValue) {
    console.log('isGood的值改变了,改变前：', oldValue, '，改变后', newValue)
});
```


**computed 和 watch 的区别**


computed可以计算多个属性， 依赖的某一个属性发生改变时就会被调用，而watch只能监听一个属性。


watch可以做异步操作，computed不可以。


# 绑定样式


## 绑定 HTML Class


在将 `v-bind` 用于 `class` 和 `style` 时，Vue.js 做了专门的增强。表达式结果的类型除了字符串之外，还可以是对象或数组


### 对象语法


可以传给 `v-bind:class` 一个对象，以动态地切换 class：


```
&lt;div v-bind:class="{ active: isActive , happy:isHappy }"&gt;&lt;/div&gt;
```


data：


```
data: {
  isMood: true,
  isHappy: true
}
```


绑定的数据对象不必内联定义在模板里：


```
&lt;div v-bind:class="classObject"&gt;&lt;/div&gt;
data: {
  classObject: {
    active: true,
    'text-danger': false
  }
}
```


绑定一个返回对象的计算属性。这是一个常用且强大的模式：


```
&lt;div v-bind:class="classObject"&gt;&lt;/div&gt;
data: {
  isActive: true,
  error: null
},
computed: {
  classObject: function () {
    return {
      active: this.isActive &amp;&amp; !this.error,
      'text-danger': this.error &amp;&amp; this.error.type === 'fatal'
    }
  }
}
```


### 数组语法


可以把一个数组传给 `v-bind:class`，以应用一个 class 列表：


```
&lt;div v-bind:class="[activeClass, errorClass]"&gt;&lt;/div&gt;
data: {
  activeClass: 'active',
  errorClass: 'text-danger'
}
```


渲染为：


```
&lt;div class="active text-danger"&gt;&lt;/div&gt;
```


# 条件渲染


```
&lt;h1 v-if="awesome"&gt;Vue is awesome!&lt;/h1&gt;
&lt;h1 v-else&gt;Oh no 😢&lt;/h1&gt;
```


data


```
data:{
    awesome: true
}
```


# 列表渲染


我们可以用 `v-for` 指令基于一个数组来渲染一个列表。`v-for` 指令需要使用 `item in items` 形式的特殊语法，其中 `items` 是源数据数组，而 `item` 则是被迭代的数组元素的**别名**。


```
&lt;ul id="example-1"&gt;
  &lt;li v-for="item in items" :key="item.message"&gt;
    {{ item.message }}
  &lt;/li&gt;
&lt;/ul&gt;
var example1 = new Vue({
  el: '#example-1',
  data: {
    items: [
      { message: 'Foo' },
      { message: 'Bar' }
    ]
  }
})
```


结果：


- Foo
- Bar



在 `v-for` 块中，我们可以访问所有父作用域的 property。`v-for` 还支持一个可选的第二个参数，即当前项的索引。


```
&lt;ul id="example-2"&gt;
  &lt;li v-for="(item, index) in items"&gt;
    {{ parentMessage }} - {{ index }} - {{ item.message }}
  &lt;/li&gt;
&lt;/ul&gt;
var example2 = new Vue({
  el: '#example-2',
  data: {
    parentMessage: 'Parent',
    items: [
      { message: 'Foo' },
      { message: 'Bar' }
    ]
  }
})
```


结果：


- Parent - 0 - Foo
- Parent - 1 - Bar



# 过滤器


Vue.js 允许你自定义过滤器，可被用于一些常见的文本格式化。过滤器可以用在两个地方：**双花括号插值和 **`**v-bind**`** 表达式** (后者从 2.1.0+ 开始支持)。过滤器应该被添加在 JavaScript 表达式的尾部，由“管道”符号指示：


```
&lt;!-- 在双花括号中 --&gt;
{{ message | capitalize }}
&lt;!-- 在 `v-bind` 中 --&gt;
&lt;div v-bind:id="rawId | formatId"&gt;&lt;/div&gt;
```


你可以在一个组件的选项中定义本地的过滤器：


```
filters: {
  capitalize: function (value) {
    if (!value) return ''
    value = value.toString()
    return value.charAt(0).toUpperCase() + value.slice(1)
  }
}
```


或者在创建 Vue 实例之前全局定义过滤器：


```
Vue.filter('capitalize', function (value) {
  if (!value) return ''
  value = value.toString()
  return value.charAt(0).toUpperCase() + value.slice(1)
})
new Vue({
  // ...
})
```


当全局过滤器和局部过滤器重名时，会采用局部过滤器。


# 组件基础


```
&lt;body&gt;
    &lt;div id="root"&gt;
        &lt;student&gt;&lt;/student&gt;
    &lt;/div&gt;
    &lt;script&gt;
        Vue.config.productionTip = false

        const student = Vue.extend({
            data() {
                return {
                    name: 'orange',
                    age: 25,
                    gender: '男'
                }
            },
            template: `
            &lt;div&gt;
                姓名：{{ name }}
                年龄：{{ age }}
                性别：{{ gender }}
            &lt;/div&gt;
                 `
        })

        new Vue({
            el: '#root',
            components: {
                student
            }
        })
    &lt;/script&gt;
&lt;/body&gt;
```


# vuecli 脚手架


Vue CLI 是一个基于 Vue.js 进行快速开发的完整系统


- 基于 webpack 构建，并带有合理的默认配置；
- 可以通过项目内的配置文件进行配置；
- 可以通过插件进行扩展。



运行以下命令来创建一个新项目：


```
vue create hello-world
```


## vue.config.js


`vue.config.js` 是一个可选的配置文件，如果项目的 (和 `package.json` 同级的) 根目录中存在这个文件，那么它会被 `@vue/cli-service` 自动加载。


```
// vue.config.js

/**
 * @type {import('@vue/cli-service').ProjectOptions}
 */
module.exports = {
  // 选项...
}
```


# ref


`ref` 被用来给元素或子组件注册引用信息。引用信息将会注册在父组件的 `$refs` 对象上。如果在普通的 DOM 元素上使用，引用指向的就是 DOM 元素；如果用在子组件上，引用就指向组件实例


标识


```
&lt;p ref="p"&gt;{{msg}}&lt;/p&gt;
```


获取


```
this.$refs.p
```


# props


props 可以是数组或对象，用于接收来自父组件的数据。props 可以是简单的数组，或者使用对象作为替代，对象允许配置高级选项，如类型检测、自定义验证和设置默认值。


- **示例**：



```
// 简单语法
Vue.component('props-demo-simple', {
  props: ['size', 'myMessage']
})
// 对象语法，提供验证
Vue.component('props-demo-advanced', {
  props: {
    // 检测类型
    height: Number,
    // 检测类型 + 其他验证
    age: {
      type: Number,
      default: 0,
      required: true,
      validator: function (value) {
        return value &gt;= 0
      }
    }
  }
})
```


## 父向子组件传值


父组件向子组件传值用**属性传值**


父组件


```
&lt;template&gt;
  &lt;div id="app"&gt;
    &lt;HelloWorld :msg="message" /&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;
import HelloWorld from "./components/HelloWorld.vue";

export default {
  name: "App",
  components: {
    HelloWorld,
  },
  data() {
    return {
      message: "今天天气不错"
    };
  },
};
&lt;/script&gt;
```


子组件


```
&lt;template&gt;
  &lt;div class="hello"&gt;
    &lt;p&gt;父组件传过来的值：{{ msg }}&lt;/p&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;
export default {
  name: "HelloWorld",
  props: {
    msg: String,
  },
};
&lt;/script&gt;
```


## 子向父组件传值


子组件向父组件传值用**函数传值**


父组件


```
&lt;template&gt;
  &lt;div id="app"&gt;
    &lt;HelloWorld :receive="receive" /&gt;
    &lt;p&gt;子组件传过来的值：{{message}}&lt;/p&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;
import HelloWorld from "./components/HelloWorld.vue";

export default {
  name: "App",
  components: {
    HelloWorld,
  },
  data() {
    return {
      message: "",
    };
  },
  methods: {
    receive(value) {
      this.message = value;
    },
  },
};
&lt;/script&gt;
```


子组件


```
&lt;template&gt;
  &lt;div class="hello"&gt;
    &lt;input type="text" v-model="message" /&gt;
    &lt;input type="button" value="传值" @click="add" /&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;
export default {
  name: "HelloWorld",
  props: ["receive"],
  data() {
    return {
      message: "",
    };
  },
  methods: {
    add() {
      this.receive(this.message);
    },
  },
};
&lt;/script&gt;
```


# 自定义事件


不同于组件和 prop，事件名不存在任何自动化的大小写转换。而是触发的事件名需要完全匹配监听这个事件所用的名称。举个例子，如果触发一个 camelCase 名字的事件：


```
this.$emit('myEvent')
```


则监听这个名字的 kebab-case 版本是不会有任何效果的：


```
&lt;!-- 没有效果 --&gt;
&lt;my-component v-on:my-event="doSomething"&gt;&lt;/my-component&gt;
```


不同于组件和 prop，事件名不会被用作一个 JavaScript 变量名或 property 名，所以就没有理由使用 camelCase 或 PascalCase 了。并且 `v-on` 事件监听器在 DOM 模板中会被自动转换为全小写 (因为 HTML 是大小写不敏感的)，所以 `v-on:myEvent` 将会变成 `v-on:myevent`——导致 `myEvent` 不可能被监听到。


因此，我们推荐你**始终使用 kebab-case 的事件名**。


自定义事件实现子组件向父组件传值


父组件


```
&lt;template&gt;
  &lt;div id="app"&gt;
    &lt;HelloWorld v-on:my-event="receive" /&gt;
    &lt;p&gt;子组件传过来的值：{{ message }}&lt;/p&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;
import HelloWorld from "./components/HelloWorld.vue";

export default {
  name: "App",
  components: {
    HelloWorld,
  },
  data() {
    return {
      message: "",
    };
  },
  methods: {
    receive(value) {
      this.message = value;
    },
  },
};
&lt;/script&gt;
```


子组件


```
&lt;template&gt;
  &lt;div class="hello"&gt;
    &lt;input type="text" v-model="message" /&gt;
    &lt;input type="button" value="传值" @click="add" /&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;
export default {
  name: "HelloWorld",
  data() {
    return {
      message: "",
    };
  },
  methods: {
    add() {
      this.$emit("my-event", this.message);
    },
  },
};
&lt;/script&gt;
```


# 全局事件总线


一种适用于任意间组件传值的方式


使用方式


注册全局事件总线


```
import Vue from 'vue'
import App from './App.vue'

Vue.config.productionTip = false

new Vue({
  render: h =&gt; h(App),
  beforeCreate() {
    Vue.prototype.$bus = this //注册全局事件总线
  }
}).$mount('#app')
```


接收数据


```
mounted() {
  this.$bus.$on("hello", (data) =&gt; {
    this.orangeMessage = data;
  });
}
```


发送数据


```
 methods: {
    send() {
      this.$bus.$emit("hello", this.message);
    },
  },
```


# axios


使用axios发送请求


安装 axios


```
npm install axios
```


使用


```
import axios from "axios";
export default {
  name: "User",
  methods: {
    getUser() {
      axios
        .get("https://localhost:8080/api/user/getuser")
        .then((res) =&gt; {
          console.log("res", res);
        })
        .catch((error) =&gt; {
          console.log("error", error);
        });
    },
  },
};
```


# 配置代理


如果你的前端应用和后端 API 服务器没有运行在同一个主机上，你需要在开发环境下将 API 请求代理到 API 服务器。这个问题可以通过 `vue.config.js` 中的 `devServer.proxy` 选项来配置。


```
module.exports = {
    devServer: {
        proxy: {
            '/api': {
                target: 'http://localhost:80',
                pathRewrite: { '^/api': '' },//将以 /api 开头的请求转发到http://localhost:80, 但请求时去掉/api
                ws: true, //用于支持webSocket
                changeOrigin: true //用于控制请求头中的host值
            },
            '/foo': {
                target: '&lt;other_url&gt;'
            }
        }
    }
}
```


# 插槽 slot


## 默认插槽


它允许你像这样合成组件：


```
&lt;navigation-link url="/profile"&gt;
  Your Profile
&lt;/navigation-link&gt;
```


然后你在 `&lt;navigation-link&gt;` 的模板中可能会写为：


```
&lt;a v-bind:href="url" class="nav-link"
&gt;
  &lt;slot&gt;&lt;/slot&gt;
&lt;/a&gt;
```


当组件渲染的时候，`&lt;slot&gt;&lt;/slot&gt;` 将会被替换为“Your Profile”。插槽内可以包含任何模板代码，包括 HTML：


```
&lt;navigation-link url="/profile"&gt;
  &lt;!-- 添加一个 Font Awesome 图标 --&gt;
  &lt;span class="fa fa-user"&gt;&lt;/span&gt;
  Your Profile
&lt;/navigation-link&gt;
```


甚至其它的组件：


```
&lt;navigation-link url="/profile"&gt;
  &lt;!-- 添加一个图标的组件 --&gt;
  &lt;font-awesome-icon name="user"&gt;&lt;/font-awesome-icon&gt;
  Your Profile
&lt;/navigation-link&gt;
```


&gt; 注意：如果 `&lt;navigation-link&gt;` 的 `template` 中**没有**包含一个 `&lt;slot&gt;` 元素，则该组件起始标签和结束标签之间的任何内容都会被抛弃。



## 有名字的插槽


```
&lt;template&gt;
  &lt;div id="app"&gt;
    &lt;HelloWorld&gt;
      &lt;div slot="center" class="slotcenter"&gt;
        &lt;p&gt;这是组件插槽的内容&lt;/p&gt;
      &lt;/div&gt;
    &lt;/HelloWorld&gt;
  &lt;/div&gt;
&lt;/template&gt;
```


然后在 `&lt;HelloWorld&gt;`中这样写


```
&lt;template&gt;
  &lt;div id="app"&gt;
    &lt;HelloWorld&gt;
      &lt;div slot="center" class="slotcenter"&gt;
        &lt;p&gt;这是组件插槽的内容&lt;/p&gt;
      &lt;/div&gt;
    &lt;/HelloWorld&gt;
  &lt;/div&gt;
&lt;/template&gt;
```


# Vuex


Vuex 是一个专为 Vue.js 应用程序开发的**状态管理模式**。它采用集中式存储管理应用的所有组件的状态，并以相应的规则保证状态以一种可预测的方式发生变化。


## 简单使用


安装Vuex


```
npm install vuex
```


创建Vuex ：src/store/index.js


```
import Vue from 'vue'
import Vuex from 'vuex'

Vue.use(Vuex)
//准备actions 用于相应组件中的动作
const actions = {
    jia(context, value) {
        context.commit('JIA', value)
    }
}
//准备mutations 用于操作数据（state）
const mutations = {
    JIA(state, value) {
        state.sum += value
    }
}
//准备state 用于存储数据
const state = {
    sum: 0
}

const store = new Vuex.Store({
    actions,
    mutations,
    state

})
export default store
```


main.js 引入store


```
import Vue from 'vue'
import App from './App.vue'
import store from './store'

Vue.config.productionTip = false

new Vue({
  render: h =&gt; h(App),
  store
}).$mount('#app')
```


使用


```
&lt;template&gt;
  &lt;div class="hello"&gt;
    &lt;p&gt;结果为：{{ $store.state.sum }}&lt;/p&gt;
    &lt;input type="button" value="点击加一" @click="increment" /&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;
export default {
  name: "hello",
  data() {
    return {
      number: 1,
    };
  },
  methods: {
    increment() {
      this.$store.dispatch("jia", this.number);
    },
  },
};
&lt;/script&gt;
```


## getters


getters是对state 的数据进行操作，包装


```
const getters = {
    bigSum(state) {
        return state.sum * 10
    }
}

const store = new Vuex.Store({
    actions,
    mutations,
    state,
    getters

})
```


获取


```
 computed: {
    getbigSum() {
      return this.$store.getters.bigSum;
    },
  }
```


## mapState


mapState用于获取state中的数据


在不用mapState之前这样获取数据


```
&lt;template&gt;
  &lt;div class="hello"&gt;
    &lt;p&gt;姓名：{{ name }}&lt;/p&gt;
    &lt;p&gt;年龄：{{ age }}&lt;/p&gt;
    &lt;p&gt;性别：{{ gender }}&lt;/p&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;
export default {
  name: "hello",
  computed: {
    name() {
      return this.$store.state.name;
    },
    age() {
      return this.$store.state.age;
    },
    gender() {
      return this.$store.state.gender;
    },
  },
};
&lt;/script&gt;
```


使用mapState，这样取值


```
&lt;template&gt;
  &lt;div class="hello"&gt;
    &lt;p&gt;姓名：{{ name }}&lt;/p&gt;
    &lt;p&gt;年龄：{{ age }}&lt;/p&gt;
    &lt;p&gt;性别：{{ gender }}&lt;/p&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;
import { mapState } from "vuex";
export default {
  name: "hello",
  computed: {
    //第一种写法，对象写法
    // ...mapState({ name: "name", age: "age", gender: "gender" }),

    //第二种写法，数组写法
    ...mapState(["name", "age", "gender"]),
  },
};
&lt;/script&gt;
```


## mapGetters


mapGetters和mapState的用法一样


## 模块化


将 actions、mutations、state 模块化


```
import Vue from 'vue'
import Vuex from 'vuex'

Vue.use(Vuex)

//用户相关
const userOptions = {
    namespaced: true,
    actions: {
        addUser(context, value) {
            console.log("执行addUSer", value);
            context.commit('ADD_USER', value)
        }
    },
    mutations: {
        ADD_USER(state, value) {
            state.users.unshift(value)
        }
    },
    state: {
        users: [
            { name: 'orange', age: 25, gender: '男' },
            { name: 'lemon', age: 23, gender: '男' }
        ]
    }
}


const store = new Vuex.Store({
    modules: {
        userAbout: userOptions
    }
})
export default store
```


获取数据和操作数据


```
&lt;template&gt;
  &lt;div class="hello"&gt;
    &lt;form&gt;
      &lt;label for="user.name"&gt;用户名&lt;/label&gt;
      &lt;input type="text" v-model="user.name" /&gt;


      &lt;label for="user.age"&gt;年龄&lt;/label&gt;
      &lt;input type="text" v-model.number="user.age" /&gt;


      &lt;input type="radio" id="one" value="男" v-model="user.gender" /&gt;
      &lt;label for="one"&gt;男&lt;/label&gt;
      &lt;input type="radio" id="two" value="女" v-model="user.gender" /&gt;
      &lt;label for="two"&gt;女&lt;/label&gt;


      &lt;input type="button" @click="insertUser" value="添加用户" /&gt;
    &lt;/form&gt;
    &lt;ul&gt;
      &lt;li v-for="(u, index) in users" :key="index"&gt;
        {{ u.name }}-{{ u.age }}-{{ u.gender }}
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;
import { mapState } from "vuex";
export default {
  name: "hello",
  data() {
    return {
      user: {
        gender: "男",
      },
    };
  },
  computed: {
    ...mapState("userAbout", ["users"]),
  },
  methods: {
    insertUser() {
      this.$store.dispatch("userAbout/addUser", this.user);
    },
  },
};
&lt;/script&gt;
```


# Vue Router


## 基本使用


安装路由


```bash
npm install vue-router
```


创建路由 `src/router/index.js`


```javascript
import Vue from 'vue'
import Router from 'vue-router'

import Home from "../components/Home.vue"
import About from "../components/About.vue"

Vue.use(Router)

const router = new Router({
    routes: [
        {
            path: '/home',
            component: Home
        },
        {
            path: '/about',
            component: About
        }
    ]
})

export default router
```


在`main.js`中


```javascript
import Vue from 'vue'
import App from './App.vue'
import router from './router'


Vue.config.productionTip = false

new Vue({
  render: h =&gt; h(App),
  router
}).$mount('#app')
```


在组件中使用

```
&lt;template&gt;
  &lt;div id="app"&gt;
    &lt;div class="routeBox"&gt;
      &lt;ul class="navbar-nav"&gt;
        &lt;li class="nav-item"&gt;
          &lt;router-link class="nav-link" active-class="active" to="/home"&gt;Home&lt;/router-link&gt;
        &lt;/li&gt;
        &lt;li class="nav-item"&gt;
          &lt;router-link class="nav-link" active-class="active" to="/about"&gt;About&lt;/router-link&gt;
        &lt;/li&gt;
      &lt;/ul&gt;
    &lt;/div&gt;
    &lt;div class="contentBox"&gt;
      &lt;router-view&gt;&lt;/router-view&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/template&gt;
```


## 多级路由


二级路由不需要以 '/' 开头


```javascript
import Vue from 'vue'
import Router from 'vue-router'

import Home from "../components/Home.vue"
import About from "../components/About.vue"

import News from "../components/News.vue"
import Message from "../components/Message.vue"

Vue.use(Router)

const router = new Router({
    routes: [
        {
            path: '/home',
            component: Home,
            children: [
                {
                    path: 'news',
                    component: News
                },
                {
                    path:'message',
                    component:Message
                }

            ]
        },
        {
            path: '/about',
            component: About
        }
    ]
})

export default router
```


## 路由query参数


路由传参的两种写法


```
&lt;!-- 第一种写法，字符窜写法 --&gt;
&lt;router-link active-class="active" :to="`/home?id=${user.id}&amp;name=${user.name}`" &gt;Home&lt;/router-link&gt;


&lt;!-- 第二种写法，对象写法 --&gt;
&lt;router-link active-class="active" :to="{
      path: '/home',
      query: {
        id: user.id,
        name: user.name,
      },
	}"
&gt;Home&lt;/router-link
```


获取参数


```
&lt;template&gt;
  &lt;div class=".container"&gt;
    &lt;p&gt;获取到路由参数id: {{ $route.query.id }}&lt;/p&gt;
    &lt;p&gt;获取到路由参数name: {{ $route.query.name }}&lt;/p&gt;
  &lt;/div&gt;
&lt;/template&gt;
```


## 命名路由


创建路由的时候加上`name`属性，跳转的时候指定`name`名称就行


```javascript
const router = new Router({
    routes: [
        {
            name:'myhome',
            path: '/home',
            component: Home,
        }
    ]
})

export default router ``` 跳转 ``` &lt;router-link:to="{ name: 'myhome' }"&gt;Home&lt;/router-link &gt;

&lt;--!配合传参--&gt;
&lt;router-link :to="{
  name: 'myhome',
  query: {
    id: user.id,
    name: user.name,
  },
}"&gt;Home&lt;/router-link&gt;
```


## 路由params参数


传递params参数需要在路由上写明


```javascript
const router = new Router({
    routes: [
        {
            name:'myhome',
            path: '/home/:id/:name',
            component: Home,
        }
    ]
})

export default router
```


跳转时放入参数


```
&lt;--! 方式一 --&gt;
&lt;router-link :to="`/home/${user.id}/${user.name}`"&gt;Home&lt;/router-link&gt;

&lt;--! 方式二  注意：这里不能使用 path ，只能使用name --&gt;
&lt;router-link :to="{
  name: 'myhome',
  params: {
    id: user.id,
    name: user.name,
  },
}"&gt;Home&lt;/router-link&gt;
```


接收参数


```
&lt;template&gt;
  &lt;div class=".container"&gt;
    &lt;p&gt;获取到路由参数id: {{ $route.params.id }}&lt;/p&gt;
    &lt;p&gt;获取到路由参数name: {{ $route.params.name }}&lt;/p&gt;
  &lt;/div&gt;
&lt;/template&gt;
```


## `&lt;router-link&gt;`的replace属性


在`&lt;router-link&gt;`标签中加上**replace**属性后不可后退 ，默认时push，可回退。


```
&lt;router-link :replace="true" to="/home"&gt;&lt;/router-link&gt;

&lt;!--简写模式 --&gt;
&lt;router-link replace to="home"&gt;&lt;/router-link&gt;
```


## 编程式路由导航


**push**和**replace**的区别：push可回退，replace不可回退


```javascript

methods: {
    toAbout() {
      this.$router.push("/about");
    },
  },

//传递参数
methods: {
    toAbout() {
      this.$router.push({
        name: "toabout",
        params: {
          id: 1,
          name: "orange",
        },
      });
    },
```


back：后退，forward：前进，to：去第几步


```javascript
this.$router.back()

this.$router.forward()

this.$router.go(number)
```


## 缓存路由组件


让不展示的路由组件保持挂载，不被销毁。


比如说有一个路由组件是表单输入，输入类容后切换走在切换回来时，输入的内容还在


属性 include 是组件的名字, 可以是一个数组


```
&lt;keep-alive include="Form"&gt;
	&lt;router-view&gt;&lt;/router-view&gt;
&lt;/keep-alive&gt;


&lt;keep-alive include="['Form','Home']"&gt;
	&lt;router-view&gt;&lt;/router-view&gt;
&lt;/keep-alive&gt;
```


## 路由生命周期钩子


用于捕获路由的激活状态的两个生命周期钩子函数


```javascript
//路由组件被激活
activated() {},

// 路由组件失活
deactivated() {},
```


## 全局路由守卫


**全局前置路由守卫:** 在初始化 和 切换路由前调用


可以用来做登录校验 ， 权限校验


```javascript
import Vue from 'vue'
import Router from 'vue-router'

import Home from "../components/Home.vue"
import About from "../components/About.vue"

Vue.use(Router)

const router = new Router({
    routes: [
        {
            name: 'myhome',
            path: '/home',
            component: Home,
        },
        {
            name: 'toabout',
            path: '/about',
            component: About
        }
    ]
})


//to:去什么位置;
//from:当前位置;
//next:放行
router.beforeEach((to, from, next) =&gt; {
    console.log('beforeEach', to);
    if (to.path === '/home') {
        //判断是否登录
    } else {
        //放行
        next()
    }
})

export default router
```


如果有很多路由都需要认证， 可以在创建路由的时候加上**meta**属性并且写上标识来判断是否需要认证


```javascript
import Vue from 'vue'
import Router from 'vue-router'

import Home from "../components/Home.vue"
import About from "../components/About.vue"

Vue.use(Router)

const router = new Router({
    routes: [
        {
            name: 'myhome',
            path: '/home',
            component: Home,
            meta: { isAuth: true }
        },
        {
            name: 'toabout',
            path: '/about',
            component: About
        }
    ]
})

// 全局前置路由守卫: 在初始化 和 切换路由前调用

//to:去什么位置; from:当前位置; next:放行
router.beforeEach((to, from, next) =&gt; {
    if (to.meta.isAuth) {
        //判断是否登录
        console.log('需要登录');
    } else {
        //放行
        next()
    }
})

export default router
```


**全局后置路由守卫:** 在初始化 和 切换路由之后调用


```javascript
router.afterEach((to, from) =&gt; {

})
```


## 独享路由守卫


独享路由守卫只有前置守卫，没有后置守卫。


```javascript
import Vue from 'vue'
import Router from 'vue-router'

import Home from "../components/Home.vue"
import About from "../components/About.vue"

Vue.use(Router)

const router = new Router({
    routes: [
        {
            name: 'myhome',
            path: '/home',
            component: Home,
            meta: { isAuth: true },
            beforeEnter: (to, from, next) =&gt; {

            }

        },
        {
            name: 'toabout',
            path: '/about',
            component: About
        }
    ]
})

export default router
```


## 路由的history和hash模式


**路由的history模式和hash模式的区别**


hash模式在地址栏上有# ：localhost:8080/home ，history模式地址栏中没有#


配置路由模式 `mode : 'history'`


```javascript
const router = new Router({
    mode: 'history',
    routes: [
        {
            name: 'myhome',
            path: '/home',
            component: Home,
            meta: { isAuth: true },
        }
    ]
})
```


**history模式刷新出现404**


在hash模式下，前端路由修改的是#中的信息，而浏览器请求时是不带#后面的。


在history模式下，当刷新时，如果服务器中没有相应的响应或者资源localhost:8080/home，就会出现404


**解决history模式刷新出现404**


将前端项目部署到nginx中，在nginx配置


```
location / {
  try_files $uri $uri/ /index.html;
}
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15337677.html</id>
        <title type="text">npm修改镜像源和包存放位置-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-26T05:23:00Z</published>
        <updated>2021-09-26T05:23:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15337677.html" />
        <content type="text">NPM是Node提供的模块管理工具，可以非常方便的下载安装前端框架。

node安装完成之后可以使用下命令查看和修改相关配置

查看配置
```bash
npm config ls
```
修改全局包下载存放位置
```bash
npm config set prefix "E:\node\node_global"
```

修改node缓存的位置
```bash
npm config set cache "E:\node\node_cache"
```

修改npm镜像为淘宝
```bash
npm config set metrics-registry "https://registry.npm.taobao.org/"
```</content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15338579.html</id>
        <title type="text">CentOS防火墙-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-26T08:01:00Z</published>
        <updated>2021-09-26T08:01:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15338579.html" />
        <content type="text">CentOS6自带的防火墙是iptables，CentOS7自带的防火墙是firewall。
**iptables：**用于过滤数据包，属于网络层防火墙。
**firewall：**底层还是使用 iptables 对内核命令动态通信包过滤的，简单理解就是firewall是centos7下管理


# iptables 防火墙
```bash
# 查看防火墙状态
service iptables status

# 停止防火墙
service iptables stop

# 启动防火墙
service iptables start

# 重启防火墙
service iptables restart

# 永久关闭防火墙
chkconfig iptables off

# 永久关闭后重启
chkconfig iptables on
```


**开启80端口**
```bash
# 编辑iptales
vim /etc/sysconfig/iptables

# 加入以下代码然后保存退出
-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT

#重启防火墙
service iptables restart
```


# firewall 防火墙


## 查看firewall服务状态
```bash
systemctl status firewalld
```
出现Active: **active (running)**绿色高亮显示则表示是启动状态。 出现 Active: inactive (dead)灰色表示停止状态。

## 查看firewall的状态
```shell
firewall-cmd --state
```


## 开启、重启、关闭firewall服务
```bash
# 开启
service firewalld start

# 重启
service firewalld restart

# 关闭
service firewalld stop

4.查看防火墙规则
firewall-cmd --list-all
```
## 查看、开放、关闭端口
```bash
# 查询端口是否开放
firewall-cmd --query-port=8080/tcp

# 开放80端口
firewall-cmd --permanent --add-port=80/tcp

# 移除端口
firewall-cmd --permanent --remove-port=8080/tcp

#重启防火墙(修改配置后要重启防火墙)
firewall-cmd --reload
```

## 指定IP和端口访问
```
# 添加规则
firewall-cmd --permanent --add-rich-rule="rule family="ipv4" source address="192.168.1.100" port protocol="tcp" port="8080" accept"

# 移除规则
firewall-cmd --permanent --remove-rich-rule="rule family="ipv4" source address="192.168.1.100" port protocol="tcp" port="8080" accept"
```

## firewall 常用命令
```bash
# 查看防火墙状态，是否是running
firewall-cmd --state

# 重新载入配置，比如添加规则之后，需要执行此命令
firewall-cmd --reload

# 列出支持的zone
firewall-cmd --get-zones

# 列出支持的服务，在列表中的服务是放行的
firewall-cmd --get-services

# 查看ftp服务是否支持，返回yes或者no
firewall-cmd --query-service ftp

# 临时开放ftp服务
firewall-cmd --add-service=ftp

# 永久开放ftp服务
firewall-cmd --add-service=ftp --permanent

# 永久移除ftp服务
firewall-cmd --remove-service=ftp --permanent

# 永久添加80端口
firewall-cmd --add-port=80/tcp --permanent

# 查看规则，这个命令和iptables的相同
iptables -L -n

# 查看帮助
man firewall-cmd
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15338610.html</id>
        <title type="text">EasyExcel对表格解析和生成-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-26T08:07:00Z</published>
        <updated>2021-09-26T08:07:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15338610.html" />
        <content type="text"># EasyExcel 简介


Java解析、生成Excel比较有名的框架有Apache  poi、jxl。但他们都存在一个严重的问题就是非常的耗内存，poi有一套SAX模式的API可以一定程度的解决一些内存溢出的问题，但POI还是有一些缺陷，比如07版Excel解压缩以及解压后存储都是在内存中完成的，内存消耗依然很大。easyexcel重写了poi对07版Excel的解析，能够原本一个3M的excel用POI  sax依然需要100M左右内存降低到几M，并且再大的excel不会出现内存溢出，03版依赖POI的sax模式。在上层做了模型转换的封装，让使用者更加简单方便


更多的使用方法可以查看官方文档 [https://github.com/alibaba/easyexcel](https://github.com/alibaba/easyexcel)


依赖


```xml
&lt;dependency&gt;
    &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
    &lt;artifactId&gt;easyexcel&lt;/artifactId&gt;
    &lt;version&gt;2.2.6&lt;/version&gt;
&lt;/dependency&gt;
```


# 写入


这里使用简单的写入


```java
/**
 * 最简单的写
 * &lt;p&gt;
 * 1. 创建excel对应的实体对象 参照{@link DemoData}
 * &lt;p&gt;
 * 2. 直接写即可
 */
@Test
public void simpleWrite() {
    // 写法1
    String fileName = "E:/" + "simpleWrite" + System.currentTimeMillis() + ".xlsx";
    // 这里 需要指定写用哪个class去写，然后写到第一个sheet，名字为模板 然后文件流会自动关闭
    // 如果这里想使用03 则 传入excelType参数即可
    EasyExcel.write(fileName, DemoData.class).sheet("模板").doWrite(data());
}

/**
 * 要写入的数据
 */
private List&lt;DemoData&gt; data() {
        List&lt;DemoData&gt; list = new ArrayList&lt;DemoData&gt;();
        for (int i = 0; i &lt; 10; i++) {
            DemoData data = new DemoData();
            data.setString("字符串" + i);
            data.setDate(new Date());
            data.setDoubleData(0.56);
            list.add(data);
        }
        return list;
    }
```


基础数据类


**DemoData**


```java
/**
 * 基础数据类
 *
 * @author Jiaju Zhuang
 **/
@Data
public class DemoData {
    @ExcelProperty("字符串标题")
    private String string;
    @ExcelProperty("日期标题")
    private Date date;
    @ExcelProperty("数字标题")
    private Double doubleData;
    /**
     * 忽略这个字段
     */
    @ExcelIgnore
    private String ignore;
}
```


# 读取


最简单的读取


```java
/**
 * 最简单的读
 * &lt;p&gt;
 * 1. 创建excel对应的实体对象 参照{@link DemoData}
 * &lt;p&gt;
 * 2. 由于默认一行行的读取excel，所以需要创建excel一行一行的回调监听器，参照{@link DemoDataListener}
 * &lt;p&gt;
 * 3. 直接读即可
 */
@Test
public void simpleRead() {
    // 有个很重要的点 DemoDataListener 不能被spring管理，要每次读取excel都要new,然后里面用到spring可以构造方法传进去
    // 写法1：
    String fileName = "E:/simpleWrite1602827890506.xlsx";
    // 这里 需要指定读用哪个class去读，然后读取第一个sheet 文件流会自动关闭
    EasyExcel.read(fileName, DemoData.class, new DemoDataListener()).sheet().doRead();
}
```


基础数据类


**DemoData**


```java
/**
 * 基础数据类.这里的排序和excel里面的排序一致
 *
 * @author Jiaju Zhuang
 **/
@Data
public class DemoData {
    private String string;
    private Date date;
    private Double doubleData;
}
```


监听类


```java
/**
 * 模板的读取类
 *
 * @author Jiaju Zhuang
 */
// 有个很重要的点 DemoDataListener 不能被spring管理，要每次读取excel都要new,然后里面用到spring可以构造方法传进去
public class DemoDataListener extends AnalysisEventListener&lt;DemoData&gt; {
    private static final Logger LOGGER = LoggerFactory.getLogger(DemoDataListener.class);
    /**
     * 每隔5条存储数据库，实际使用中可以3000条，然后清理list ，方便内存回收
     */
    private static final int BATCH_COUNT = 5;
    List&lt;DemoData&gt; list = new ArrayList&lt;DemoData&gt;();
    /**
     * 假设这个是一个DAO，当然有业务逻辑这个也可以是一个service。当然如果不用存储这个对象没用。
     */
    private DemoDAO demoDAO;

    public DemoDataListener() {
        // 这里是demo，所以随便new一个。实际使用如果到了spring,请使用下面的有参构造函数
        demoDAO = new DemoDAO();
    }

    /**
     * 如果使用了spring,请使用这个构造方法。每次创建Listener的时候需要把spring管理的类传进来
     *
     * @param demoDAO
     */
    public DemoDataListener(DemoDAO demoDAO) {
        this.demoDAO = demoDAO;
    }

    /**
     * 这个每一条数据解析都会来调用
     *
     * @param data
     *            one row value. Is is same as {@link AnalysisContext#readRowHolder()}
     * @param context
     */
    @Override
    public void invoke(DemoData data, AnalysisContext context) {
        LOGGER.info("解析到一条数据:{}", JSON.toJSONString(data));
        list.add(data);
        // 达到BATCH_COUNT了，需要去存储一次数据库，防止数据几万条数据在内存，容易OOM
        if (list.size() &gt;= BATCH_COUNT) {
            saveData();
            // 存储完成清理 list
            list.clear();
        }
    }

    /**
     * 所有数据解析完成了 都会来调用
     *
     * @param context
     */
    @Override
    public void doAfterAllAnalysed(AnalysisContext context) {
        // 这里也要保存数据，确保最后遗留的数据也存储到数据库
        saveData();
        LOGGER.info("所有数据解析完成！");
    }

    /**
     * 加上存储数据库
     */
    private void saveData() {
        LOGGER.info("{}条数据，开始存储数据库！", list.size());
        demoDAO.save(list);
        LOGGER.info("存储数据库成功！");
    }
}
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15339145.html</id>
        <title type="text">Java线程池和异步任务-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-27T06:23:00Z</published>
        <updated>2021-09-27T06:23:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15339145.html" />
        <content type="text"># 线程池的构造函数

```java
public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue&lt;Runnable&gt; workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler)
```

## 构造函数的参数

`int corePoolSize`：保留在池中的线程数，即使它们是空闲的，除非设置了允许核心线程超时(allowCoreThreadTimeOut)
`int maximumPoolSize`：池中允许的最大线程数
`long keepAliveTime`：当线程数大于核心线程数时，这是空闲线程在终止前等待新任务的最大时间。（空闲线程的存活时间）
`TimeUnit unit`：keepAliveTime参数的时间单位
`BlockingQueue&lt;Runnable&gt; workQueue`：用来存放核心线程来不及处理的任务，默认值为Integer的最大值。
`ThreadFactory threadFactory`：执行程序创建新线程时使用的工厂
`RejectedExecutionHandler handler`：当执行被阻塞时使用的处理程序，因为线程边界和队列容量已经达到（当任务队列满了之后，按照指定的拒绝策略执行任务）

## 工作流程
1. 线程池创建，准备好指定数量的核心线程数，准备接收任务
2. 新的任务进来，用准备好的空闲线程执行。
3. 核心线程满了，就将再进来的任务放入阻塞队列中。空闲的核心线程就会去阻塞队列获取任务执行。
4. 阻塞队列满了，就直接开新线程执行，最大能开到maximumPoolSize指定的数量。
5. maximumPoolSize都执行好了，maximumPoolSize数量空闲的线程会在keepAliveTime指定的时间后自动销毁，最终保存核心线程
6. 如果线程数开到了maximumPoolSize数量，还有新任务进来，就会使用handler指定的拒绝策略进行处理


# 常见的四种线程池



## Executors.newCachedThreadPool()
带缓存的线程池，核心线程数为0，所有线程都可回收

使用的构造方法如下
```java
public static ExecutorService newCachedThreadPool() {
    return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                  60L, TimeUnit.SECONDS,
                                  new SynchronousQueue&lt;Runnable&gt;());
}
```

## Executors.newFixedThreadPool()

固定线程数的线程池，所有线程都不可回收

使用的构造方法如下
```java
public static ExecutorService newFixedThreadPool(int nThreads) {
    return new ThreadPoolExecutor(nThreads, nThreads,
                                  0L, TimeUnit.MILLISECONDS,
                                  new LinkedBlockingQueue&lt;Runnable&gt;());
}
```

## Executors.newScheduledThreadPool()
定时任务的线程池

## Executors.newSingleThreadExecutor()
单线程的线程池，核心数是1，最大数也是1

使用的构造方法如下

 ![](https://img2020.cnblogs.com/blog/1801000/202109/1801000-20210926171848614-1409180018.png)


# CompletableFuture异步编排

CompletableFuture主要是用于异步调用，内部封装了线程池，可以将请求或者处理过程，进行异步处理。

CompletableFuture提供了四个静态方法来创建异步操作
```java
//没有返回值
public static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable) {
    return asyncRunStage(asyncPool, runnable);
}
//没有返回值，可指定线程池
public static CompletableFuture&lt;Void&gt; runAsync(Runnable runnable,
                                               Executor executor) {
    return asyncRunStage(screenExecutor(executor), runnable);
}

//有返回值
public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier) {
    return asyncSupplyStage(asyncPool, supplier);
}
//有返回值，可指定线程池
public static &lt;U&gt; CompletableFuture&lt;U&gt; supplyAsync(Supplier&lt;U&gt; supplier,
                                                   Executor executor) {
    return asyncSupplyStage(screenExecutor(executor), supplier);
}
```

## 开启异步任务

```java
public static void main(String[] args) {
    //创建线程池
    ExecutorService executorService = Executors.newFixedThreadPool(10);
    //开启异步任务
    CompletableFuture&lt;Integer&gt; completableFuture = CompletableFuture.supplyAsync(() -&gt; {
        int a = 1 + 1;
        return a;
    }, executorService);
    try {
        //获取返回结果
        Integer result = completableFuture.get();
        System.out.println("得到返回结果：" + result);
    } catch (InterruptedException e) {
        e.printStackTrace();
    } catch (ExecutionException e) {
        e.printStackTrace();
    }
}
```

## 任务完成回调和异常

whenComplete
```java
public static void main(String[] args) {
    //创建线程池
    ExecutorService executorService = Executors.newFixedThreadPool(10);
    //开启异步任务
    CompletableFuture&lt;Integer&gt; completableFuture = CompletableFuture.supplyAsync(() -&gt; {
        int a = 1 / 0;
        return a;
    }, executorService).whenComplete((res, exception) -&gt; {
        System.out.println("异步任务完成，结果为：" + res);
        System.out.println("异常是：" + exception);
    }).exceptionally(throwable -&gt; {
        //当发生异常时，返回默认值
        return 0;
    });
    try {
        Integer result = completableFuture.get();
        System.out.println("结果为：" + result);
    } catch (InterruptedException e) {
        e.printStackTrace();
    } catch (ExecutionException e) {
        e.printStackTrace();
    }

}
```

handle
```java
public static void main(String[] args) {
    //创建线程池
    ExecutorService executorService = Executors.newFixedThreadPool(10);
    //开启异步任务
    CompletableFuture&lt;Integer&gt; completableFuture = CompletableFuture.supplyAsync(() -&gt; {
        int a = 1 / 0;
        return a;
    }, executorService).handle((res, exception) -&gt; {
        if (res != null) {
            return res * 2;
        }
        if (exception!=null){
            return 0;
        }
        return 0;
    });
    try {
        Integer result = completableFuture.get();
        System.out.println("结果为：" + result);
    } catch (InterruptedException e) {
        e.printStackTrace();
    } catch (ExecutionException e) {
        e.printStackTrace();
    }
}
```

## 线程串行化
- `thenRunAsync`：不能获取结果，没有返回值
- `thenAcceptAsync`：可以获取结果，没有返回值
- `thenApplyAsync `：可以获取结果，并且有返回值

thenRunAsync不能获取上一步的执行结果

例子
```java
public static void main(String[] args) {
    //创建线程池
    ExecutorService executorService = Executors.newFixedThreadPool(10);
    //开启异步任务
    CompletableFuture&lt;Void&gt; completableFuture = CompletableFuture.thenRunAsync(() -&gt; {
        System.out.println("异步任务");
    }, executorService).thenRunAsync(() -&gt; {
        System.out.println("任务二启动");
    }, executorService);
}
```

thenAcceptAsync 可以获取上一步的结果，但是没有返回值

例子
```java
public static void main(String[] args) {
    //创建线程池
    ExecutorService executorService = Executors.newFixedThreadPool(10);
    //开启异步任务
    CompletableFuture.supplyAsync(() -&gt; {
        System.out.println("异步任务");
        int result = 1 + 1;
        return result;
    }, executorService).thenAcceptAsync(res -&gt; {
        System.out.println("任务二启动，上一步的结果为：" + res);
    }, executorService);
}
```

thenApplyAsync 可以获取上一步的结果，还有返回值
例子
```java
public static void main(String[] args) {
    //创建线程池
    ExecutorService executorService = Executors.newFixedThreadPool(10);
    //开启异步任务
    CompletableFuture&lt;Integer&gt; completableFuture = CompletableFuture.supplyAsync(() -&gt; {
        System.out.println("异步任务");
        int result = 1 + 1;
        return result;
    }, executorService).thenApplyAsync(res -&gt; {
        System.out.println("任务二启动，上一步的结果为：" + res);
        return res * 2;
    }, executorService);

    try {
        Integer result = completableFuture.get();
        System.out.println("结果是：" + result);
    } catch (InterruptedException e) {
        e.printStackTrace();
    } catch (ExecutionException e) {
        e.printStackTrace();
    }
}
```

## 两任务组合

当任务一和任务二都完成再执行任务三
- `runAfterBothAsync `：不能获取前两个任务的结果，也没有返回值
- `thenAcceptBothAsync`：可以获取前两个任务的返回值，但是本身没有返回值
- `thenCombineAsync`：可以获取前两个任务的结果，还能返回值

两个任务，只要有一个任务完成，就执行任务三
- `runAfterEitherAsync`：不能获取前一个任务的结果，也没有返回值
- `acceptEitherAsync`：可以获取上一个任务的结果，但是没有返回值
- `applyToEitherAsync`：可以获取上一步的返回结果，并且有返回值


**runAfterBothAsync**
runAfterBothAsync不能获取前两个任务的结果，也没有返回值
例子
```java
public static void main(String[] args) {
    //创建线程池
    ExecutorService executorService = Executors.newFixedThreadPool(10);
    //开启异步任务1
    CompletableFuture&lt;Integer&gt; task = CompletableFuture.supplyAsync(() -&gt; {
        System.out.println("异步任务1，当前线程是：" + Thread.currentThread().getId());
        int result = 1 + 1;
        System.out.println("异步任务1结束");
        return result;
    }, executorService);

    //开启异步任务2
    CompletableFuture&lt;Integer&gt; task2 = CompletableFuture.supplyAsync(() -&gt; {
        System.out.println("异步任务2，当前线程是：" + Thread.currentThread().getId());
        int result = 1 + 1;
        System.out.println("异步任务2结束");
        return result;
    }, executorService);

    task.runAfterBothAsync(task2, () -&gt; {
        System.out.println("任务3开始");
        System.out.println("任务三结束");
    }, executorService);
}
```

**thenAcceptBothAsync**
可以获取前两个任务的返回值，但是本身没有返回值
```java
public static void main(String[] args) {
    //创建线程池
    ExecutorService executorService = Executors.newFixedThreadPool(10);
    //开启异步任务1
    CompletableFuture&lt;Integer&gt; task = CompletableFuture.supplyAsync(() -&gt; {
        System.out.println("异步任务1，当前线程是：" + Thread.currentThread().getId());
        int result = 1 + 1;
        System.out.println("异步任务1结束");
        return result;
    }, executorService);

    //开启异步任务2
    CompletableFuture&lt;Integer&gt; task2 = CompletableFuture.supplyAsync(() -&gt; {
        System.out.println("异步任务2，当前线程是：" + Thread.currentThread().getId());
        int result = 1 + 1;
        System.out.println("异步任务2结束");
        return result;
    }, executorService);

    //任务组合
    task.thenAcceptBothAsync(task2, (f1, f2) -&gt; {
        System.out.println("执行任务3，当前线程是：" + Thread.currentThread().getId());
        System.out.println("任务1返回值：" + f1);
        System.out.println("任务2返回值：" + f2);
    }, executorService);
}
```

**thenCombineAsync**
可以获取前两个任务的结果，还能返回值
```java
public static void main(String[] args) {
    //创建线程池
    ExecutorService executorService = Executors.newFixedThreadPool(10);
    //开启异步任务1
    CompletableFuture&lt;Integer&gt; task = CompletableFuture.supplyAsync(() -&gt; {
        System.out.println("异步任务1，当前线程是：" + Thread.currentThread().getId());
        int result = 1 + 1;
        System.out.println("异步任务1结束");
        return result;
    }, executorService);

    //开启异步任务2
    CompletableFuture&lt;Integer&gt; task2 = CompletableFuture.supplyAsync(() -&gt; {
        System.out.println("异步任务2，当前线程是：" + Thread.currentThread().getId());
        int result = 1 + 1;
        System.out.println("异步任务2结束");
        return result;
    }, executorService);

    //任务组合
    CompletableFuture&lt;Integer&gt; task3 = task.thenCombineAsync(task2, (f1, f2) -&gt; {
        System.out.println("执行任务3，当前线程是：" + Thread.currentThread().getId());
        System.out.println("任务1返回值：" + f1);
        System.out.println("任务2返回值：" + f2);
        return f1 + f2;
    }, executorService);

    try {
        Integer res = task3.get();
        System.out.println("最终结果：" + res);
    } catch (InterruptedException e) {
        e.printStackTrace();
    } catch (ExecutionException e) {
        e.printStackTrace();
    }
}
```

**runAfterEitherAsync**
不能获取前一个任务的结果，也没有返回值
```java
public static void main(String[] args) {
    //创建线程池
    ExecutorService executorService = Executors.newFixedThreadPool(10);
    //开启异步任务1
    CompletableFuture&lt;Integer&gt; task = CompletableFuture.supplyAsync(() -&gt; {
        System.out.println("异步任务1，当前线程是：" + Thread.currentThread().getId());
        int result = 1 + 1;
        System.out.println("异步任务1结束");
        return result;
    }, executorService);

    //开启异步任务2
    CompletableFuture&lt;Integer&gt; task2 = CompletableFuture.supplyAsync(() -&gt; {
        System.out.println("异步任务2，当前线程是：" + Thread.currentThread().getId());
        int result = 1 + 1;
        System.out.println("异步任务2结束");
        return result;
    }, executorService);

    //任务组合
    task.runAfterEitherAsync(task2, () -&gt; {
        System.out.println("执行任务3，当前线程是：" + Thread.currentThread().getId());
    }, executorService);
```

**acceptEitherAsync**
可以获取上一个任务的结果，但是没有返回值
```java
public static void main(String[] args) {
    //创建线程池
    ExecutorService executorService = Executors.newFixedThreadPool(10);
    //开启异步任务1
    CompletableFuture&lt;Integer&gt; task = CompletableFuture.supplyAsync(() -&gt; {
        System.out.println("异步任务1，当前线程是：" + Thread.currentThread().getId());
        int result = 1 + 1;
        System.out.println("异步任务1结束");
        return result;
    }, executorService);

    //开启异步任务2
    CompletableFuture&lt;Integer&gt; task2 = CompletableFuture.supplyAsync(() -&gt; {
        System.out.println("异步任务2，当前线程是：" + Thread.currentThread().getId());
        int result = 1 + 2;
        try {
            Thread.sleep(3000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println("异步任务2结束");
        return result;
    }, executorService);

    //任务组合
    task.acceptEitherAsync(task2, (res) -&gt; {
        System.out.println("执行任务3，当前线程是：" + Thread.currentThread().getId());
        System.out.println("上一个任务的结果为："+res);
    }, executorService);
}
```

**applyToEitherAsync**
可以获取上一步的返回结果，并且有返回值
```java
public static void main(String[] args) {
    //创建线程池
    ExecutorService executorService = Executors.newFixedThreadPool(10);
    //开启异步任务1
    CompletableFuture&lt;Integer&gt; task = CompletableFuture.supplyAsync(() -&gt; {
        System.out.println("异步任务1，当前线程是：" + Thread.currentThread().getId());
        int result = 1 + 1;
        System.out.println("异步任务1结束");
        return result;
    }, executorService);

    //开启异步任务2
    CompletableFuture&lt;Integer&gt; task2 = CompletableFuture.supplyAsync(() -&gt; {
        System.out.println("异步任务2，当前线程是：" + Thread.currentThread().getId());
        int result = 1 + 2;
        try {
            Thread.sleep(3000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println("异步任务2结束");
        return result;
    }, executorService);

    //任务组合
    CompletableFuture&lt;Integer&gt; task3 = task.applyToEitherAsync(task2, (res) -&gt; {
        System.out.println("执行任务3，当前线程是：" + Thread.currentThread().getId());
        System.out.println("上一个任务的结果为：" + res);
        return res * 3;
    }, executorService);

    try {
        Integer res = task3.get();
        System.out.println("最终结果：" + res);
    } catch (InterruptedException e) {
        e.printStackTrace();
    } catch (ExecutionException e) {
        e.printStackTrace();
    }
}
```

## 多任务组合
- `allOf`：等待所有任务完成
- `anyOf`：只要有一个任务完成

**allOf**
等待所有任务完成
```java
public static void main(String[] args) {
    //创建线程池
    ExecutorService executorService = Executors.newFixedThreadPool(10);
    //开启异步任务1
    CompletableFuture&lt;Integer&gt; task = CompletableFuture.supplyAsync(() -&gt; {
        System.out.println("异步任务1，当前线程是：" + Thread.currentThread().getId());
        int result = 1 + 1;
        System.out.println("异步任务1结束");
        return result;
    }, executorService);

    //开启异步任务2
    CompletableFuture&lt;Integer&gt; task2 = CompletableFuture.supplyAsync(() -&gt; {
        System.out.println("异步任务2，当前线程是：" + Thread.currentThread().getId());
        int result = 1 + 2;
        try {
            Thread.sleep(3000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println("异步任务2结束");
        return result;
    }, executorService);

    //开启异步任务3
    CompletableFuture&lt;Integer&gt; task3 = CompletableFuture.supplyAsync(() -&gt; {
        System.out.println("异步任务3，当前线程是：" + Thread.currentThread().getId());
        int result = 1 + 3;
        try {
            Thread.sleep(4000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println("异步任务3结束");
        return result;
    }, executorService);

    //任务组合
    CompletableFuture&lt;Void&gt; allOf = CompletableFuture.allOf(task, task2, task3);
    try {
        //等待所有任务完成
        allOf.get();

        //获取任务的返回结果
        System.out.println("task结果为：" + task.get());
        System.out.println("task2结果为：" + task2.get());
        System.out.println("task3结果为：" + task3.get());
    } catch (InterruptedException e) {
        e.printStackTrace();
    } catch (ExecutionException e) {
        e.printStackTrace();
    }

}
```

**anyOf**
只要有一个任务完成
```java
public static void main(String[] args) {
    //创建线程池
    ExecutorService executorService = Executors.newFixedThreadPool(10);
    //开启异步任务1
    CompletableFuture&lt;Integer&gt; task = CompletableFuture.supplyAsync(() -&gt; {
        System.out.println("异步任务1，当前线程是：" + Thread.currentThread().getId());
        int result = 1 + 1;
        System.out.println("异步任务1结束");
        return result;
    }, executorService);

    //开启异步任务2
    CompletableFuture&lt;Integer&gt; task2 = CompletableFuture.supplyAsync(() -&gt; {
        System.out.println("异步任务2，当前线程是：" + Thread.currentThread().getId());
        int result = 1 + 2;
        try {
            Thread.sleep(3000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println("异步任务2结束");
        return result;
    }, executorService);

    //开启异步任务3
    CompletableFuture&lt;Integer&gt; task3 = CompletableFuture.supplyAsync(() -&gt; {
        System.out.println("异步任务3，当前线程是：" + Thread.currentThread().getId());
        int result = 1 + 3;
        try {
            Thread.sleep(4000);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println("异步任务3结束");
        return result;
    }, executorService);

    //任务组合
    CompletableFuture&lt;Object&gt; anyOf = CompletableFuture.anyOf(task, task2, task3);
    try {
        //只要有一个有任务完成
        Object o = anyOf.get();
        System.out.println("完成的任务的结果：" + o);
    } catch (InterruptedException e) {
        e.printStackTrace();
    } catch (ExecutionException e) {
        e.printStackTrace();
    }
}
```</content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15348046.html</id>
        <title type="text">ElasticSearch-7入门学习和ik分词器-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-28T07:12:00Z</published>
        <updated>2021-09-28T07:12:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15348046.html" />
        <content type="text"># 文档和索引

Elasticsearch 是一个分布式文档存储。Elasticsearch 不是将信息存储为列状数据的行，而是存储已序列化为 JSON 文档的复杂数据结构。当集群中有多个 Elasticsearch 节点时，存储的文档分布在整个集群中，并且可以从任何节点立即访问。



存储文档后，它会被编入索引，并且可以[近乎实时地进行](https://www.elastic.co/guide/en/elasticsearch/reference/current/near-real-time.html)全面搜索——在1 秒内。Elasticsearch 使用一种称为倒排索引的数据结构，它支持非常快速的全文搜索。倒排索引列出出现在任何文档中的每个唯一单词，并标识每个单词出现在的所有文档



索引可以被认为是文档的优化集合，每个文档都是字段的集合，这些字段是包含数据的键值对。默认情况下，Elasticsearch 索引每个字段中的所有数据，每个索引字段都有一个专用的、优化的数据结构。例如，文本字段存储在倒排索引中，数值和地理字段存储在 BKD 树中。使用每个字段的数据结构来组合和返回搜索结果的能力使 Elasticsearch 如此之快。

[ElasticSearch 7.5 官方文档](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/elasticsearch-intro.html)

# 基本请求

Elasticsearch 提供了一个简单、一致的 REST API 来管理您的集群以及索引和搜索您的数据

## _cat 命令


查看所有节点
```bash
GET _cat/nodes
```

查看es健康状况
```bash
GET _cat/health
```

查看主节点
```bash
GET _cat/master
```

查看所有索引
```bash
GET _cat/indices
```



## POST和PUT

POST 可以添加和修改数据。当指定ID的时候，如果数据不存在则添加，存在则修改，如果不指定ID就是添加，会自动生成一个唯一ID

PUT 可以修改和添加数据。不指定ID会报错，所以一般PUT用于修改。



添加一个文档

```json
POST /person/_doc 	# POST /{index}/_doc/{id} #POST /{index}/_doc #POST /{index}/_create/{id}
{
  "id":1,
  "name":"cy-lemon",
  "age":22
}
```

```json
{
  "_index" : "person", # 数据的所在索引
  "_type" : "_doc", # 数据所在类型
  "_id" : "3Onn93sBHtr2zC8_QGi3", #数据的ID
  "_version" : 1,	# 数据版本
  "result" : "created", # 保存操作
  "_shards" : {		# 分片信息
    "total" : 2,
    "successful" : 1,
    "failed" : 0
  },
  "_seq_no" : 0,
  "_primary_term" : 1
}
```



**_upadte**

当POST更新文档加上_upadte，会检查文档是否发生变化，没有变化版本号就不会+1，

```bash
POST /person/_doc/1/_update
{
  "doc": { 	# 更新文档加上_update时就要 加上 doc
    "id": 2,
    "name": "cy-orange",
    "age": 20
  }
}
```

```json
{
  "_index" : "person",
  "_type" : "_doc",
  "_id" : "1",
  "_version" : 2,
  "result" : "noop", # 当更新文档加上_upadte，会检查文档是否发生变化
  "_shards" : {
    "total" : 0,
    "successful" : 0,
    "failed" : 0
  },
  "_seq_no" : 2,
  "_primary_term" : 1
}
```







## GET 查询文档

以ID查询文档 `GET /{index}/_doc/{id}`

```bash
GET /person/_doc/1
```

```json
{
  "_index" : "person",
  "_type" : "_doc",
  "_id" : "1",
  "_version" : 2,
  "_seq_no" : 2,	#并发控制字段，每次更新就会+1，用来做乐观锁
  "_primary_term" : 1,
  "found" : true,
  "_source" : {		#内容
    "id" : 2,
    "name" : "cy-orange",
    "age" : 20
  }
}
```



## DElETE 删除文档



```bash
DELETE /person/_doc/1
```

```json
{
  "_index" : "person",
  "_type" : "_doc",
  "_id" : "1",
  "_version" : 5,
  "result" : "deleted",
  "_shards" : {
    "total" : 2,
    "successful" : 1,
    "failed" : 0
  },
  "_seq_no" : 5,
  "_primary_term" : 1
}
```



## _bulk 批量操作

 添加多个文档

```json
POST /bank/_bulk
{"index":{"_id":"1"}}
{"account_number":1,"balance":39225,"firstname":"Amber","lastname":"Duke","age":32,"gender":"M","address":"880 Holmes Lane","employer":"Pyrami","email":"amberduke@pyrami.com","city":"Brogan","state":"IL"}
{"index":{"_id":"6"}}
{"account_number":6,"balance":5686,"firstname":"Hattie","lastname":"Bond","age":36,"gender":"M","address":"671 Bristol Street","employer":"Netagy","email":"hattiebond@netagy.com","city":"Dante","state":"TN"}

```



# Query DSL



基本语法

```json
GET /bank/_search
{
  "query": {
    "match_all": {} # 匹配全部
  },
  "sort": [		# 字段排序
    {
      "account_number": {
        "order": "asc"
      }
    }
  ],
  "from": 0, # 第几条开始
  "size": 5,  # 查询多少条
  "_source": ["account_number","firstname","lastname","balance"] # 要返回的字段
}
```



## Match query

分词匹配

```json
GET /bank/_search
{
  "query": {
    "match": {
      "account_number": 0
    }
  }
}
```



## Match phrase query

短语匹配

```json
GET /bank/_search
{
  "query": {
    "match_phrase": {
      "address": "282 Kings Place"
    }
  }
}
```



## Multi-match

多字段匹配，会分词

```json
GET /bank/_search
{
  "query": {
    "multi_match": {
      "query": "Ribera Kings",
      "fields": ["address","city"]
    }
  }
}
```



## bool

- must 满足，gender："M"并且 address："mill"
- must_not 不满足，age ！= 18
- should 希望满足，lastname=Wallace ，不满足也可以

```json
GET /bank/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "match": {
            "gender": "M"
          }
        },
        {
          "match": {
            "address": "mill"
          }
        }
      ],
      "must_not": [
        {
          "match": {
            "age": "18"
          }
        }
      ],
      "should": [
        {
          "match": {
            "lastname": "Wallace"
          }
        }
      ]
    }
  }
}
```



filter 和 must 过滤

区别在于 filter不会计算相关性得分，must会计算相关性得分

must

```json
GET /bank/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "range": {
            "age": {
              "gte": 18,
              "lte": 20
            }
          }
        }
      ]
    }
  }
}
```



filter

```json
GET /bank/_search
{
  "query": {
    "bool": {
      "filter": [
        {
          "range": {
            "age": {
              "gte": 18,
              "lte": 20
            }
          }
        }
      ]
    }
  }
}
```



## Term query



term 和 match 一样，匹配某个属性的值

全文检索字段使用match，其他非text字段匹配使用 term

term

```json
GET /bank/_search
{
  "query": {
    "term": {
      "balance": 39868
    }
  }
}
```



match

```json
GET /bank/_search
{
  "query": {
    "match": {
      "firstname": "Claudia"
    }
  }
}
```



# Aggregations聚合

聚合提供了从数据中分组和和提取数据的能力。最简单的聚合方法大致等于SQL FROUP BY和SQL聚合函数。

聚合分为三类：

- 从字段值中计算指标（如总和或平均值）的公制聚合值。
- 根据字段值、范围或其他标准将文档组组到存储桶（也称为"垃圾箱"）的桶聚合。
- 管道聚合，从其他聚合中而不是从文档或字段中接收输入。

聚合的基本结构：

```json
"aggregations" : {
    "&lt;aggregation_name&gt;" : {
        "&lt;aggregation_type&gt;" : {
            &lt;aggregation_body&gt;
        }
        [,"meta" : {  [&lt;meta_data_body&gt;] } ]?
        [,"aggregations" : { [&lt;sub_aggregation&gt;]+ } ]?
    }
    [,"&lt;aggregation_name_2&gt;" : { ... } ]*
}
```



案例：搜索address中包含maill的所有人的年龄分布以及平均年龄。但不显示这些人的详情。

```json
GET /bank/_search
{
  "query": {
    "match": {
      "address": "mill"
    }
  },
  "aggs": {
    "ageAgg": {
      "terms": {
        "field": "age",
        "size": 10  #比如有100种可能，从中选取前10种
      }
    }
  }
}
```

结果

```json
{
  "took" : 52,
  "timed_out" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 4,
      "relation" : "eq"
    },
    "max_score" : 5.4032025,
    "hits" : [
      {},
      {},
      {},
      {}
      }
    ]
  },
  "aggregations" : {
    "ageAgg" : {
      "doc_count_error_upper_bound" : 0,
      "sum_other_doc_count" : 0,
      "buckets" : [
        {
          "key" : 38,
          "doc_count" : 2
        },
        {
          "key" : 28,
          "doc_count" : 1
        },
        {
          "key" : 32,
          "doc_count" : 1
        }
      ]
    }
  }
}
```



# mapping映射

[映射|弹性搜索指南 7.5 |弹性的 (elastic.co)](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/mapping.html)

映射是定义文档及其包含的字段如何存储和索引的过程。例如，使用映射来定义：

- 哪些字符串字段应视为全文字字段。
- 哪些字段包含数字、日期或地理位置。
- 日期值的[格式](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/mapping-date-format.html)。
- 自定义规则，以控制[动态添加字段的](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/dynamic-mapping.html)映射。

映射定义具有：

- [元字段](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/mapping-fields.html)

  元字段用于自定义如何处理文档的元数据相关内容。元字段的例子包括文档[`的_index、_id`](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/mapping-index-field.html)和[`_source`](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/mapping-source-field.html)字段。

- [字段](https://www.elastic.co/guide/en/elasticsearch/reference/7.5/mapping-types.html)或属性

  映射包含与文档相关的字段列表。`properties`



可以使用创建索引API 创建具有明确映射的新索引。

创建，整数字段age
创建，关键字字段email
创建，文本字段name

```json
PUT /my-index
{
  "mappings": {
    "properties": {
      "age":    { "type": "integer" },
      "email":  { "type": "keyword"  },
      "name":   { "type": "text"  }
    }
  }
}
```



# Ik分词

ElasticSearch内置的分词器不能对中文进行分词，需要安装ik分词插件。

IK提供了两个分词算法：`ik_smart`和`ik_max_word`，其中`ik_smart`为最少切分，`ik_max_word`为最细粒度切分！

## 安装ik分词器插件

在GitHub上下载ElasticSearch版本对应的ik分词器：https://github.com/medcl/elasticsearch-analysis-ik/releases

然后在ElasticSearch安装目录下的plugins目录下创建ik目录，把ik分词器解压到ik目录，这样就完成了ik分词器的安装

测试，在kibana中运行如下例子

```json
POST _analyze
{
  "analyzer": "ik_max_word",
  "text": "今天天气真不错"
}
```

结果

```json
{
  "tokens" : [
    {
      "token" : "今天天气",
      "start_offset" : 0,
      "end_offset" : 4,
      "type" : "CN_WORD",
      "position" : 0
    },
    {
      "token" : "今天",
      "start_offset" : 0,
      "end_offset" : 2,
      "type" : "CN_WORD",
      "position" : 1
    },
    {
      "token" : "天天",
      "start_offset" : 1,
      "end_offset" : 3,
      "type" : "CN_WORD",
      "position" : 2
    },
    {
      "token" : "天气",
      "start_offset" : 2,
      "end_offset" : 4,
      "type" : "CN_WORD",
      "position" : 3
    },
    {
      "token" : "真不错",
      "start_offset" : 4,
      "end_offset" : 7,
      "type" : "CN_WORD",
      "position" : 4
    },
    {
      "token" : "真不",
      "start_offset" : 4,
      "end_offset" : 6,
      "type" : "CN_WORD",
      "position" : 5
    },
    {
      "token" : "不错",
      "start_offset" : 5,
      "end_offset" : 7,
      "type" : "CN_WORD",
      "position" : 6
    }
  ]
}
```

结果可以看到中文短语被分成一个个词语

## 自定义扩展词库

ik分词器只能拆分一些词语，如果是一些人名或者品牌的名字则会被拆分为一个个字，

例如：鸿星尔克球鞋

```json
POST _analyze
{
  "analyzer": "ik_max_word",
  "text": "鸿星尔克球鞋"
}
```

```json
{
  "tokens" : [
    {
      "token" : "鸿",
      "start_offset" : 0,
      "end_offset" : 1,
      "type" : "CN_CHAR",
      "position" : 0
    },
    {
      "token" : "星",
      "start_offset" : 1,
      "end_offset" : 2,
      "type" : "CN_CHAR",
      "position" : 1
    },
    {
      "token" : "尔",
      "start_offset" : 2,
      "end_offset" : 3,
      "type" : "CN_CHAR",
      "position" : 2
    },
    {
      "token" : "克",
      "start_offset" : 3,
      "end_offset" : 4,
      "type" : "CN_CHAR",
      "position" : 3
    },
    {
      "token" : "球鞋",
      "start_offset" : 4,
      "end_offset" : 6,
      "type" : "CN_WORD",
      "position" : 4
    }
  ]
}
```

可以看到，鸿星尔克被分为一个个字，想要实现这类关键字的分词， 需要给ik分词器自定义词库

首先需要一个词库用来存放关键词，然后给ik分词器配置词库的位置。可以使用Nignx来做词库

在Ningx的html目录中创建`ik-word.txt`文件，并写入关键词`鸿星尔克`

 ![](https://img2020.cnblogs.com/blog/1801000/202109/1801000-20210928151459675-435121426.png)


打开ik分词器插件目录下的`config/IKAnalyzer.cfg.xml`配置文件，配置远程词库的位置

```xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd"&gt;
&lt;properties&gt;
	&lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt;
	&lt;!--用户可以在这里配置自己的扩展字典 --&gt;
	&lt;entry key="ext_dict"&gt;&lt;/entry&gt;
	 &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt;
	&lt;entry key="ext_stopwords"&gt;&lt;/entry&gt;
	&lt;!--用户可以在这里配置远程扩展字典 --&gt;
	&lt;entry key="remote_ext_dict"&gt;http://localhost/ik-word.txt&lt;/entry&gt;
	&lt;!--用户可以在这里配置远程扩展停止词字典--&gt;
	&lt;!-- &lt;entry key="remote_ext_stopwords"&gt;words_location&lt;/entry&gt; --&gt;
&lt;/properties&gt;
```

配置好远程词库的位置之后，重启ElasticSearch

运行刚才的例子

```json
POST _analyze
{
  "analyzer": "ik_max_word",
  "text": "鸿星尔克球鞋"
}
```

```json
{
  "tokens" : [
    {
      "token" : "鸿星尔克",
      "start_offset" : 0,
      "end_offset" : 4,
      "type" : "CN_WORD",
      "position" : 0
    },
    {
      "token" : "球鞋",
      "start_offset" : 4,
      "end_offset" : 6,
      "type" : "CN_WORD",
      "position" : 1
    }
  ]
}
```

可看到`鸿星尔克`被分为一个词，自定义词库完成
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15349282.html</id>
        <title type="text">Maven手动安装依赖-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-28T10:21:00Z</published>
        <updated>2021-09-28T10:21:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15349282.html" />
        <content type="text">如果某个依赖在maven中央仓库中没有，或者总是通过maven下载不下来，可以考虑手动安装依赖到Maven本地仓库中

比如说要手动安装`lucene-analyzers-common-8.9.0.jar`, 它的坐标如下
```xml
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;
    &lt;artifactId&gt;lucene-analyzers-common&lt;/artifactId&gt;
    &lt;version&gt;8.9.0&lt;/version&gt;
&lt;/dependency&gt;
```

在jar所在位置打开cmd窗口，执行如下命令，`^` 是cmd中的换行符
```bash
mvn install:install-file ^ -DgroupId=org.apache.lucene ^ -DartifactId=lucene-analyzers-common ^ -Dversion=8.9.0 ^ -Dpackaging=jar ^ -Dfile=lucene-analyzers-common-8.9.0.jar
```</content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15357778.html</id>
        <title type="text">Docker配置镜像加速器-青橙e</title>
        <summary type="html"></summary>
        <published>2021-09-30T09:55:00Z</published>
        <updated>2021-09-30T09:55:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15357778.html" />
        <content type="text">配置阿里的Docker镜像加速器

首先登录阿里云，获取镜像加速器地址

产品-&gt;容器与中间件-&gt;容器服务 ACK
 ![](https://img2020.cnblogs.com/blog/1801000/202109/1801000-20210930174418602-1923853010.png)

管理控制台
 ![](https://img2020.cnblogs.com/blog/1801000/202109/1801000-20210930174556239-964723827.png)

镜像工具-&gt;镜像加速器
 ![](https://img2020.cnblogs.com/blog/1801000/202109/1801000-20210930174750316-26700101.png)


通过修改daemon配置文件/etc/docker/daemon.json来使用加速器
在etc目录下创建docker目录
```bash
sudo mkdir -p /etc/docker
```

创建配置文件写入加速器地址
```bash
sudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'
{
  "registry-mirrors": ["https://g66wjbqs.mirror.aliyuncs.com"]
}
EOF
```

重新加载
```bash
sudo systemctl daemon-reload
```

重启Docker
```bash
sudo systemctl restart docker
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15359744.html</id>
        <title type="text">Docker基本操作-青橙e</title>
        <summary type="html"></summary>
        <published>2021-10-01T09:29:00Z</published>
        <updated>2021-10-01T09:29:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15359744.html" />
        <content type="text"># image镜像操作

搜索可用的镜像，在DockerHub上搜索比较方便
```bash
docker search Nginx
```

拉取镜像，如果不指定版本号，拉取的就是最新版的镜像
```bash
docker pull 镜像名:版本号
```

列出本地镜像
```bash
docker images
```

删除镜像
```bash
docker rmi hello-world
```

# 容器操作

**启动容器**
有了镜像之后， 就可以从镜像启动容器，例如启动一个MySQL容器
`-p 3306:3306`：将容器的3306端口映射到主机的3306端口，左边是主机端口，右边是容器端口。
`--name：MySQL`：给容器取名为MySQL。
`-v /opt/mysql/log:/var/log/mysql`：将日志文件挂载到主机。
`-v /opt/mysql/data:/var/lib/mysql`：将数据文件挂载到主机。
`-v /opt/mysql/conf:/etc/mys`：将配置文件挂载到主机。
`-e MYSQL_ROOT_PASSWORD=orange`：初始化root账户密码。
`-d`： 后台启动。
```bash
docker run -p 3306:3306 --name mysql \
  -v /opt/mysql/log:/var/log/mysql \
  -v /opt/mysql/data:/var/lib/mysql \
  -v /opt/mysql/conf:/etc/mysql \
  -e MYSQL_ROOT_PASSWORD=orange \
  -d mysql:5.7
```

**查看容器**
不加-a选项默认查看启动的容器，加-a选项查看所有容器
```bash
docker ps -a
```

**停止容器**
```bash
docker stop my-nginx
```

**启动已存在的容器**
```bash
docker start my-nginx
```

**删除容器**
可以按照容器id或者容器name删除，可以加-f选项删除正在运行的容器
```bash
docker rm my-tomcat
```

**进入容器**
以交互式的方式进入容器，可以修改容器中的配置等，退出容器命令`exit`
`-i`: 交互式操作。
`-t`: 终端。
`nginx`: nginx容器。
`/bin/bash`：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 /bin/bash
```bash
docker exec -it nginx /bin/bash
```

**拷贝容器中的文件到主机**

```bash
docker cp nginx:/etc/nginx/ /opt/nginx/
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15359852.html</id>
        <title type="text">Docker安装Nginx挂载数据卷-青橙e</title>
        <summary type="html"></summary>
        <published>2021-10-01T10:29:00Z</published>
        <updated>2021-10-01T10:29:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15359852.html" />
        <content type="text">1. 首先启动一个Nginx容器
```bash
docker run --name my-nginx -p 8080:8080 -d nginx
```

2. 进入容器
```bash
docker exec -it my-nginx bash
```

3. 查看Nginx的html、配置和日志目录
- `/etc/nginx`：配置文件的目录
- `/usr/share/nginx/html`：html目录
- `/var/log/nginx`：日志目录
```bash
root@33aab93c60f7:/# find / -name nginx
/etc/default/nginx
/etc/init.d/nginx
/etc/logrotate.d/nginx
/etc/nginx
find: '/proc/1/map_files': Operation not permitted
find: '/proc/31/map_files': Operation not permitted
find: '/proc/32/map_files': Operation not permitted
find: '/proc/38/map_files': Operation not permitted
/usr/lib/nginx
/usr/sbin/nginx
/usr/share/doc/nginx
/usr/share/nginx
/var/cache/nginx
/var/log/nginx
```

4. `exit`退出容器，在/opt下创建nginx目录用来存放html、配置和日志目录
```bash
mkdir /opt/nginx
```

5. 拷贝容器中nginx的配置目录到/opt/nginx，并改名为conf
```bash
docker cp my-nginx:/etc/nginx /opt/nginx

mv /opt/nginx/nginx /opt/nginx/conf
```

6. 删除容器
```bash
docker rm -f my-nginx
```

7. 启动nginx容器并挂载目录
```bash
docker run -p 80:80 --name nginx \
	-v /opt/nginx/conf:/etc/nginx \
	-v /opt/nginx/html:/usr/share/nginx/html \
	-v /opt/nginx/log:/var/log/nginx \
	-d nginx
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15369190.html</id>
        <title type="text">RabbitMQ的延时队列-青橙e</title>
        <summary type="html"></summary>
        <published>2021-10-05T10:31:00Z</published>
        <updated>2021-10-05T10:31:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15369190.html" />
        <content type="text">使用RabbitMQ的作为延时队列，模拟订单超时，解锁库存。

RabbitMQ没有延迟队列，可以用死信队列+普通队列来完成延迟队列的功能。

1. 消息发给交`order.event.exchange`交换机，交换机使用`order.create.order`路由键将消息发给`order.delay.queue`死信队列
2. 死信队列中的消息过期之后，使用`order.event.exchange`交换机和`order.create.order`路由键将消息发给`order.release.queue`队列

 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211005183857905-47981458.png)





创建Spring Boot项目，添加依赖

```xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;version&gt;2.3.12.RELEASE&lt;/version&gt;
        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;
    &lt;/parent&gt;
    &lt;groupId&gt;com.orange&lt;/groupId&gt;
    &lt;artifactId&gt;demo-rabbit-order&lt;/artifactId&gt;
    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
    &lt;properties&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
    &lt;/properties&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;optional&gt;true&lt;/optional&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;excludes&gt;
                        &lt;exclude&gt;
                            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
                            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
                        &lt;/exclude&gt;
                    &lt;/excludes&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
&lt;/project&gt;

```



application.yml中配置RabbitMQ的信息

```yaml
spring:
  rabbitmq:
    host: localhost
    port: 5672
    virtual-host: /
```



定义常量：队列、交换机、路由

```java
package com.orange.rabbitorder.constant;

import lombok.Getter;

@Getter
public enum MQEnum {
    ORDER_DELAY_QUEUE("order.delay.queue","order.event.exchange","order.create.order"),
    ORDER_RELEASE_QUEUE("order.release.queue","order.event.exchange","order.release.order")
    ;

    private String queue;
    private String exchange;
    private String routingKye;

    MQEnum(String queue, String exchange, String routingKye) {
        this.queue = queue;
        this.exchange = exchange;
        this.routingKye = routingKye;
    }
}
```



创建队列、交换机、路由和绑定关系

```java
package com.orange.rabbitorder.config;

import com.orange.rabbitorder.constant.MQEnum;
import org.springframework.amqp.core.Binding;
import org.springframework.amqp.core.Exchange;
import org.springframework.amqp.core.Queue;
import org.springframework.amqp.core.TopicExchange;
import org.springframework.amqp.support.converter.Jackson2JsonMessageConverter;
import org.springframework.amqp.support.converter.MessageConverter;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

import java.util.HashMap;

@Configuration
public class RabbitMQConfig {

    /**
     * 设置消息序列化为json格式传输
     *
     * @return
     */
    @Bean
    public MessageConverter messageConverter() {
        return new Jackson2JsonMessageConverter();
    }

    @Bean
    public Queue orderDelayQueue() {
        /**
         * 创建队列的构造方法
         * Queue(String name, boolean durable, boolean exclusive, boolean autoDelete, @Nullable Map&lt;String, Object&gt; arguments)
         * name：队列的名字
         * durable：是否持久化
         * exclusive：是否排他
         * autoDelete：是否自动删除
         * arguments：自定义属性
         */
        HashMap&lt;String, Object&gt; arguments = new HashMap&lt;&gt;();
        arguments.put("x-dead-letter-exchange", MQEnum.ORDER_DELAY_QUEUE.getExchange());
        arguments.put("x-dead-letter-routing-key", MQEnum.ORDER_RELEASE_QUEUE.getRoutingKye());
        arguments.put("x-message-ttl", 60000);//单位毫秒
        Queue queue = new Queue(MQEnum.ORDER_DELAY_QUEUE.getQueue(), true, false, false, arguments);
        return queue;
    }

    @Bean
    public Queue orderReleaseQueue() {
        Queue queue = new Queue(MQEnum.ORDER_RELEASE_QUEUE.getQueue(), true, false, false);
        return queue;
    }

    @Bean
    public Exchange orderEventExchange() {
        return new TopicExchange(MQEnum.ORDER_RELEASE_QUEUE.getExchange(), true, false);
    }

    @Bean
    public Binding orderCreateOrderBinding() {
        return new Binding(MQEnum.ORDER_DELAY_QUEUE.getQueue(),
                Binding.DestinationType.QUEUE,
                MQEnum.ORDER_DELAY_QUEUE.getExchange(),
                MQEnum.ORDER_DELAY_QUEUE.getRoutingKye(),
                null);
    }

    @Bean
    public Binding orderOrderBinding() {
        return new Binding(MQEnum.ORDER_RELEASE_QUEUE.getQueue(),
                Binding.DestinationType.QUEUE,
                MQEnum.ORDER_RELEASE_QUEUE.getExchange(),
                MQEnum.ORDER_RELEASE_QUEUE.getRoutingKye(),
                null);
    }
}
```



发送消息

```java
@RestController
@RequestMapping("order")
public class OrderController {

    @Autowired
    private RabbitTemplate rabbitTemplate;

    @RequestMapping("createOrder")
    public String createOrder() {
        //创建订单
        //扣减库存
        // 下单成功
        //给mq发消息
        SkuStockDO skuStockDO = new SkuStockDO();
        skuStockDO.setId(123L);
        skuStockDO.setSkuId(1L);
        skuStockDO.setNumber(2);
        rabbitTemplate.convertAndSend(MQEnum.ORDER_DELAY_QUEUE.getExchange(),
                MQEnum.ORDER_DELAY_QUEUE.getRoutingKye(),
                skuStockDO);
        return "下单成功";
    }

}
```



监听消息

```java
package com.orange.rabbitorder.service;

import com.orange.rabbitorder.dataobject.SkuStockDO;
import com.rabbitmq.client.Channel;
import org.springframework.amqp.core.Message;
import org.springframework.amqp.rabbit.annotation.RabbitListener;
import org.springframework.stereotype.Service;


@Service
public class StockService {

    @RabbitListener(queues = {"order.release.queue"})
    public void dcrStock(Message message, SkuStockDO skuStockDO, Channel channel) {
        System.out.println("收到超时的订单，解锁库存：" + skuStockDO);
        System.out.println("解锁库存成功");
    }
}

```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15382597.html</id>
        <title type="text">Docker安装Redis并设置密码-青橙e</title>
        <summary type="html"></summary>
        <published>2021-10-08T11:57:00Z</published>
        <updated>2021-10-08T11:57:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15382597.html" />
        <content type="text">首先在`/opt`下创建`redis`目录，用于存放redis的数据和配置文件
```bash
mkdir /opt/redis

cd /opt/redis
```
创建redis的配置文件，并写入配置`vim /opt/redis/redis.conf`
```bash
#是否持久化
appendonly yes

#设置密码
requirepass orange
```

拉取镜像，默认的版本是latest最新版，可以使用 `docker pull redis:version`指定版本
```bash
docker pull redis
```
启动Redis容器，`redis-server /etc/redis/redis.conf`是指定使用配置文件启动，默认不使用配置文件
```bash
docker run -p 6379:6379 \
	-d --name redis \
	-v /opt/redis/data:/data \
	-v /opt/redis/redis.conf:/etc/redis/redis.conf \
	redis:latest \
	redis-server /etc/redis/redis.conf
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15398468.html</id>
        <title type="text">JMeter压力测试-青橙e</title>
        <summary type="html"></summary>
        <published>2021-10-12T08:30:00Z</published>
        <updated>2021-10-12T08:30:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15398468.html" />
        <content type="text"># 安装JMeter

下载JMeter对应的压缩包：[https://jmeter.apache.org/download_jmeter.cgi](https://jmeter.apache.org/download_jmeter.cgi)
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211012140321744-353819371.png)

解开压缩包，进入bin目录中双击`jmeter.bat` 就可以运行 JMeter
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211012140639439-1263950792.png)

启动完成之后，会出现如下界面
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211012141316992-2032510489.png)

JMeter支持语言设置，默认是英文，可以修改为中文
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211012142657330-1044190318.png)


# 使用JMeter

## 测试计划
首先新建一个测试计划，点击左上角`文件 &gt; 新建`
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211012143516087-1313694230.png)

## 线程组
右键刚才新建的查询计划，添加线程组：
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211012144431875-870043217.png)

 在线程组中设置 线程数、Ramp-Up时间、循环次数，如下图所示：1秒钟启动200个线程循环100次，如果循环次数勾选了永远，需要点击上方的停止按钮
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211012145516023-728921703.png)

## HTTP请求
右键线程组，添加取样器为 HTTP请求
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211012145838023-1420696376.png)

设置HTTP请求：协议、服务器名或IP、端口号、请求方式、路径、参数
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211012150943346-1440168911.png)

## 察看结果树
右键线程组，添加监听器为结果树，结果树可以看到每一次请是成功还是失败，成功的响应结果。
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211012151412666-1519291528.png)

结果树
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211012161724513-1763449456.png)


## 汇总报告
右键线程组，添加监视器为汇总报告
![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211012152110667-638530249.png)

汇总报告的个字段意思：
样本：一共发了多少个请求
平均值：平均每个请求的响应时间
最小值：最小响应时间
最大值：最大响应时间
标准偏差：表示请求的稳定性，值越大也不稳定，说明有的请求快，有的请求慢
异常：所有请求中发生异常的比例
吞吐量：衡量接口每秒可以处理多少个并发请求
接收：每秒接收的数据
发送：每秒发送的数据
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211012161642558-1547530400.png)

最后就可以在HTTP请求中点击测试了
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211012162012475-1008107124.png)
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15412107.html</id>
        <title type="text">MySQL索引创建和删除-青橙e</title>
        <summary type="html"></summary>
        <published>2021-10-15T09:56:00Z</published>
        <updated>2021-10-15T09:56:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15412107.html" />
        <content type="text">## 索引分类
唯一索引：索引列的值必须唯一，但是允许有多个`null`值
单值索引：一个索引只包含单个列，一个表中可以有多个单值索引
符合索引：一个索引包含多个列

## 创建索引


首先创建一张测试表
```sql
CREATE TABLE if not exists `test` (
    `id` BIGINT NOT NULL COMMENT 'id',
    `username` VARCHAR(100) NOT NULL COMMENT '用户名',
    `age` TINYINT not null COMMENT '年龄',
    `gender` TINYINT(1) DEFAULT 0 COMMENT '性别：0-男，1-女',
    `deleted` TINYINT(1) DEFAULT 0 COMMENT '0-未删除，1-已删除',
    PRIMARY KEY (`id`)
  ) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci COMMENT = '测试表';
```
唯一索引：给`username`字段创建唯一索引
```sql
CREATE UNIQUE INDEX uk_test_username ON test(username);
```

单值索引：给`deleted`字段创建单值索引
```sql
`CREATE INDEX index_test_deleted ON test(deleted);`
```

复合索引：给`age` 和 `gender` 字段创建复合索引
```sql
`create INDEX index_test_age_gender ON test(age,gender);`
```
## 查看索引
show index from tableName;
```sql
mysql&gt; show index from test;
+-------+------------+-----------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+
| Table | Non_unique | Key_name              | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | Visible | Expression |
+-------+------------+-----------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+
| test  |          0 | PRIMARY               |            1 | id          | A         |           0 |     NULL |   NULL |      | BTREE      |         |               | YES     | NULL       |
| test  |          0 | uk_test_username      |            1 | username    | A         |           0 |     NULL |   NULL |      | BTREE      |         |               | YES     | NULL       |
| test  |          1 | index_test_deleted    |            1 | deleted     | A         |           0 |     NULL |   NULL | YES  | BTREE      |         |               | YES     | NULL       |
| test  |          1 | index_test_age_gender |            1 | age         | A         |           0 |     NULL |   NULL |      | BTREE      |         |               | YES     | NULL       |
| test  |          1 | index_test_age_gender |            2 | gender      | A         |           0 |     NULL |   NULL | YES  | BTREE      |         |               | YES     | NULL       |
+-------+------------+-----------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+
5 rows in set (0.00 sec)
```

 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211015174612551-152733300.png)

## 删除索引
DROP INDEX indexName ON tableName;

```SQL
DROP index uk_test_username on test;
```</content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15412412.html</id>
        <title type="text">MySQL-DDL-数据定义语言-青橙e</title>
        <summary type="html"></summary>
        <published>2021-10-15T11:34:00Z</published>
        <updated>2021-10-15T11:34:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15412412.html" />
        <content type="text"># 查询数据库
```sql
# 显示当前mysql中的数据库列表
show databases;

# 显示指定名称的数据的创建的SQL指令
show create database &lt;dbName&gt;;

# 切换数据库
use &lt;dbName&gt;
```

# 创建数据库
```sql
# 创建数据库 dbName表示创建的数据库名称，可以⾃定义
create database &lt;dbName&gt;;

## 创建数据库，当指定名称的数据库不存在时执⾏创建
create database if not exists &lt;dbName&gt;;

## 在创建数据库的同时指定数据库的字符集（字符集：数据存储在数据库中采⽤的编码格式utf8 gbk）
create database &lt;dbName&gt; character set utf8;
```

# 修改数据库
```sql
# 修改数据库的字符集
alter database &lt;dbName&gt; character set utf8md4;
```

# 删除数据库
```sql
# 删除数据库
drop database &lt;dbName&gt;;

## 如果数据库存在则删除数据库
drop database is exists &lt;dbName&gt;;
```

# 创建数据表

```sql
# 如果表不存在就创建
CREATE TABLE if not exists `test` (
    `id` BIGINT NOT NULL COMMENT 'id',
    `username` VARCHAR(100) NOT NULL COMMENT '用户名',
    `age` TINYINT not null COMMENT '年龄',
    `gender` TINYINT(1) DEFAULT 0 COMMENT '性别：0-男，1-女',
    `deleted` TINYINT(1) DEFAULT 0 COMMENT '0-未删除，1-已删除',
    PRIMARY KEY (`id`)
  ) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci COMMENT = '测试表';
```

# 查看数据表
```sql
# 查看数据库中有那些表
show tables;

# 查看表的结构
desc &lt;tableName&gt;

# 查看数据表的创建源码
show create table &lt;tableName&gt;;
```

# 删除表
```sql
# 删除数据表
drop table &lt;tableName&gt;;

## 当数据表存在时删除数据表
drop table if exists &lt;tableName&gt;;
```

# 修改表
修改表名
```sql
alter table &lt;tableName&gt; rename to &lt;newTableName&gt;;
```

数据表也是有字符集的，默认字符集和数据库⼀致
```sql
alter table &lt;tableName&gt; character set utf8;
```

## 添加字段
例子：在年龄字段后面添加性别字段
```sql
ALTER Table student add `gender` TINYINT(1) DEFAULT 0 COMMENT '性别：0-男，1-女' after age;
```

## 修改字段的类型
```sql
alter table &lt;tableName&gt; modify &lt;columnName&gt; &lt;newType&gt;;
```

## 修改字段的名字和类型
```sql
alter table &lt;tableName&gt; change &lt;oldColumnName&gt; &lt;newCloumnName&gt; &lt;type&gt;;
```

## 删除字段
```sql
alter table &lt;tableName&gt; drop &lt;columnName&gt;;
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15418942.html</id>
        <title type="text">Windows常用软件-青橙e</title>
        <summary type="html"></summary>
        <published>2021-10-17T16:39:00Z</published>
        <updated>2021-10-17T16:39:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15418942.html" />
        <content type="text">
Redis的客户端 Another Redis Desktop Manager https://github.com/qishibo/AnotherRedisDesktopManager/releases

Redis官方客户端RedisInsight：https://redis.com/redis-enterprise/redis-insight/

增强的Windows终端，SSH客户端：https://mobaxterm.mobatek.net/

Windows系统文件搜索软件：https://www.voidtools.com/zh-cn/downloads

Snipaste是一个简单但功能强大的截图工具：https://www.snipaste.com/</content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15422749.html</id>
        <title type="text">Docker安装MySQL5.7-青橙e</title>
        <summary type="html"></summary>
        <published>2021-10-18T14:45:00Z</published>
        <updated>2021-10-18T14:45:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15422749.html" />
        <content type="text">首先拉取MySQL5.7镜像
```
docker pull mysql:5.7
```

有了镜像之后， 就可以从镜像启动一个MySQL容器
`-p 3306:3306`：将容器的3306端口映射到主机的3306端口，左边是主机端口，右边是容器端口。
`--name：MySQL`：给容器取名为MySQL。
`-v /opt/mysql/log:/var/log/mysql`：将日志文件挂载到主机。
`-v /opt/mysql/data:/var/lib/mysql`：将数据文件挂载到主机。
`-v /opt/mysql/conf:/etc/mys`：将配置文件挂载到主机。
`-e MYSQL_ROOT_PASSWORD=orange`：初始化root账户密码。
`-d`： 后台启动。
```
docker run -p 3306:3306 --name mysql \
  -v /opt/mysql/log:/var/log/mysql \
  -v /opt/mysql/data:/var/lib/mysql \
  -v /opt/mysql/conf:/etc/mysql \
  -e MYSQL_ROOT_PASSWORD=orange \
  -d mysql:5.7 ``` 添加配置，在`/opt/mysql/conf`目录下创建MySQL配置文件`my.cnf`，并加入配置 ``` [client] port=3306 default-character-set=utf8 [mysql] default-character-set=utf8 default-storage-engine=INNODB [mysqld] init_connect='SET collation_connection=utf8_unicode_ci' init_connect='SET NAMES utf8' character-set-server=utf8 collation-server=utf8_unicode_ci
skip-character-set-client-handshake
skip-name-resolve
```

添加配置之后，重启MySQL容器
```
docker restart mysql
```</content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15423125.html</id>
        <title type="text">SQL优化-青橙e</title>
        <summary type="html"></summary>
        <published>2021-10-18T18:32:00Z</published>
        <updated>2021-10-18T18:32:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15423125.html" />
        <content type="text"># 复合索引

1. 必须要使用到最左边的索引列
2. 不能跳过中间的列


# 复合索引失效情况：

1. 使用范围查找会使后面的列索引失效
2. 使用字段运算会使本列索引和后面的索引都失效
3. 数据类型不正确，如果字段的类型是字符串，却给了一个数字，会使本列索引和后面的索引列都失效
4. 模糊查询使用`%`开头会使本列索引和后面的索引列都失效


# or 条件使索引失效情况

如果or连接的查询条件中某一边没有使用索引，索引全都会失效

建议使用union来替换or


# NULL判断索引失效情况

当列中的NULL值比较多的时候，is null 使索引失效；is not null 走索引

当列中的NULL值比较少的时候，is not null 使索引失效；is null 走索引



# in 和 not in 索引失效情况

in 使用索引，not in 不使用索引


# 全表扫描更快的情况

当表中的数据比较少的时候，全表扫描的速度比较快，就会放弃使用索引。


# 覆盖索引
覆盖索引指的是select查询的列都是索引列


# order by优化

MySQL的两种排序方式：

一种是通过有序索引扫描返回有序的数据，叫做using index，效率高

另一种是通过对返回的数据进行排序，叫做using filesort，效率低

排序的时候尽量使用覆盖索引，如果不是覆盖索引，排序方式就using filesort

using filesort排序算法：
1. 两次扫描算法：MySQL4.1之前的排序方式。首先根据条件取出排序字段和行指针信息，然后在排序区 sort buffer 中排序，如果 buffer 不够，则在临时表 temporary table 中存储排序结果，完成排序之后，再根据行指针会表读取记录，该操作可能会导致大量随机I/O操作
2. 一次性取出满足条件的所有字段，然后在排序区 sort buffer 中进行排序后直接输出结果排序时内存开销比较大，但是排序效率比两次扫描算法高

MySQL通过比较系统变量 `max_length_for_sort_data` 的大小和Query语句取出的字段总大小，来判断使用什么排序算法，如果`max_length_for_sort_data` 比较大，那么使用一次扫描算法，否则使用两次扫描算法
可以适当提高 `sort_buffer_size` 和 `max_length_for_sort_data` 系统变量，来增大排序区的大小，提高排序的效率
```bash
mysql&gt; show variables like 'sort_buffer_size';
+------------------+--------+
| Variable_name    | Value  |
+------------------+--------+
| sort_buffer_size | 262144 |
+------------------+--------+
1 row in set, 1 warning (0.00 sec)

mysql&gt; show variables like 'max_length_for_sort_data';
+--------------------------+-------+
| Variable_name            | Value |
+--------------------------+-------+
| max_length_for_sort_data | 4096  |
+--------------------------+-------+
1 row in set, 1 warning (0.00 sec)

mysql&gt; set global sort_buffer_size=262144;
Query OK, 0 rows affected (0.10 sec)

mysql&gt; set global max_length_for_sort_data=4096;
Query OK, 0 rows affected, 1 warning (0.00 sec)
```


多字段排序需要注意：
1. 当使用多个字段排序的时候，如果一个升序一个降序， 即使参与排序的列都有索引，排序方式都会是using filesort，效率低
2. 参与排序的字段顺序必须按照复合索引列的顺序，排序方式都会是using filesort


# group by优化

经常需要分组的字段可以考虑创建索引

在进行group by分组的时候，默认会对分组的列进行排序，没有索引的字段进行排序需要扫描数据文件，非常耗时。如果不想使用这个排序操作，可以在group by 后加上 order by null

```sql
select age,count(*) from user group by order by null;
```


# or 条件优化
如果 or 条件的有一边没有使用索引，索引都会失效

建议使用union来替换or条件


# limit 分页优化
当表中的数据量很大，分页查询后面的记录，速度就会特别慢，因为MySQL需要排序查询前面的记录，直到查询到需要的那一页，然后丢弃前面的记录，返回需要的那一页数据，查询排序的速度很慢

优化方式一：在主键上完成排序分页操作，然后根据主键关联查询其他列数据
```sql
SELECT * FROM user a , (SELECT id FROM user ORDER BY id LIMIT 2000000 ,10) b WHERE a.id=b.id; ``` 优化方式二：如果表中的id是连续自增的，根据查询的页数和查询的记录数可以算出查询的id的范围 比如说要查询第10页，查20条。id=(currentPage-1)pageSize+1=(10-1)*20=180

```sql
select * from `user` where id &gt; 180 limit 10;
```


# 索引提示

如果表中的某列是单值索引列，同时也是复合索引中的最左索引列，在使用到这个列做条件查找时，数据库会选择使用该列其中的一个索引

如果想自己决定该列使用哪个索引，可以在where关键字前加 use index(indexName)
```sql
select * from user use index(idx_username) where username='青橙ee';
```

ignore index(indexName) 忽略某个索引
force index(indexName) 强制使用某个索引，即使全表扫描会更快


# MySQL查询缓存

开启MySQL的查询缓存，当执行完全相同的SQL语句时，MySQL服务器就会直接从缓存中读取结果，当数据被修改，之前的缓存就会失效，修改比较频繁的表不适合做查询缓存

MySQL的查询缓存功能在MySQL8.0被移除了，因为现在缓存更多是做在应用逻辑层或者使用一些NoSQL型数据库

## 查询缓存的配置参数

查看MySQL是否支持查询缓存
```bash
mysql&gt; show variables like 'have_query_cache';
+------------------+-------+
| Variable_name    | Value |
+------------------+-------+
| have_query_cache | YES   |
+------------------+-------+
1 row in set (0.00 sec)
```

查看MySQL是否开启了查询缓存，OFF表示关闭，ON表示开启
```bash
mysql&gt; show variables like 'query_cache_type';
+------------------+-------+
| Variable_name    | Value |
+------------------+-------+
| query_cache_type | OFF   |
+------------------+-------+
1 row in set (0.00 sec)
```

查看查询缓存的占用大小，单位时字节
```bash
mysql&gt; show variables like 'query_cache_size';
+------------------+---------+
| Variable_name    | Value   |
+------------------+---------+
| query_cache_size | 1048576 |
+------------------+---------+
1 row in set (0.00 sec)
```

查看缓存的信息
Qcache_free_blocks：可用的内存块
Qcache_free_memory：可用的内存空间
Qcache_hits：查询缓存的命中次数
Qcache_inserts：添加到查询缓存的次数
Qcache_lowmem_prunes：内存空间不足，从缓存中移除数据的次数
Qcache_not_cached：未做缓存的次数
Qcache_total_blocks：查询缓存中的内存块总数
```bash
mysql&gt; show status like 'qcache%';
+-------------------------+---------+
| Variable_name           | Value   |
+-------------------------+---------+
| Qcache_free_blocks      | 1       |
| Qcache_free_memory      | 1031832 |
| Qcache_hits             | 0       |
| Qcache_inserts          | 0       |
| Qcache_lowmem_prunes    | 0       |
| Qcache_not_cached       | 1       |
| Qcache_queries_in_cache | 0       |
| Qcache_total_blocks     | 1       |
+-------------------------+---------+
8 rows in set (0.00 sec)
```

## 开启查询缓存
MySQL的查询缓存默认时关闭的，需要手动配置参数`query_cache_type`开启查询缓存，这个参数的取值有三个
- OFF或0：查询缓存关闭
- ON或1：查询缓存开启
- DEMAND或2：查询缓存按需进行，显示指定SQL_CACHE的select的语句才会缓存 在MySQL的配置文件中加上如下配置，开启查询缓存 ``` query_cache_type=1
```
配置之后重启MySQL服务才可以 生效


查询缓存select选项：
- select SQL_CACHE * FROM USER：从缓存中获取结果，如果没有，就执行查询并缓存结果
- select SQL_NO_CACHE * FROM USER：不会从缓存中获取结果，查询的结果也不会缓存


## 查询缓存失效场景

1. SQL语句不一致的情况
2. 当查询语句有一些不确定时，不会缓存。如：`select * from user where update_time &lt; now()`
3. 查询MySQL系统表的时候不会缓存
4. 当执行更新操作之后，查询缓存失效</content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15423127.html</id>
        <title type="text">MySQL的四种日志-青橙e</title>
        <summary type="html"></summary>
        <published>2021-10-18T18:39:00Z</published>
        <updated>2021-10-18T18:39:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15423127.html" />
        <content type="text">在MySQL中，有4种不同的日志，分别是错误日志、二进制日志（BINLOG日志）、查询日志和慢查询日志

# 错误日志

错误日志记录了MySQL在启动、停止、以及服务器在运行过程中发生任何严重错误的相关信息。

该日志是默认开启的，查看错误日志的位置
```bash
mysql&gt; show variables like 'log_error%';
+----------------------------+----------------------------------------+
| Variable_name              | Value                                  |
+----------------------------+----------------------------------------+
| log_error                  | .\XIEJINCHI.err                        |
| log_error_services         | log_filter_internal; log_sink_internal |
| log_error_suppression_list |                                        |
| log_error_verbosity        | 2                                      |
+----------------------------+----------------------------------------+
4 rows in set, 1 warning (0.06 sec)
```

# 二进制日志

二进制日志（BINLOG日志）记录了所有DDL（数据库定义语言）语句和DML（数据操纵语言）语句，但是不包括查询语句，此日志对于灾难时的数据恢复有非常重要的作用，MySQL的主从复制，就是通过该日志实现的

二进制日志默认情况下是没有开启的，需要到MySQL的配置文件中开启，并配置MySQL日志的格式

查看binlog日志是否开启
```
mysql&gt; show variables like '%log_bin%';
+---------------------------------+-------+
| Variable_name                   | Value |
+---------------------------------+-------+
| log_bin                         | OFF   |
| log_bin_basename                |       |
| log_bin_index                   |       |
| log_bin_trust_function_creators | OFF   |
| log_bin_use_v1_row_events       | OFF   |
| sql_log_bin                     | ON    |
+---------------------------------+-------+
6 rows in set (0.00 sec) ``` 开启binlog，如果没有指定日志文件的路径，默认写入MySQL的数据目录 ``` #文件名 log-bin=mysql-bin #序列号 server-id=1 #日志格式 binlog_format=STATEMENT
```
在 MySQL 5.7.3 及以后版本,如果没有设置server-id, 那么设置binlog后无法开启MySQL服务


日志格式
**STATEMENT**
这个格式的日志文件中记录的都是SQL语句，每一条对数据进行修改的SQL都会记录在日志文件中，通过MySQL提供的mysqlbinlog工具，可以清晰的查看到每一条语句的文本，主从复制的时候，从库（slave）会将日志解析为原文本，并在从库重新执行一次

**ROW**
这个格式的日志文件记录的是每一行数据的变更，而不是SQL语句

**MIXED**
这个是目前MySQL默认的日志格式，混合了STATEMENT和ROW两种格式，默认情况下使用STATEMENT,但是在一些特殊情况下采用ROW来进行记录。MIXED格式能尽量利用两种模式的优点，而避开它们的缺点。

查看binlog日志
查看日志文件存放的位置
```
mysql&gt; show variables like '%log_bin%';
+---------------------------------+--------------------------------+
| Variable_name                   | Value                          |
+---------------------------------+--------------------------------+
| log_bin                         | ON                             |
| log_bin_basename                | /var/lib/mysql/mysql-bin       |
| log_bin_index                   | /var/lib/mysql/mysql-bin.index |
| log_bin_trust_function_creators | OFF                            |
| log_bin_use_v1_row_events       | OFF                            |
| sql_log_bin                     | ON                             |
+---------------------------------+--------------------------------+
6 rows in set (0.00 sec)
```
mysql-bin.index：是日志的索引文件，记录日志的文件名
mysql-bin：是日志文件



查看binlog文件列表 `show binary logs;`

查看binlog文件内容 `show binlog events in 'mysql-bin.000001';`




binlog日志的删除
对于比较繁忙的系统，由于每天生成大量的日志，这些日志如果长时间不清除，就会占用大量的磁盘空间

删除方式一：通过 Reset Master 指令删除全部日志，日志编号重新开始
```
mysql&gt; reset master;
Query OK, 0 rows affected (0.00 sec)
```

删除方式二：删除指定编号之前的日志文件，比如删除mysql-bin.000001之前的文件
```
mysql&gt; purge master logs to 'mysql-bin.000001';
Query OK, 0 rows affected (0.00 sec)
```

删除方式三：删除某个时间点之前的日志
```
mysql&gt; purge master logs before '2021-10-19 00:00:00 ';
Query OK, 0 rows affected, 1 warning (0.01 sec)
```

删除方式四：设置日志的过期时间，单位为天，到期自动删除日志
查看binlog的过期时间
```
mysql&gt; show variables like "%expire_logs%";
+------------------+-------+
| Variable_name    | Value |
+------------------+-------+
| expire_logs_days | 0     |
+------------------+-------+
1 row in set (0.01 sec)
```
0 表示永不过期 修改MySQL配置文件，设置binlog过期时间，然后重启MySQL ``` expire_logs_days=15 #达到过期时间并不会立即删掉，binlog大小超过max_binlog_size才会删掉 max_binlog_size=500M
```


# 查询日志

查询日志中记录了客户端所有操作语句，包括select语句

查看查询日志是否开启，OFF表示未开启
```
mysql&gt; show variables like "general_log%";
+------------------+---------------------------------+
| Variable_name    | Value                           |
+------------------+---------------------------------+
| general_log      | OFF                             |
| general_log_file | /var/lib/mysql/d6e04edbfb09.log |
+------------------+---------------------------------+
2 rows in set (0.00 sec) ``` 查询日志默认是未开启的，可以修改MySQL配置文件来开启 ``` #开启查询日志，1-开启，0-关闭 general-log=1 #设置日志的文件名，默认的文件名为host_name.log general_log_file=/var/log/mysql/general_log.log
```



# 慢查询日志 MySQL默认10s内没有响应SQL结果，则为慢查询 可以修改这个默认时间 慢查询日志默认是关闭的，修改MySQL配置文件，来开启慢查询日志 ``` #开启慢查询日志，0-关闭，1-开启 slow_query_log=1 #指定慢查询日志的文件名 slow_query_log_file=/var/log/mysql/slow_query.log #查询超过这个时间就记录为慢查询,单位是秒 long_query_time=3
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15427127.html</id>
        <title type="text">Docker搭建MySQL5.7主从复制-青橙e</title>
        <summary type="html"></summary>
        <published>2021-10-19T16:18:00Z</published>
        <updated>2021-10-19T16:18:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15427127.html" />
        <content type="text">MySQL复制是指将主数据库的DDL和DML操作通过binlog日志传到从库服务器中，然后在从库上对这些日志从新执行，从而达到从库和主库的数据保持同步

MySQL支持一台主库同时向多台从库进行复制，从库同时也可以作为其他从服务器的主库，实现链状复制

主从复制流程
1. Master 主库在事务提交时，会把数据变更作为时间Events记录在binglog日志中
2. Master推送binlog中的日志事件到Slave的中继日志Relay Log
3. Slave重做Relay log中的事件，从而达到复制的效果

主从复制至少需要一主一从两个MySQL服务器节点
Master 192.168.232.133
Slave 192.168.232.134 配置Master 在MySQL主节点的配置文件中添加如下配置，然后重启MySQL服务 ``` #在集群中需要是唯一的 server-id=1

#binglog日志 log-bin=mysql-bin
```

Master创建同步数据的账户，并给予权限
用户名：orange，密码：orange123，权限是所有库所有表

```
mysql&gt; grant replication slave on *.* 'orange'@'192.168.232.134' identified by 'orange123';
```

创建用户和给用户授权也可以分开写
```
mysql&gt; CREATE USER 'orange'@'192.168.232.134' IDENTIFIED BY 'orange123';

mysql&gt; GRANT REPLICATION SLAVE ON *.* TO 'orange'@'192.168.232.134';
```

刷新权限列表
```
mysql&gt; flush privileges;
```

查看主节点状态，主要查看File字段和Position字段的值，下面配置slave时会用到

```
mysql&gt; show master status;
+------------------+----------+--------------+------------------+-------------------+
| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
+------------------+----------+--------------+------------------+-------------------+
| mysql-bin.000001 |      771 |              |                  |                   |
+------------------+----------+--------------+------------------+-------------------+
1 row in set (0.00 sec) ``` 配置Slave 在MySQL的Slave节点的配置文件中添加如下配置，然后重启服务 ``` #MySQL服务端id，需要是集群中唯一的 server-id=2 #binlog文件名 log-bin=mysql-bin #是否只读：1-只读，0-读写，但是特权用户还是可以读写 read-only=1 #不需要同步的数据库 binlog-ignore-db=mysql
```

在Slave节点配置主从通信
```
change master to \ master_host='192.168.232.133',\ master_user='orange',\ master_password='orange123',\ master_log_file='mysql-bin.000001',\ master_log_pos=771; ``` 其中`master_log_file='mysql-bin.000001'`和`master_log_pos=771`的值就是刚才查看master节点状态信息中的值


启动从服务器复制线程

```
mysql&gt; start slave;
```

查看复制状态

```
mysql&gt; show slave status\G;
```
`Slave_IO_State` Slave的当前状态
`Slave_IO_Running： Yes`：读取主程序二进制日志的I/O线程是否正在运行
`Slave_SQL_Running： Yes`：执行读取主服务器中二进制日志事件的SQL线程是否正在运行。
`Seconds_Behind_Master `：是否为0，0就是已经同步了


其中`Slave_IO_Running`和`Slave_SQL_Running`的值必须是yes


需要停止复制可以关闭slave的复制线程

```
mysql&gt; stop slave;
```</content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15431657.html</id>
        <title type="text">SpringBoot+MyBatis-Plus多数据源操作MySQL读写分离-青橙e</title>
        <summary type="html"></summary>
        <published>2021-10-20T21:48:00Z</published>
        <updated>2021-10-20T21:48:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15431657.html" />
        <content type="text">MySQL做了读写分离，一主两从。主服务器写数据，从服务器只可以读数据，不可以写数据

所以现在有三个数据源，写一个，读两个

使用MyBatis-Plus的多数据源来做数据源的切换

加入依赖
```xml
&lt;dependency&gt;
    &lt;groupId&gt;com.baomidou&lt;/groupId&gt;
    &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;3.4.2&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.baomidou&lt;/groupId&gt;
    &lt;artifactId&gt;dynamic-datasource-spring-boot-starter&lt;/artifactId&gt;
    &lt;version&gt;3.4.1&lt;/version&gt;
&lt;/dependency&gt;
```



配置多数据源

```yaml
spring:
  datasource:
    dynamic:
      primary: master #设置默认的数据源或者数据源组,默认值即为master
      strict: false #严格匹配数据源,默认false. true未匹配到指定数据源时抛异常,false使用默认数据源
      datasource:
        master:
          url: jdbc:mysql://192.168.43.208:3306/test?serverTimezone=GMT%2B8&amp;characterEncoding=utf-8
          username: root
          password: orange
          driver-class-name: com.mysql.cj.jdbc.Driver # 3.2.0开始支持SPI可省略此配置
        slave_1:
          url: jdbc:mysql://192.168.43.163:3306/test?serverTimezone=GMT%2B8&amp;characterEncoding=utf-8
          username: orange123
          password: orange123
          driver-class-name: com.mysql.cj.jdbc.Driver
        slave_2:
          url: jdbc:mysql://192.168.43.116:3306/test?serverTimezone=GMT%2B8&amp;characterEncoding=utf-8
          username: orange
          password: orange123
          driver-class-name: com.mysql.cj.jdbc.Driver
```





约定

1. 本框架只做 **切换数据源** 这件核心的事情，并**不限制你的具体操作**，切换了数据源可以做任何CRUD。
2. 配置文件所有以下划线 `_` 分割的数据源 **首部** 即为组的名称，相同组名称的数据源会放在一个组下。
3. 切换数据源可以是组名，也可以是具体数据源名称。组名则切换时采用负载均衡算法切换。
4. 默认的数据源名称为 **master** ，你可以通过 `spring.datasource.dynamic.primary` 修改。
5. 方法上的注解优先于类上注解。
6. DS支持继承抽象类上的DS，暂不支持继承接口上的DS。





使用 **@DS** 切换数据源。

**@DS** 可以注解在方法上或类上，**同时存在就近原则 方法上注解 优先于 类上注解**。

|     注解      |                   结果                   |
| :-----------: | :--------------------------------------: |
|    没有@DS    |                默认数据源                |
| @DS("dsName") | dsName可以为组名也可以为具体某个库的名称 |

```java
@Service
public class UserServiceImpl extends ServiceImpl&lt;UserMapper, UserDO&gt; implements UserService {

    @DS("master")
    @Override
    public ResponseData&lt;Void&gt; addUser(UserDO userDO) {
        int insert = baseMapper.insert(userDO);
        if (insert &lt; 1) {
            new ResponseData&lt;Void&gt;().field();
        }
        return new ResponseData&lt;Void&gt;().ok();
    }

    @DS("slave")
    @Override
    public ResponseData&lt;UserDO&gt; getUserById(Long id) {
        return new ResponseData&lt;UserDO&gt;().ok(super.getById(id));
    }
}
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15440368.html</id>
        <title type="text">XXL-JOB分布式定时任务-青橙e</title>
        <summary type="html"></summary>
        <published>2021-10-22T11:29:00Z</published>
        <updated>2021-10-22T11:29:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15440368.html" />
        <content type="text">xxl-job分布式定时任务分为两个部分：调度中心和执行器；

调度中心通过Web页面对任务进行CRUD操作，统一管理任务调度平台上调度任务，负责触发调度执行。

执行器是要处理的任务

下面看一下怎么使用xxl-job分布式定时任务

# 初始化数据库

请下载项目源码并解压，获取 “调度数据库初始化SQL脚本” 并执行即可。
Github地址： https://github.com/xuxueli/xxl-job
码云地址：http://gitee.com/xuxueli0323/xxl-job

“调度数据库初始化SQL脚本” 位置为:
```
/xxl-job/doc/db/tables_xxl_job.sql
```
调度中心支持集群部署，集群情况下各节点务必连接同一个mysql实例;

如果mysql做主从,调度中心集群节点务必强制走主库;

# 部署调度中心
将下载的的xxl-job项目导入到IDEA中
```
xxl-job
  doc SQL脚本
  xxl-job-admin：调度中心
  xxl-job-core：公共依赖
  xxl-job-executor-samples：执行器Sample示例（选择合适的版本执行器，可直接使用，也可以参考其并将现有项目改造成执行器）
    ：xxl-job-executor-sample-springboot：Springboot版本，通过Springboot管理执行器，推荐这种方式； ：xxl-job-executor-sample-frameless：无框架版本； pom.xml ``` 配置调度中心，主要配置调度中心的数据源 ``` server.port=9990 server.servlet.context-path=/xxl-job-admin

### 调度中心JDBC链接，就是刚才创建的数据库 spring.datasource.url=jdbc:mysql://127.0.0.1:3306/xxl_job?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;serverTimezone=Asia/Shanghai spring.datasource.username=root spring.datasource.password=root_pwd spring.datasource.driver-class-name=com.mysql.jdbc.Driver

### 报警邮箱 spring.mail.host=smtp.qq.com spring.mail.port=25 spring.mail.username=xxx@qq.com spring.mail.password=xxx spring.mail.properties.mail.smtp.auth=true spring.mail.properties.mail.smtp.starttls.enable=true spring.mail.properties.mail.smtp.starttls.required=true spring.mail.properties.mail.smtp.socketFactory.class=javax.net.ssl.SSLSocketFactory

### 调度中心通讯TOKEN [选填]：非空时启用； xxl.job.accessToken=

### 调度中心国际化配置 [必填]： 默认为 "zh_CN"/中文简体, 可选范围为 "zh_CN"/中文简体, "zh_TC"/中文繁体 and "en"/英文； xxl.job.i18n=zh_CN

## 调度线程池最大线程配置【必填】 xxl.job.triggerpool.fast.max=200 xxl.job.triggerpool.slow.max=100

### 调度中心日志表数据保存天数 [必填]：过期日志自动清理；限制大于等于7时生效，否则, 如-1，关闭自动清理功能； xxl.job.logretentiondays=30
```

如果已经正确进行上述配置，可将 xxl-job-admin 项目编译打包部署。

调度中心访问地址：http://localhost:8080/xxl-job-admin (该地址执行器将会使用到，作为回调地址)

默认登录账号 “admin/123456”, 登录后运行界面如下图所示。
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211022182736019-427967154.png)


调度中心支持集群部署，提升调度系统容灾和可用性。

调度中心集群部署时，几点要求和建议：

DB配置保持一致；
集群机器时钟保持一致（单机集群忽视）；
建议：推荐通过nginx为调度中心集群做负载均衡，分配域名。调度中心访问、执行器回调配置、调用API服务等操作均通过该域名进行。

# 创建执行器项目

创建一个SpringBoot项目，加入xxl-job-core” 的maven依赖
```
&lt;dependency&gt;
    &lt;groupId&gt;com.xuxueli&lt;/groupId&gt;
    &lt;artifactId&gt;xxl-job-core&lt;/artifactId&gt;
    &lt;version&gt;2.3.0&lt;/version&gt;
&lt;/dependency&gt;
```

添加配置
```yaml
server:
  port: 8081

xxl:
  job:
    # 执行器通讯TOKEN [选填]：非空时启用；
    accessToken:
    # 调度中心部署跟地址 [选填]：如调度中心集群部署存在多个地址则用逗号分隔。
    #执行器将会使用该地址进行"执行器心跳注册"和"任务结果回调"；为空则关闭自动注册；
    admin:
      addresses: http://127.0.0.1:9990/xxl-job-admin
    executor:
      # 执行器IP [选填]：默认为空表示自动获取IP，
      # 多网卡时可手动设置指定IP，该IP不会绑定Host仅作为通讯实用；
      #  地址信息用于 "执行器注册" 和 "调度中心请求并触发任务"；
      ip:
      # 执行器端口号 [选填]：小于等于0则自动获取；默认端口为9999，单机部署多个执行器时，注意要配置不同执行器端口；
      port: 9999
      # 执行器注册 [选填]：优先使用该配置作为注册地址，为空时使用内嵌服务 ”IP:PORT“ 作为注册地址。从而更灵活的支持容器类型执行器动态IP和动态映射端口问题。
      address:
      # 执行器AppName [选填]：执行器心跳注册分组依据；为空则关闭自动注册
      appname: xxl-job-demo
      # 执行器运行日志文件存储磁盘路径 [选填] ：需要对该路径拥有读写权限；为空则使用默认路径；
      logpath: E:/log/xxl-job-demo
      # 执行器日志文件保存天数 [选填] ： 过期日志自动清理, 限制值大于等于3时生效; 否则, 如-1, 关闭自动清理功能；
      logretentiondays: 30
```

配置执行器组件
```java
@Configuration
public class XxlJobConfig {
    private Logger logger = LoggerFactory.getLogger(XxlJobConfig.class);

    @Value("${xxl.job.admin.addresses}")
    private String adminAddresses;

    @Value("${xxl.job.accessToken}")
    private String accessToken;

    @Value("${xxl.job.executor.appname}")
    private String appname;

    @Value("${xxl.job.executor.address}")
    private String address;

    @Value("${xxl.job.executor.ip}")
    private String ip;

    @Value("${xxl.job.executor.port}")
    private int port;

    @Value("${xxl.job.executor.logpath}")
    private String logPath;

    @Value("${xxl.job.executor.logretentiondays}")
    private int logRetentionDays;


    @Bean
    public XxlJobSpringExecutor xxlJobExecutor() {
        logger.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; xxl-job config init.");
        XxlJobSpringExecutor xxlJobSpringExecutor = new XxlJobSpringExecutor();
        xxlJobSpringExecutor.setAdminAddresses(adminAddresses);
        xxlJobSpringExecutor.setAppname(appname);
        xxlJobSpringExecutor.setAddress(address);
        xxlJobSpringExecutor.setIp(ip);
        xxlJobSpringExecutor.setPort(port);
        xxlJobSpringExecutor.setAccessToken(accessToken);
        xxlJobSpringExecutor.setLogPath(logPath);
        xxlJobSpringExecutor.setLogRetentionDays(logRetentionDays);
        return xxlJobSpringExecutor;
    }

    /**
     * 针对多网卡、容器内部署等情况，可借助 "spring-cloud-commons" 提供的 "InetUtils" 组件灵活定制注册IP；
     *
     *      1、引入依赖：
     *          &lt;dependency&gt;
     *             &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;
     *             &lt;artifactId&gt;spring-cloud-commons&lt;/artifactId&gt;
     *             &lt;version&gt;${version}&lt;/version&gt;
     *         &lt;/dependency&gt;
     *
     *      2、配置文件，或者容器启动变量
     *          spring.cloud.inetutils.preferred-networks: 'xxx.xxx.xxx.'
     *
     *      3、获取IP
     *          String ip_ = inetUtils.findFirstNonLoopbackHostInfo().getIpAddress();
     */
}
```

开发第一个任务
```java
@Slf4j
@Component
public class TestJobHandler  {

    @XxlJob("productJobHandler")
    public void productJobHandler() throws Exception {
        log.info("test xxl-job productJobHandler....");
    }
}
```

接下来去调度中心 添加执行器，配置执行器任务的触发时间，打开调度中心 http://localhost:9990/xxl-job-admin/

点击左侧导航栏的 执行器管理 新增
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211022190014198-1930481782.png)


AppName就是刚才在执行器项目中配置的`执行器AppName`，注册方式选择 自动注册

 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211022190534562-961457538.png)


添加任务
点击左侧导航栏的 任务管理 &gt; 新增，执行器选择刚才添加的执行器，JobHandler就是刚才在执行器项目中` @XxlJob("productJobHandler")`注解中的值
CRON 选择执行的时间，这里是每米执行一次，还可以填写邮箱，任务执行出错时会发邮件提醒
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211022191540436-903425630.png)


执行任务，点击刚才添加的这条记录后面的操作按钮下拉列表，启动
 ![](https://img2020.cnblogs.com/blog/1801000/202110/1801000-20211022192111428-98363790.png)
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15460046.html</id>
        <title type="text">Spring Boot整合ElasticSearch7-青橙e</title>
        <summary type="html"></summary>
        <published>2021-10-25T11:12:00Z</published>
        <updated>2021-10-25T11:12:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15460046.html" />
        <content type="text"># ElasticSearch的Java客户端

官方文档：https://www.elastic.co/guide/en/elasticsearch/client/index.html

Java REST 客户端有两种风格：

- Java 低级 REST 客户端：Elasticsearch 的官方低级客户端。它允许通过 http 与 Elasticsearch 集群通信。将请求编组和响应取消编组给用户。它与所有 Elasticsearch 版本兼容。
- Java 高级 REST 客户端：Elasticsearch 的官方高级客户端。基于低级客户端，它公开 API 特定方法并处理请求编组和响应解组。

一般使用高级的REST客户端，因为它对低级的REST客户端做了封装，比较方便。

Java高级  REST Client 至少需要 Java 1.8 并且依赖于 Elasticsearch 核心项目。客户端版本与开发客户端的 Elasticsearch 版本相同。

Java高级  REST Client 的Maven仓库

```xml
&lt;dependency&gt;
    &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt;
    &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt;
    &lt;version&gt;7.14.2&lt;/version&gt;
&lt;/dependency&gt;
```



# Spring Boot整合ElasticSearch

创建Spring Boot项目，引入ElasticSearch的Java 高级 REST 客户端依赖，并修改Elasticsearch 核心项目依赖的版本，因为在Spring Boot项目的父项目依赖管理中定义了ElasticSearch核心项目依赖的版本，所以要修改为自己的版本

```xml
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;version&gt;2.4.11&lt;/version&gt;
        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;
    &lt;/parent&gt;
    &lt;groupId&gt;com.example&lt;/groupId&gt;
    &lt;artifactId&gt;demo-elasticsearch&lt;/artifactId&gt;
    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;

    &lt;properties&gt;
        &lt;java.version&gt;1.8&lt;/java.version&gt;
        &lt;elasticsearch.version&gt;7.14.0&lt;/elasticsearch.version&gt;
    &lt;/properties&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt;
            &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt;
            &lt;version&gt;7.14.0&lt;/version&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;

&lt;/project&gt;

```



配置`RestHighLevelClient` 和 `RequestOptions `

```java
@Configuration
public class ElasticSearchConfig {

    public static final RequestOptions COMMON_OPTIONS;

    static {
        RequestOptions.Builder builder = RequestOptions.DEFAULT.toBuilder();
/*        builder.addHeader("Authorization", "Bearer " + TOKEN);
        builder.setHttpAsyncResponseConsumerFactory(
                new HttpAsyncResponseConsumerFactory
                        .HeapBufferedResponseConsumerFactory(30 * 1024 * 1024 * 1024));*/
        COMMON_OPTIONS = builder.build();
    }

    @Bean
    public RestHighLevelClient restHighLevelClient() {
        return new RestHighLevelClient(
                RestClient.builder(
                        new HttpHost("127.0.0.1", 9200, "http")));
    }
}
```



## 保存数据

可以保存数据，也可以修改数据，多次保存同一个数据version值会增加

```java
@SpringBootTest
class DemoElasticsearchApplicationTests {

    @Autowired
    private RestHighLevelClient restClient;

    @Test
    void indexRequest() throws IOException {
        //创建索引
        IndexRequest request = new IndexRequest("users");
        //数据的id
        request.id("1");
        User user = new User();
        user.setId(1L);
        user.setName("青橙");
        user.setAge(25);
        user.setGender("男");
        String jsonString = JSON.toJSONString(user);
        request.source(jsonString, XContentType.JSON);
        IndexResponse response = restClient.index(request, ElasticSearchConfig.COMMON_OPTIONS);
        System.out.println(response);
    }
}
```



## 更新数据

当数据没有发生改变时，元数据的version值也不会增加

```java
@SpringBootTest
class DemoElasticsearchApplicationTests {

    @Autowired
    private RestHighLevelClient restClient;

    @Test
    void updateRequest() throws IOException {
        UpdateRequest request = new UpdateRequest("users", "1");
        User user = new User();
        user.setName("青橙ee");
        String jsonString = JSON.toJSONString(user);
        request.doc(jsonString, XContentType.JSON);
        UpdateResponse updateResponse = restClient.update(request, ElasticSearchConfig.COMMON_OPTIONS);
        System.out.println(updateResponse);
    }
}
```



## 获取数据

根据文档的id来获取数据

```java
@SpringBootTest
class DemoElasticsearchApplicationTests {

    @Autowired
    private RestHighLevelClient restClient;

    @Test
    void getRequest() throws IOException {
        GetRequest request = new GetRequest("users", "1");
        GetResponse response = restClient.get(request, ElasticSearchConfig.COMMON_OPTIONS);
        if (response.isExists()) {
            String sourceAsString = response.getSourceAsString();
            User user = JSON.parseObject(sourceAsString, User.class);
            System.out.println(user);
        } else {
            System.out.println("没有搜索到数据");
        }
    }
}
```



## 删除数据

根据文档id删除数据

```java
@SpringBootTest
class DemoElasticsearchApplicationTests {

    @Autowired
    private RestHighLevelClient restClient;

    @Test
    void deleteRequest() throws IOException {
        DeleteRequest deleteRequest = new DeleteRequest("users", "1");
        DeleteResponse deleteResponse = restClient.delete(deleteRequest, ElasticSearchConfig.COMMON_OPTIONS);
        ReplicationResponse.ShardInfo shardInfo = deleteResponse.getShardInfo();
        if (shardInfo.getTotal() != shardInfo.getSuccessful()) {
            System.out.println("删除数据成功");

        }
    }
}
```



## 复杂检索

构建一个复杂的检索，并获取检索到的数据：文档元数据、文档数据、分析信息。如下

```json
GET /bank/_search
{
  "query": {
    "match": {
      "address": "mill"
    }
  },
  "aggs": {
    "ageAgg": {
      "terms": {
        "field": "age",
        "size": 10
      }
    },
    "balanceAvg": {
      "avg": {
        "field": "balance"
      }
    }
  }
}
```



```java
@SpringBootTest
class DemoElasticsearchApplicationTests {

    @Autowired
    private RestHighLevelClient restClient;

    @Test
    void searchRequest() throws IOException {
        //创建索引请求
        SearchRequest searchRequest = new SearchRequest();
        //指定DSL检索条件
        SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();
        //检索条件：address中包含mill的
        MatchQueryBuilder matchQuery = QueryBuilders.matchQuery("address", "mill");
        searchSourceBuilder.query(matchQuery);

        //聚合：根据年龄分布进行聚合
        TermsAggregationBuilder ageAgg = AggregationBuilders.terms("ageAgg").field("age").size(10);
        searchSourceBuilder.aggregation(ageAgg);
        //聚合：根据平均薪资进行聚合
        AvgAggregationBuilder balanceAvg = AggregationBuilders.avg("balanceAvg").field("balance");
        searchSourceBuilder.aggregation(balanceAvg);

        searchRequest.source(searchSourceBuilder);
        //执行检索
        SearchResponse searchResponse = restClient.search(searchRequest, ElasticSearchConfig.COMMON_OPTIONS);
        //获取检索结果
        SearchHits hits = searchResponse.getHits();
        //检索到的文档总数
        long value = hits.getTotalHits().value;
        System.out.println("检索到的文档总数" + value);
        //文档最大分数
        float maxScore = hits.getMaxScore();
        System.out.println("文档最大分数" + maxScore);

        SearchHit[] searchHits = hits.getHits();
        for (SearchHit hit : searchHits) {
            //文档所属索引
            String index = hit.getIndex();
            System.out.println("文档所属索引" + index);
            //文档id
            String id = hit.getId();
            System.out.println("文档id" + id);
            //文档得分
            float score = hit.getScore();
            System.out.println("文档得分" + score);
            //文档数据
            String sourceAsString = hit.getSourceAsString();
            AccountDTO accountDTO = JSON.parseObject(sourceAsString, AccountDTO.class);
            System.out.println("文档内容" + accountDTO);

            //获取检索到的分析信息
            Aggregations aggregations = searchResponse.getAggregations();

            //获取年龄分布聚合的分析信息
            Terms ageAggregation = aggregations.get("ageAgg");
            for (Terms.Bucket bucket : ageAggregation.getBuckets()) {
                Integer key = Integer.parseInt(bucket.getKey().toString());
                long docCount = bucket.getDocCount();
                System.out.println("key: " + key + ", docCount: " + docCount);
            }
            //获取平均薪资的聚合分析信息
            Avg balanceAggregation = aggregations.get("balanceAvg");
            double avgValue = balanceAggregation.getValue();
            System.out.println("平均薪资是：" + avgValue);
        }
    }
}
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15465935.html</id>
        <title type="text">Windows Terminal终端美化-青橙e</title>
        <summary type="html"></summary>
        <published>2021-10-26T07:14:00Z</published>
        <updated>2021-10-26T07:14:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15465935.html" />
        <content type="text">```json
{
    "$schema": "https://aka.ms/terminal-profiles-schema",
    "actions": [
        {
            "command": {
                "action": "copy",
                "singleLine": false
            },
            "keys": "ctrl+c"
        },
        {
            "command": "find",
            "keys": "ctrl+shift+f"
        },
        {
            "command": "paste",
            "keys": "ctrl+v"
        },
        {
            "command": {
                "action": "splitPane",
                "split": "auto",
                "splitMode": "duplicate"
            },
            "keys": "alt+shift+d"
        }
    ],
    "copyFormatting": "none",
    "copyOnSelect": false,
    "defaultProfile": "{61c54bbd-c2c6-5271-96e7-009a87ff44bf}",
    "profiles": {
        "defaults": {
            "colorScheme": "Vintage", // 主题
            //"useAcrylic": true, // 毛玻璃特效
            "acrylicOpacity": 1, // 不透明度
            "cursorColor": "#E6FF00", // 光标颜色
            "cursorShape": "bar", // 光标类型
            "fontFace": "Cascadia Code PL", // 字体名称
            "fontSize": 12, // 字体大小
            "foreground": "#3CB371", // #90EE90 #808080 #3CB371
            "icon": "ms-appx:///ProfileIcons/{61c54bbd-c2c6-5271-96e7-009a87ff44bf}.png", // 图标
            "backgroundImage": "C:/Users/xiejinchi/Pictures/Camera Roll/girl-cat.jpg", // 背景图片
            "backgroundImageOpacity": 0.2, // 背景图片的不透明度
            "closeOnExit": true, // 输入exit退出命令窗口
            "padding": "100, 30, 30, 30", // 内容距离界面的内部距离
            "snapOnInput": true, // 嗅探输入
            "historySize": 8001 // 历史大小
        },
        "list": [
            {
                "commandline": "powershell.exe",
                "guid": "{61c54bbd-c2c6-5271-96e7-009a87ff44bf}",
                "hidden": false,
                "name": "Windows PowerShell"
            },
            {
                "commandline": "cmd.exe",
                "guid": "{0caa0dad-35be-5f56-a8ff-afceeeaa6101}",
                "hidden": false,
                "name": "命令提示符"
            },
            {
                "guid": "{b453ae62-4e3d-5e58-b989-0a998ec441b8}",
                "hidden": false,
                "name": "Azure Cloud Shell",
                "source": "Windows.Terminal.Azure"
            },
            {
                "guid": "{574e775e-4f2a-5b96-ac1e-a2962a402336}",
                "name": "PowerShell",
                "source": "Windows.Terminal.PowershellCore"
            }
        ]
    },
    "schemes": [
        {
            "name": "Frost",
            "background": "#FFFFFF",
            "black": "#3C5712",
            "blue": "#17b2ff",
            "brightBlack": "#749B36",
            "brightBlue": "#27B2F6",
            "brightCyan": "#13A8C0",
            "brightGreen": "#89AF50",
            "brightPurple": "#F2A20A",
            "brightRed": "#F49B36",
            "brightWhite": "#741274",
            "brightYellow": "#991070",
            "cyan": "#3C96A6",
            "foreground": "#000000",
            "green": "#6AAE08",
            "purple": "#991070",
            "red": "#8D0C0C",
            "white": "#6E386E",
            "yellow": "#991070"
        },
        {
            "name": "Ubuntu",
            "black": "#2e3436",
            "red": "#cc0000",
            "green": "#4e9a06",
            "yellow": "#c4a000",
            "blue": "#3465a4",
            "purple": "#75507b",
            "cyan": "#06989a",
            "white": "#d3d7cf",
            "brightBlack": "#555753",
            "brightRed": "#ef2929",
            "brightGreen": "#8ae234",
            "brightYellow": "#fce94f",
            "brightBlue": "#729fcf",
            "brightPurple": "#ad7fa8",
            "brightCyan": "#34e2e2",
            "brightWhite": "#eeeeec",
            "background": "#300a24",
            "foreground": "#eeeeec"
        },
        {
            "background": "#0C0C0C",
            "black": "#0C0C0C",
            "blue": "#0037DA",
            "brightBlack": "#767676",
            "brightBlue": "#3B78FF",
            "brightCyan": "#61D6D6",
            "brightGreen": "#16C60C",
            "brightPurple": "#B4009E",
            "brightRed": "#E74856",
            "brightWhite": "#F2F2F2",
            "brightYellow": "#F9F1A5",
            "cursorColor": "#FFFFFF",
            "cyan": "#3A96DD",
            "foreground": "#CCCCCC",
            "green": "#13A10E",
            "name": "Campbell",
            "purple": "#881798",
            "red": "#C50F1F",
            "selectionBackground": "#FFFFFF",
            "white": "#CCCCCC",
            "yellow": "#C19C00"
        },
        {
            "background": "#012456",
            "black": "#0C0C0C",
            "blue": "#0037DA",
            "brightBlack": "#767676",
            "brightBlue": "#3B78FF",
            "brightCyan": "#61D6D6",
            "brightGreen": "#16C60C",
            "brightPurple": "#B4009E",
            "brightRed": "#E74856",
            "brightWhite": "#F2F2F2",
            "brightYellow": "#F9F1A5",
            "cursorColor": "#FFFFFF",
            "cyan": "#3A96DD",
            "foreground": "#CCCCCC",
            "green": "#13A10E",
            "name": "Campbell Powershell",
            "purple": "#881798",
            "red": "#C50F1F",
            "selectionBackground": "#FFFFFF",
            "white": "#CCCCCC",
            "yellow": "#C19C00"
        },
        {
            "background": "#282C34",
            "black": "#282C34",
            "blue": "#61AFEF",
            "brightBlack": "#5A6374",
            "brightBlue": "#61AFEF",
            "brightCyan": "#56B6C2",
            "brightGreen": "#98C379",
            "brightPurple": "#C678DD",
            "brightRed": "#E06C75",
            "brightWhite": "#DCDFE4",
            "brightYellow": "#E5C07B",
            "cursorColor": "#FFFFFF",
            "cyan": "#56B6C2",
            "foreground": "#DCDFE4",
            "green": "#98C379",
            "name": "One Half Dark",
            "purple": "#C678DD",
            "red": "#E06C75",
            "selectionBackground": "#FFFFFF",
            "white": "#DCDFE4",
            "yellow": "#E5C07B"
        },
        {
            "background": "#FAFAFA",
            "black": "#383A42",
            "blue": "#0184BC",
            "brightBlack": "#4F525D",
            "brightBlue": "#61AFEF",
            "brightCyan": "#56B5C1",
            "brightGreen": "#98C379",
            "brightPurple": "#C577DD",
            "brightRed": "#DF6C75",
            "brightWhite": "#FFFFFF",
            "brightYellow": "#E4C07A",
            "cursorColor": "#4F525D",
            "cyan": "#0997B3",
            "foreground": "#383A42",
            "green": "#50A14F",
            "name": "One Half Light",
            "purple": "#A626A4",
            "red": "#E45649",
            "selectionBackground": "#FFFFFF",
            "white": "#FAFAFA",
            "yellow": "#C18301"
        },
        {
            "background": "#002B36",
            "black": "#002B36",
            "blue": "#268BD2",
            "brightBlack": "#073642",
            "brightBlue": "#839496",
            "brightCyan": "#93A1A1",
            "brightGreen": "#586E75",
            "brightPurple": "#6C71C4",
            "brightRed": "#CB4B16",
            "brightWhite": "#FDF6E3",
            "brightYellow": "#657B83",
            "cursorColor": "#FFFFFF",
            "cyan": "#2AA198",
            "foreground": "#839496",
            "green": "#859900",
            "name": "Solarized Dark",
            "purple": "#D33682",
            "red": "#DC322F",
            "selectionBackground": "#FFFFFF",
            "white": "#EEE8D5",
            "yellow": "#B58900"
        },
        {
            "background": "#FDF6E3",
            "black": "#002B36",
            "blue": "#268BD2",
            "brightBlack": "#073642",
            "brightBlue": "#839496",
            "brightCyan": "#93A1A1",
            "brightGreen": "#586E75",
            "brightPurple": "#6C71C4",
            "brightRed": "#CB4B16",
            "brightWhite": "#FDF6E3",
            "brightYellow": "#657B83",
            "cursorColor": "#002B36",
            "cyan": "#2AA198",
            "foreground": "#657B83",
            "green": "#859900",
            "name": "Solarized Light",
            "purple": "#D33682",
            "red": "#DC322F",
            "selectionBackground": "#FFFFFF",
            "white": "#EEE8D5",
            "yellow": "#B58900"
        },
        {
            "background": "#000000",
            "black": "#000000",
            "blue": "#3465A4",
            "brightBlack": "#555753",
            "brightBlue": "#729FCF",
            "brightCyan": "#34E2E2",
            "brightGreen": "#8AE234",
            "brightPurple": "#AD7FA8",
            "brightRed": "#EF2929",
            "brightWhite": "#EEEEEC",
            "brightYellow": "#FCE94F",
            "cursorColor": "#FFFFFF",
            "cyan": "#06989A",
            "foreground": "#D3D7CF",
            "green": "#4E9A06",
            "name": "Tango Dark",
            "purple": "#75507B",
            "red": "#CC0000",
            "selectionBackground": "#FFFFFF",
            "white": "#D3D7CF",
            "yellow": "#C4A000"
        },
        {
            "background": "#FFFFFF",
            "black": "#000000",
            "blue": "#3465A4",
            "brightBlack": "#555753",
            "brightBlue": "#729FCF",
            "brightCyan": "#34E2E2",
            "brightGreen": "#8AE234",
            "brightPurple": "#AD7FA8",
            "brightRed": "#EF2929",
            "brightWhite": "#EEEEEC",
            "brightYellow": "#FCE94F",
            "cursorColor": "#000000",
            "cyan": "#06989A",
            "foreground": "#555753",
            "green": "#4E9A06",
            "name": "Tango Light",
            "purple": "#75507B",
            "red": "#CC0000",
            "selectionBackground": "#FFFFFF",
            "white": "#D3D7CF",
            "yellow": "#C4A000"
        },
        {
            "background": "#000000",
            "black": "#000000",
            "blue": "#000080",
            "brightBlack": "#808080",
            "brightBlue": "#0000FF",
            "brightCyan": "#00FFFF",
            "brightGreen": "#00FF00",
            "brightPurple": "#FF00FF",
            "brightRed": "#FF0000",
            "brightWhite": "#FFFFFF",
            "brightYellow": "#FFFF00",
            "cursorColor": "#FFFFFF",
            "cyan": "#008080",
            "foreground": "#C0C0C0",
            "green": "#008000",
            "name": "Vintage",
            "purple": "#800080",
            "red": "#800000",
            "selectionBackground": "#FFFFFF",
            "white": "#C0C0C0",
            "yellow": "#808000"
        }
    ]
}
```</content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15473518.html</id>
        <title type="text">Spring Cloud Gateway 自定义Filter-青橙e</title>
        <summary type="html"></summary>
        <published>2021-10-27T15:13:00Z</published>
        <updated>2021-10-27T15:13:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15473518.html" />
        <content type="text">Spring Cloud Gateway 的自定义Filter分为GatewayFilter局部过滤器和GlobalFilter全局过滤器

GatewayFilter : 需要通过spring.cloud.routes.filters 配置在具体路由下，只作用在当前路由上或通过spring.cloud.default-filters配置在全局，作用在所有路由上

GlobalFilter : 全局过滤器，不需要在配置文件中配置，作用在所有的路由上，最终通过GatewayFilterAdapter包装成GatewayFilterChain可识别的过滤器

# GatewayFilter局部过滤器

自定义局部过滤器需要实现`GatewayFilter` 和 `Ordered` 两个接口
```java
@Slf4j
public class CostomerGatewayFilter implements GatewayFilter, Ordered {
    @Override
    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        log.info("自定义局部过滤器：{}====================", "CustomerGatewayFilter");
        return chain.filter(exchange);
    }

    /**
     * 值越小，优先级越高
     *
     * @return
     */
    @Override
    public int getOrder() {
        return 0;
    }
}
```

在配置文件中使用自定义局部过滤器还需要使用自定义过滤器工厂来包装
这里的后缀`GatewayFilterFactory`不能写错，因为配置文件中配置的自定义过滤器名就是自定义过滤器工厂的类名去掉`GatewayFilterFactory`后缀的名字
把后缀写错了项目启动的时候就会报错说找不到这个自定义过滤器

```java
public class CustomerGatewayFilterFactory extends AbstractGatewayFilterFactory {
    @Override
    public GatewayFilter apply(Object config) {
        return new CostomerGatewayFilter();
    }
}
```

在配置类中将自定义过滤器工厂注册到容器中，当然也可以在自定义过滤器工厂类上加@Component注解
```java
@Configuration
public class GatewayConfig {

    @Bean
    public CustomerGatewayFilterFactory myGatewayFilterFactory() {
        return new CustomerGatewayFilterFactory();
    }

}
```

在配置文件中配置自定义过滤器，这里的`Customer`就是自定义过滤器工厂类名去掉`GatewayFilterFactory`后缀的名字
```java
spring:
  application:
    name: service-gateway
  cloud:
    nacos:
      discovery:
        server-addr: 127.0.0.1:8848
    gateway:
      routes:
        - id: service-provider
          uri: lb://service-provider
          predicates:
            - Path=/provider/**
          filters:
            - Customer
```


# GlobalFilter全局过滤器

自定义全局过滤器需要实现 `GlobalFilter` 和 `Ordered` 接口
```java
@Slf4j
public class LoginFilter implements GlobalFilter, Ordered {
    @Override
    public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) {
        ServerHttpRequest request = exchange.getRequest();
        String path = request.getURI().getPath();
        String token = request.getHeaders().getFirst("token");
        log.info("访问的路径：{}", path);
        log.info("token: {}==================", token);

        if (token == null) {
            ServerHttpResponse response = exchange.getResponse();
            response.getHeaders().add("Content-Type", "application/json;charset=UTF-8");
            ResponseData responseData = new ResponseData(401, "请登录");
            String res = null;
            try {
                res = new ObjectMapper().writeValueAsString(responseData);
            } catch (JsonProcessingException e) {
                e.printStackTrace();
            }
            DataBuffer wrap = response.bufferFactory().wrap(res.getBytes(StandardCharsets.UTF_8));
            return response.writeWith(Mono.just(wrap));
        }
        return chain.filter(exchange);
    }

    @Override
    public int getOrder() {
        return 0;
    }
}
```

在配置类中注册全局过滤器，这样这个全局过滤器就是全局过滤了
```java
@Configuration
public class GatewayConfig {

    @Bean
    public GlobalFilter loginFilter() {
        return new LoginFilter();
    }
}
```</content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15480859.html</id>
        <title type="text">Spring Cloud微服务之间用户信息的转递-青橙e</title>
        <summary type="html"></summary>
        <published>2021-10-29T07:51:00Z</published>
        <updated>2021-10-29T07:51:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15480859.html" />
        <content type="text">实现思路：
1. 准备一个ThreadLocal变量，供线程之间共享。
2. 每个微服对请求过滤，不管是经过网关的请求还是Feign的请求，如果是从网关过来的请求，从请求头中获取`token`并解析得到用户信息，然后存入`ThreadLocal`变量；如果是feign请求，直接获取请求头中的用户信息存入`ThreadLocal`中。
3. 每个微服务在使用Feign调用别的微服务时，先从ThreadLocal里面取出user信息，并放在request的请求头中。



ThreadLocal工具类：
```java
package com.orange.common.system;

import com.orange.common.entity.UserInfo;

public class UserInfoContext {
    private static ThreadLocal&lt;UserInfo&gt; userInfo = new ThreadLocal&lt;&gt;();
    public final static String FEIGN_HEADER_USERINFO = "X-FEIGN-HEADER-USERINFO";

    public static UserInfo getUser() {
        return (UserInfo) userInfo.get();
    }

    public static void setUser(UserInfo user) {
        userInfo.set(user);
    }
}

```

承载用户信息的实体类：
```java
package com.orange.common.entity;

import lombok.Data;

import java.io.Serializable;

@Data
public class UserInfo implements Serializable {
    private Long userId;
    private String username;
}
```

微服务的请求过滤器

```java
package com.orange.provider.component;


import com.alibaba.fastjson.JSON;
import com.orange.common.entity.UserInfo;
import com.orange.common.system.UserInfoContext;
import com.orange.common.util.JwtUtil;
import lombok.extern.slf4j.Slf4j;
import org.springframework.core.annotation.Order;
import org.springframework.stereotype.Component;
import org.springframework.util.StringUtils;

import javax.servlet.*;
import javax.servlet.http.HttpServletRequest;
import java.io.IOException;

@Slf4j
@Component
@Order(1)
public class UserInfoFilter implements Filter {

    @Override
    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {
        initUserInfo((HttpServletRequest) servletRequest);
        filterChain.doFilter(servletRequest, servletResponse);
    }

    private void initUserInfo(HttpServletRequest request) {
        log.info("执行过滤器{}===================", "UserInfoFilter");
        String token = request.getHeader(JwtUtil.HEADER_TOKEN);
        log.info("获取请求头中的token：{}=======", token);
        String username = JwtUtil.getUsername(token);
        if (username != null) {
            UserInfo userInfo = new UserInfo();
            userInfo.setUsername(username);
            userInfo.setUserId(JwtUtil.getUserId(token));
            UserInfoContext.setUser(userInfo);
        }

        String userJson = request.getHeader(UserInfoContext.FEIGN_HEADER_USERINFO);
        log.info("获取feign请求头中的userInfo: {}=========", userJson);
        if (!StringUtils.isEmpty(userJson)) {
            UserInfo userInfo = JSON.parseObject(userJson, UserInfo.class);
            UserInfoContext.setUser(userInfo);
        }
    }
}

```

Feign请求拦截器
```java
package com.orange.consumer.config;

import com.alibaba.fastjson.JSON;
import com.orange.common.entity.UserInfo;
import com.orange.common.system.UserInfoContext;
import feign.RequestInterceptor;
import feign.RequestTemplate;
import lombok.extern.slf4j.Slf4j;
import org.springframework.context.annotation.Configuration;

@Slf4j
@Configuration
public class FeignConfig implements RequestInterceptor {

    @Override
    public void apply(RequestTemplate requestTemplate) {
        log.info("feign请求拦截器============");
        //从应用上下文中取出user信息，放入Feign的请求头中
        UserInfo user = UserInfoContext.getUser();
        log.info("应用上下文中的UserInfo：{}",user);
        if (user != null) {
            String userJson = JSON.toJSONString(user);
            try {
                requestTemplate.header(UserInfoContext.FEIGN_HEADER_USERINFO, userJson);
            } catch (Exception e) {
                log.info("用户信息设置失败=========");
            }
        }
    }

}

```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15757644.html</id>
        <title type="text">CentOS-7配置yum镜像源-青橙e</title>
        <summary type="html"></summary>
        <published>2022-01-02T08:08:00Z</published>
        <updated>2022-01-02T08:08:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15757644.html" />
        <content type="text">1. 备份原本的yum镜像源
```bash
mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup
```

2. 下载阿里云yum镜像源
```bash
wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo
```

3. 清除系统所有的yum缓存
```bash
yum clean all
```

4. 生成yum缓存
```bash
yum makecache
```</content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15807886.html</id>
        <title type="text">制作Windows10启动盘-纯净安装-青橙e</title>
        <summary type="html"></summary>
        <published>2022-01-15T11:49:00Z</published>
        <updated>2022-01-15T11:49:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15807886.html" />
        <content type="text">制作 Windows 10 U盘启动盘，不会捆绑第三方软件，从U盘启动就能看见Windows的安装界面。

1. 点击以下连接进入windows官方
[https://www.microsoft.com/zh-cn/software-download/windows10%20]()

2. 下载工具
![](https://img2020.cnblogs.com/blog/1801000/202201/1801000-20220115191626250-936786331.png)

3. 安装下载的工具
![](https://img2020.cnblogs.com/blog/1801000/202201/1801000-20220115192301163-1246153397.png)

4. 插入U盘，选择 为另一台电脑创建安装介质(U盘、DVD或ISO文件)，下一步
![](https://img2020.cnblogs.com/blog/1801000/202201/1801000-20220115192757040-226979710.png)

5. 选择语言、版本，一般默认就可以，下一步
![](https://img2020.cnblogs.com/blog/1801000/202201/1801000-20220115193027064-1840679313.png)

6. 选择 U盘，点击下一步
![](https://img2020.cnblogs.com/blog/1801000/202201/1801000-20220115193323124-1743101159.png)

7. 选择刚才插入的U盘，点击下一步
![](https://img2020.cnblogs.com/blog/1801000/202201/1801000-20220115193449366-1877661866.png)

8. 等待下载 Windows 10，网速慢的话可以泡杯茶慢慢等
![](https://img2020.cnblogs.com/blog/1801000/202201/1801000-20220115193806434-1319219726.png)

接下来从U盘启动就可以重装系统了
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15810069.html</id>
        <title type="text">Ubuntu安装.deb软件包-青橙e</title>
        <summary type="html"></summary>
        <published>2022-01-16T06:32:00Z</published>
        <updated>2022-01-16T06:32:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15810069.html" />
        <content type="text">直接双击安装deb文件包，可能会出现安装不上的问题，这时候我们建议使用dpkg命令安装。

## 安装

```
sudo dpkg -i package_name.deb
```

通常情况下会报依赖关系的错误，我们可以使用以下的命令修复安装
```
sudo apt install -f
```

## 查找

查找安装的软件
```
dpkg -l |grep -i 软件名
```

## 卸载
```
sudo dpkg -r 软件名
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15860857.html</id>
        <title type="text">CentOS 7安装GitLab14.7-青橙e</title>
        <summary type="html"></summary>
        <published>2022-02-02T13:57:00Z</published>
        <updated>2022-02-02T13:57:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15860857.html" />
        <content type="text">在CentOS 7上安装GitLab 14.7

在 CentOS 7（以及 RedHat/Oracle/Scientific Linux 7）上，下面的命令还将在系统防火墙中打开 HTTP、HTTPS 和 SSH 访问

```bash
sudo yum install -y curl policycoreutils-python openssh-server perl

#查看openssh服务状态
sudo systemctl status sshd

#设置openssh服务开机启动
sudo systemctl enable sshd

#启动openssh
sudo systemctl start sshd

#查看防火墙是否打开
sudo systemctl status firewalld

#防火墙添加http和https
sudo firewall-cmd --permanent --add-service=http
sudo firewall-cmd --permanent --add-service=https

#重新加载防火墙
sudo systemctl reload firewalld
```

在线安装：

1. 添加 GitLab 包存储库

```bash
curl -s https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash
```

2. 安装

```bash
yum install -y gitlab-ce
```

离线安装

1. 下载Gitlab软件包上传到CentOS

访问 https://packages.gitlab.com/gitlab/gitlab-ce/ 获取对应的软件包

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220202215201880-745347934.png)


2. 安装GitLab

```bash
yum -y install gitlab-ce-14.7.0-ce.0.el7.x86_64.rpm
```

配置访问地址和端口

vim /etc/gitlab/gitlab.rb

```bash
external_url 'http://192.168.1.22:8000'

nginx['listen_port'] = 8000
```

重载配置、重启服务

```bash
gitlab-ctl reconfigure

gitlab-ctl restart
```

把端口添加到防火墙

```bash
firewall-cmd --zone=public --add-port=8000/tcp --permanent

#重新加载防火墙
firewall-cmd --reload
```

默认有一个用户root，安装时没有设置密码，密码随机生成，在目录 `/etc/gitlab/initial_root_password`</content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15861123.html</id>
        <title type="text">VMware虚拟机网络桥接模式配置静态IP地址-青橙e</title>
        <summary type="html"></summary>
        <published>2022-02-02T18:28:00Z</published>
        <updated>2022-02-02T18:28:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15861123.html" />
        <content type="text">修改VMware网络配置
编辑 &gt;虚拟网络编辑器
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220202235951842-508123848.png)

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203020418992-1427225864.png)

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203020659648-388347785.png)

编辑虚拟机设置
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203022209981-1597642639.png)

网络适配器选择桥接模式
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203022355838-842817144.png)


查看主机网关 `ipconfig`
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203021503176-218901768.png)

修改CentOS网络配置，网关和主机网关一致，IP地址和主机在同一个网段 `vim /etc/sysconfig/network-scripts/ifcfg-ens33` ![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203021057123-2092691768.png) ``` TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=static DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no NAME=enp0s3 UUID=eae5023a-eec6-47ef-8213-8ecba2b2ba99 DEVICE=enp0s3 ONBOOT=yes IPADDR=192.168.1.119 GATEWAY=192.168.1.1 NETMASK=255.255.255.0 DNS1=8.8.8.8

```

重启网络：`systemctl restart network.service`
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15861764.html</id>
        <title type="text">CentOS 7安装openjdk-青橙e</title>
        <summary type="html"></summary>
        <published>2022-02-03T09:49:00Z</published>
        <updated>2022-02-03T09:49:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15861764.html" />
        <content type="text">下载 jdk，下载速度很慢，可以使用迅雷下载之后上传到CentOS

```bash
wget https://download.java.net/openjdk/jdk11/ri/openjdk-11+28_linux-x64_bin.tar.gz
```

解压到`/opt/`目录下

```bash
tar xvf openjdk-11+28_linux-x64_bin.tar.gz -C /opt/
```

配置jdk环境变量，`vim /etc/profile`添加如下配置

```bash
export JAVA_HOME=/opt/jdk-11
export PATH=$PATH:$JAVA_HOME/bin
```

使配置生效

```bash
source /etc/profile
```

验证配置是否正确 `java --version`，输出一下内容证明配置正确

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203174831068-1183815140.png)
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/15861842.html</id>
        <title type="text">CentOS7安装Jenkinsj及相关配置-青橙e</title>
        <summary type="html"></summary>
        <published>2022-02-03T10:58:00Z</published>
        <updated>2022-02-03T10:58:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/15861842.html" />
        <content type="text">## 安装Jenkins

```bash
sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.repo

sudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.keyreload

yum install epel-release

yum install java-11-openjdk-devel

yum install jenkins

```

修改Jenkins配置，使用本机root用户登录Jenkins，`vim /etc/sysconfig/jenkins` ```bash JENKINS_USER="root"
```

启动Jenkins

```bash
sudo systemctl start jenkins
```

检查 Jenkins 服务的状态：

```bash
sudo systemctl status jenkins
```

防火墙添加端口，jenkins默认的端口为8080

```bash
firewall-cmd --zone=public --add-port=8080/tcp --permanent

#重新加载防火墙
firewall-cmd --reload
```

浏览器访问ip地址:端口，如下所示表示安装成功

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203184942855-2013512330.png)


获取密码

```bash
cat /var/lib/jenkins/secrets/initialAdminPassword
```

输入密码之后进入下页面：Jenkins安装插件默认从官网下载，速度很慢，暂时不安装插件，点击选择插件来安装

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203185045743-918759160.png)


点击 无，点击 安装

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203185104022-1169562758.png)


创建第一个管理员用户

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203185136476-1075584306.png)


![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203185151864-928137299.png)


![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203185205031-1492788394.png)


## 修改插件下载地址

浏览器访问： https://mirrors.aliyun.com/jenkins/updates/

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203185424838-1936593470.png)


访问jenkins：Manage Jenkins–&gt;Manage Plugins

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203185304882-1678778582.png)


选择Advanced

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203185500057-1104184367.png)


滑到最下面，将Update Site的url改为刚才复制的地址，点击submit

https://mirrors.aliyun.com/jenkins/updates/update-center.json

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203185626890-713408629.png)


重启Jenkins，在端口号后加`/restart`可以重启Jenkins，例如 http://192.168.1.102:8080/restart ，点击yes

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203185639223-2032444183.png)


## 安装Jenkins中文插件

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203185709409-1525975753.png)


安装后重启，可以看到Jenkins界面变成了中文

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203185722315-1353742198.png)


## 安装权限管理插件

在可选插件中输入 role-based 查找插件并安装
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203190421847-1748333518.png)


配置权限
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203190815601-456188515.png)

授权策略选择 Role-Based Strategy
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203190952505-178049125.png)

## Jenkins使用凭证管理


在可选插件中输入 Credentials Binding 安装插件
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203192400318-1535098718.png)


安装完成之后在Manage jenkins中可以看见凭证配置
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203193031892-714917038.png)

## Jenkins安装Git插件
Jenkins要去GitLab拉取代码，需要Jenkins安装git插件，部署Jenkins的的机器安装Git

Jenkins安装git插件在可选插件中搜索git安装即可

安装git
```bash
yum install -y git
```

查看git是否安装成功
```bash
git --version
```

## jenkins使用ssh私钥凭证拉取GitLab代码

在CentOS中输入 `ssh-keygen -t rsa`，一路按回车，会在`~/.ssh/`目录下生成公钥和私钥

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203231854047-1219508888.png)

私钥
```bash
[root@strawberry ~]# cat .ssh/id_rsa
-----BEGIN RSA PRIVATE KEY----- MIIEpAIBAAKCAQEA1fM+hbjmx4J4zCMSF79sPiKQP65Wa2YXF5Q39j3LFN0ssyyj TjO8mSi1xaDCz0s2cqoi6+sa/OotfbcWS/dpzYV+ZdAcP3DF3YWj/tDY8V27hr8K qRdXHRvvkqnur1Tz0EYkOPHAm9uovs9zunc00BUERCb73m4IKEWxdR+E0HdTp3ht VnB9qfsed1dAm2xqRDbHK6cJABhvQgB/T54Mq/+u3UdRzPyBrxml6tAVIEn5bzTK 01hy2eUfReaAcSltcLqcgFXUMIFML9J4XUQaR0etHLFhRecMgzQd5qr3xIuWD+S1 2U/McveNUioQtHrj/3CizKqVtHhOfxvDVLUQBwIDAQABAoIBAQCgHg4Bl9KnJ17u L6T/vtPsYIOiFQA6GkpX7CZBlBdjQu+MHHEPOqr/2LbI87o31yslf2zpMKee9kcb WaVHLx+wnyJsYeZyGB0M31JPhs+FO8f3XQxGZeBdOaX/Fkw6TZK2oXfEYjDqs+bC /pC20TXmMIRj2OUQnzpdoWLgq7kDJZuAEs9lvqpNFBXnX9j3hu8QOwfbLTQo6Hu/ ferWx+6km9WcW8qE/Xb13HHOckSoTCg2WLPTbj2KADgn4Hr83ofyyzyrHNgJRSl2 TuhvvHVXLih7PW20HQ6TPcR5CeBdyjhoaXYKRZqux4IdqDeGh+d6VBPUSqqogPxT XKFhmsJxAoGBAPru6SFcL7qFp5PFRrFeJCAs0aBChmj99FExGQCEv4byP3c2cNMf j0+LVuYNNUnGi3XUesXJ6oN6gAqI6SnMhz8nMS2JEt94s70YkcdY763hSdw95Tb2 8F7wVi7fzXsjfBiisAWaq+5msptv7MZfTF0NcmoFdvmpR6lKYKo46Ep/AoGBANpF KnGHYdvY2GoM7pWJj3g7EzSlslXpeG9NXQFH9z1YHNoEtUtZphFOtFxwtc9R08Ph NK035Jb4D48XxiNNbHZ8lnAgw6LkPEKnfb6++qMxxe1sjHjii7TSbugF9dwVtSpu +dTJpbHGNmC5TSAVFDs4RT9pAMROUH7Z9YQQpSZ5AoGBAI//GXkzVZBLsmZyBqcx xrlP/ttgUZFeah1Nd3N8ugvOZ+0ZKJV+vtZ+t1c8rR+w98aeL/XgcNsSKPfiqSp7 XAE5lFb1GgdzVHFm8ADdYGz/o0rnmel4u2c/s7UiaOAI9OWONkSBBbjA5i2chNsx RLkBRm7gw+1w3tae/+muzl4xAoGAV2ssPJwETZDj3FWhmLKni3fdkVBrxIzld258 uW6hTyhjJc6M7cjSAkyLYBqkNoyHTAR+nIGuQ+jGEoFrEeiIcEwl1HLK6AqROADt E+BZcdMVeqnm+OODIMDHOpZoieUH0h7wYJECk9jXHpYYlajbmXxH/8WGURkslCGn e2VPP8ECgYACCBXQa70SIVqkTBD7fdc0T01zqyejjtNdk1a4kpGDECkPJryMye6E lgH+Bcnp2elgMmZd/MQYUNAz3ZBra6ahg+6TT2FXstHrFs6S0sPWmlSIZYeVl8jJ iRrKTlzXKv51GOQQeajT0bf0Rdcpvx5yGh1mawIDuEEWhKBU5TnzdQ==
-----END RSA PRIVATE KEY-----
```

公钥
```bash
[root@strawberry ~]# cat .ssh/id_rsa.pub
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDV8z6FuObHgnjMIxIXv2w+IpA/rlZrZhcXlDf2PcsU3SyzLKNOM7yZKLXFoMLPSzZyqiLr6xr86i19txZL92nNhX5l0Bw/cMXdhaP+0NjxXbuGvwqpF1cdG++Sqe6vVPPQRiQ48cCb26i+z3O6dzTQFQREJvvebggoRbF1H4TQd1OneG1WcH2p+x53V0CbbGpENscrpwkAGG9CAH9Pngyr/67dR1HM/IGvGaXq0BUgSflvNMrTWHLZ5R9F5oBxKW1wupyAVdQwgUwv0nhdRBpHR60csWFF5wyDNB3mqvfEi5YP5LXZT8xy941SKhC0euP/cKLMqpW0eE5/G8NUtRAH root@strawberry
```

在GitLab中添加`ssh key`，使用root账户登录GitLab

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203234448505-245650571.png)

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203234622768-1090415133.png)

将刚才生成的公钥复制进去

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203235133484-1284782403.png)



在Jenkins的项目配置中，源码管理 Repository URL要填GitLab项目中ssh链接地址

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220204000639994-1604129161.png)

将刚才生成的私钥复进去
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220203233450482-1661938752.png)


## jenkins配置maven和jdk
jdk在安装Jenkins的时候已经安装了，现在还需要安装maven
浏览器访问maven官网，下载maven压缩包 https://maven.apache.org/download.cgi
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220204002359891-507741848.png)

上传maven压缩包到CentOS，解压到`/opt/`目录下
```bash
tar xvf apache-maven-3.8.4-bin.tar.gz -C /opt/
```

```bash
[root@strawberry ~]# ll /opt/
总用量 0
drwxr-xr-x. 6 root root 99 2月   4 00:26 apache-maven-3.8.4
drwxr-xr-x. 8 root root 96 2月   3 16:36 jdk-11
```

配置maven环境变量：`vim /etc/profile`，添加如下内容
```bash
export MAVEN_HOME=/opt/apache-maven-3.8.4
export PATH=$PATH:$MAVEN_HOME/bin
```

使配置生效
```bash
source /etc/profile
```

验证配置是否成功：`mvn --version`
```bash
[root@strawberry ~]# mvn --version
Apache Maven 3.8.4 (9b656c72d54e5bacbed989b64718c159fe39b537)
Maven home: /opt/apache-maven-3.8.4
Java version: 11.0.14, vendor: Red Hat, Inc., runtime: /usr/lib/jvm/java-11-openjdk-11.0.14.0.9-1.el7_9.x86_64
Default locale: zh_CN, platform encoding: UTF-8
OS name: "linux", version: "3.10.0-1160.53.1.el7.x86_64", arch: "amd64", family: "unix"
```

maven配置阿里云镜像仓库地址、本地仓库地址，修改maven配置文件：`vim /opt/apache-maven-3.8.4/conf/settings.xml`
本地仓库位置
```xml
&lt;localRepository&gt;/root/maven_repo&lt;/localRepository&gt;
```

阿里云仓库地址
```xml
&lt;mirror&gt;
    &lt;id&gt;nexus-aliyun&lt;/id&gt;
    &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;
    &lt;name&gt;Nexus aliyun&lt;/name&gt;
    &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt;
&lt;/mirror&gt;
```

在Jenkins中配置jdk和maven，首先在 Global Tool configruation中配置，然后在 Configure System中配置

点击 Manage Jenkins &gt; Global Tool configruation

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220204024339782-279780159.png)

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220204024500921-1462400102.png)

新增JDK
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220204024727216-1372063615.png)

填写jdk别名、jkd的安装目录，去掉 Install automatically选项
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220204025023040-1081008629.png)

新增maven
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220204025442965-740181160.png)

点击应用，点击保存

点击 Manage Jenkins &gt; Configure System

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220204030027866-1756580189.png)

在全局属性中新增环境变量
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220204030237544-1522376913.png)

添加三个环境变量：JAVA_HOME、M2_HOME、PATH+EXTRE
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220204031058661-1219834896.png)

点击应用，点击保存

验证配置是否成功，项目配置 &gt; 构建触发器 &gt; 增加构建步骤 &gt; Excute shell
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220204031712366-1497177054.png)

输入命令：mvn package
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220204031848416-1692998168.png)

点击应用，点击保存


验证Jenkins配置jdk和maven是否成功，点击这个项目
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220204033204710-1347344080.png)

点击 Build Now
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220204033311515-1311835442.png)

![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220204033423169-210501595.png)

点击控制台输出
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220204033450802-2082491969.png)

滑到最下面看是否构建成功
![](https://img2022.cnblogs.com/blog/1801000/202202/1801000-20220204033622989-1325783060.png)
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/16097228.html</id>
        <title type="text">CentOS7安装Nginx-青橙e</title>
        <summary type="html"></summary>
        <published>2022-04-03T12:32:00Z</published>
        <updated>2022-04-03T12:32:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/16097228.html" />
        <content type="text">下载Nginx源码包上传到CentOS服务器
安装gcc，Nginx编译源码时所需要的编译器

```
yum install -y gcc
```

安装pcre，让 nginx 支持重写功能

```
yum -y install pcre pcre-devel
```

安装zlib，zlib 库提供了很多压缩和解压缩的方式，nginx 使用 zlib 对 http 包内容进行 gzip 压缩

```
yum -y install zlib zlib-devel
```

安装openssl，安全套接字层密码库，用于通信加密

```
yum -y install openssl openssl-devel
```

解压Nginx源码包

```
tar zxvf nginx-1.20.2.tar.gz
```



进入Nginx源码目录

```
cd nginx-1.20.2
```



为编译安装做准备

```
./configure --prefix=/usr/local/nginx
```



编译安装

```
make &amp;&amp; make install
```



启动Nginx

```
cd /usr/local/nginx/sbin
./nginx
```

nginx常用命令

```
./nginx    #启动
./nginx    #停止
./nginx -s quit    #优雅关闭，在推出前完成已接受的连接请求
./nginx -s reload    #重新加载配置
```



将nginx设置为系统服务，创建服务脚本：`vim /usr/lib/systemd/system/nginx.service` ``` [Unit] Description=nginx - web server After=network.target remote-fs.target nss-lookup.target [Service] Type=forking PIDFile=/usr/local/nginx/logs/nginx.pid ExecStartPre=/usr/local/nginx/sbin/nginx -t -c /usr/local/nginx/conf/nginx.conf ExecStart=/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf ExecReload=/usr/local/nginx/sbin/nginx -s reload ExecStop=/usr/local/nginx/sbin/nginx -s stop ExecQuit=/usr/local/nginx/sbin/nginx -s quit PrivateTmp=true [Install] WantedBy=multi-user.target
```



创建服务脚本之后需要重新加载系统服务

```
systemctl daemon-reload
```

设置开机启动
```
systemctl enable nginx.service
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/16166232.html</id>
        <title type="text">Linux-CentOS 常用操作-青橙e</title>
        <summary type="html"></summary>
        <published>2022-04-19T12:22:00Z</published>
        <updated>2022-04-19T12:22:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/16166232.html" />
        <content type="text">Linux系统中一切皆文件

# 关于系统信息
在Linux系统中，提供了proc文件系统显示系统的软硬件信息。如果想了解系统中CPU的提供商和相关配置信息，则可以通过`/proc/cpuinfo`文件得到。

使用以下命令来读取`/proc/cpuinfo`文件，查看cpu的信息
```
cat  /proc/cpuinfo
```

输出：
```
processor       : 0
vendor_id       : GenuineIntel
cpu family      : 6
model           : 142
model name      : Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz
stepping        : 9
microcode       : 0xd6
cpu MHz         : 2904.000
cache size      : 4096 KB
physical id     : 0
siblings        : 1
core id         : 0
cpu cores       : 1
apicid          : 0
initial apicid  : 0
fpu             : yes
fpu_exception   : yes
cpuid level     : 22
wp              : yes
flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon nopl xtopology tsc_reliable nonstop_tsc eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 invpcid rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 arat md_clear spec_ctrl intel_stibp flush_l1d arch_capabilities
bogomips        : 5808.00
clflush size    : 64
cache_alignment : 64
address sizes   : 45 bits physical, 48 bits virtual
power management:
```
相关说明：
- processor：系统中逻辑处理核的编号。对于单核处理器，则可认为是其CPU编号，对于多核处理器则可以是物理核、或者使用超线程技术虚拟的逻辑核；它的计数是从0开始的。
- vendor_id：CPU制造商
- cpu family：CPU产品系列代号
- model：CPU属于其系列中的哪一代的代号
- model name：CPU属于的名字及其编号、标称主频
- stepping：CPU属于制作更新版本
- cpu MHz：CPU的实际使用主频
- cache size：CPU二级缓存大小
- physical id：单个CPU的标号
- siblings：单个CPU逻辑物理核数
- core id：当前物理核在其所处CPU中的编号，这个编号不一定连续
- cpu cores：该逻辑核所处CPU的物理核数
- apicid：用来区分不同逻辑核的编号，系统中每个逻辑核的此编号必然不同，此编号不一定连续
- fpu：是否具有浮点运算单元（Floating Point Unit）
- fpu_exception：是否支持浮点计算异常
- vcpuid level：执行cpuid指令前，eax寄存器中的值，根据不同的值cpuid指令会返回不同的内容
- wp ：表明当前CPU是否在内核态支持对用户空间的写保护（Write Protection）
- flags：当前CPU支持的功能
- vbogomips   ：在系统内核启动时粗略测算的CPU速度（Million Instructions Per Second）
- clflush size  ：每次刷新缓存的大小单位
- cache_alignment ：缓存地址对齐单位
- address sizes：可访问地址空间位数

如何不想获取cpu的全部信息，只是想要查看cpu型号，可以使用以下命令：
```
cat /proc/cpuinfo | grep 'model name' |uniq
```

查看物理CPU个数
```
cat /proc/cpuinfo | grep 'cpu cores' |uniq
```

查看系统内核版本
```
uname -r
```

查看系统的发行版本
```
cat /etc/redhat-release
```

# 查看文件内容

## more
`more info.log`分页查看文件内容
- 回车：下一行
- 空格：下一页
- Ctrl+ B：上一页
- B：回到文档第一页
- h：帮助
- q：退出

## less
`less -N info.log` 带行号查看文件内容
- k： 上一行
- f： 向下滚动一屏幕
- b： 向上滚动一屏幕
- g： 定位到文档头部
- G： 定位到文档最尾部
- 空格键：滚动一页(同f)
- 回车键：滚动一行(同j)

实时查看文档变动：
- F：实时滚动文档
- Ctrl + c：退出实时滚动模式

查找内容：
/keyword 向下查找
- n：向下匹配下一处匹配文本
- N：向上匹配下一处匹配文本


?keyword 向上查找
- n：向上匹配下一处匹配文本
- N：向下匹配下一处匹配文本

# 文件查找

## find
find命令是从指定目录递归遍历其子目录，将满足条件的文件或目录显示在终端
语法：find [搜索范围] [选项]
选项：
- `-name`：指定文件名查找
- `-user`：查找指定用户的所有文件
- `-size`：指定文件的大小查找（+n大于，-n小于，n等于，单位：k，M，G）

## locate

locate指令可以快速定位文件路径。locate指令利用事先建立的文件系统中所有文件名及其路径的locate数据库实现快速定位指定的文件。locate无需便遍历整个文件系统，查询速度较快。为了查询的准确度，管理员必须定期更新locate。

由于locate是基于数据库查询，所以第一次运行前，必须 使用updatedb指令创建locate数据库。

语法：locate 文件名


## 管道符`|` 和grep
管道符`|`：表示将前一个命令的处理结果传递给后面的命令
`grep`：过滤查找

`grep`基本语法：grep [选项] 查找内容 源文件
选项：
- -n：显示匹配及行号
- -i：忽略字母大小写

例如：查询nginx.conf文件中包含location字符所在的行
```
cat /usr/local/nginx/conf/nginx.conf | grep -n 'location'
```

# 压缩和解压缩

## gzip/gunzip

`gzip`用于将文件压缩为`.gz`文件
`gunzip`用于解压`.gz`文件

## zip/unzip

zip用于将文件压缩为`.zip`文件，unzip用于解压缩`.zip`文件

zip语法：zip [选项] xxx.zip 文件或目录
选项：
- -r：递归压缩，压缩目录

unzip语法：unzip [选项] xxx.zip
选项：
- -d：指定解压文件目录

## tar

tar用于将文件打包，打包后的格式为`.tar.gz`

打包：tar [选项] xxx.tar.gz ...文件或目录
解包：tar [选项] xxx.tar.gz

选项：
- -c：产生`.tar`打包文件
- -v：显示详细信息
- -f：指定压缩后的文件名
- -z：打包同时压缩
- -x：解包tar文件
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/16218659.html</id>
        <title type="text">Java-Files和Paths类的使用-青橙e</title>
        <summary type="html"></summary>
        <published>2022-05-03T08:29:00Z</published>
        <updated>2022-05-03T08:29:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/16218659.html" />
        <content type="text"># 遍历目录
```java
@Test
void pathTest() throws IOException {
    AtomicInteger directoryCount = new AtomicInteger();
    AtomicInteger fileCount = new AtomicInteger();
    Files.walkFileTree(Paths.get("D:/software_work/jdk-17.0.2"), new SimpleFileVisitor&lt;Path&gt;() {
        @Override
        public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException {
            directoryCount.incrementAndGet();
            System.out.println("目录：" + dir);
            return super.preVisitDirectory(dir, attrs);
        }

        @Override
        public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException {
            fileCount.incrementAndGet();
            System.out.println("文件：" + file);
            return super.visitFile(file, attrs);
        }
    });
    System.out.println("目录数量：" + directoryCount.get());
    System.out.println("文件数量：" + fileCount.get());
}
```

# 拷贝目录
```java
@Test
void copyDirectory() {
    String source = "D:\\software_work\\apache-maven-3.8.4";
    String target = "D:\\software_work\\apache-maven";
    try {
        Files.walk(Paths.get(source)).forEach(path -&gt; {
            String targetDirectory = path.toString().replace(source, target);
            // 目录
            if (Files.isDirectory(path)) {
                try {
                    Files.createDirectory(Paths.get(targetDirectory));
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
            // 文件
            else if (Files.isRegularFile(path)) {
                try {
                    Files.copy(path, Paths.get(targetDirectory));
                } catch (IOException e) {
                    e.printStackTrace();
                }
            }
        });
    } catch (Exception e) {
        e.printStackTrace();
    }
}
```

# 复制文件
```
@Test
void copyFileTest() {
    Path path = Paths.get("./头像.jpg");
    if (!Files.exists(path)) {
        return;
    }
    Path pathNew = Paths.get("./头像2.jpg");
    try {
        //StandardCopyOption.REPLACE_EXISTING 如果文件存在就覆盖
        Files.copy(path, pathNew, StandardCopyOption.REPLACE_EXISTING);
    } catch (IOException e) {
        e.printStackTrace();
    }
}
```

# 移动文件
```java
@Test
void moveFileTest() {
    Path path = Paths.get("./头像2.jpg");
    if (!Files.exists(path)) {
        return;
    }
    Path pathNew = Paths.get("D:/头像2.jpg");
    try {
        //StandardCopyOption.REPLACE_EXISTING 如果文件存在就覆盖
        Files.move(path, pathNew, StandardCopyOption.REPLACE_EXISTING);
    } catch (IOException e) {
        e.printStackTrace();
    }
}
```</content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/16219416.html</id>
        <title type="text">Java-NIO学习-青橙e</title>
        <summary type="html"></summary>
        <published>2022-05-03T12:54:00Z</published>
        <updated>2022-05-03T12:54:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/16219416.html" />
        <content type="text">
# I/O 模型基本说明

I/O 模型：就是用什么样的通道或者说是通信模式和架构进行数据的传输和接收，很大程度上决定了程序通信的性能，Java 共支持 3 种网络编程的/IO 模型：**BIO、NIO、AIO**
实际通信需求下，要根据不同的业务场景和性能需求决定选择不同的I/O模型


##  Java BIO

同步并阻塞(传统阻塞型)，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器
端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销


## Java NIO

Java NIO ： 同步非阻塞，服务器实现模式为一个线程处理多个请求(连接)，即客户端发送的连接请求都会注
册到多路复用器上，多路复用器轮询到连接有 I/O 请求就进行处理

##  Java AIO

Java AIO(NIO.2) ： 异步 异步非阻塞，服务器实现模式为一个有效请求一个线程，客户端的I/O请求都是由OS先完成了再通知服务器应用去启动线程进行处理，一般适用于连接数较多且连接时间较长的应用

## BIO、NIO、AIO 适用场景分析

1. **BIO** 方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择，但程序简单易理解。
2. **NIO** 方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，弹幕系统，服务器间通讯等。编程比较复杂，JDK1.4 开始支持。
3. AIO 方式使用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用 OS 参与并发操作，编程比较复杂，JDK7 开始支持。

# Java BIO深入剖析


* Java BIO 就是传统的 java io  编程，其相关的类和接口在 java.io
* BIO(blocking I/O) ： 同步阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，可以通过线程池机制改善(实现多个客户连接服务器).

##  BIO 工作机制

1) 服务器端启动一个 **ServerSocket**，注册端口，调用accpet方法监听客户端的Socket连接。
2) 客户端启动 **Socket** 对服务器进行通信，默认情况下服务器端需要对每个客户 建立一个线程与之通讯

## 传统的BIO编程实例

网络编程的基本模型是Client/Server模型，也就是两个进程之间进行相互通信，其中服务端提供位置信（绑定IP地址和端口），客户端通过连接操作向服务端监听的端口地址发起连接请求，基于TCP协议下进行三次握手连接，连接成功后，双方通过网络套接字（Socket）进行通信。
传统的同步阻塞模型开发中，服务端ServerSocket负责绑定IP地址，启动监听端口；客户端Socket负责发起连接操作。连接成功后，双方通过输入和输出流进行同步阻塞式通信。
基于BIO模式下的通信，客户端 - 服务端是完全同步，完全耦合的。

客户端案例如下

```java
public static void main(String[] args) throws Exception {
    System.out.println("==客户端的启动==");
    // （1）创建一个Socket的通信管道，请求与服务端的端口连接。
    Socket socket = new Socket("127.0.0.1", 8888);
    // （2）从Socket通信管道中得到一个字节输出流。
    OutputStream os = socket.getOutputStream();
    // （3）把字节流改装成自己需要的流进行数据的发送
    PrintStream ps = new PrintStream(os);
    // （4）开始发送消息
    ps.println("我是客户端，我想约你吃小龙虾！！！");
    ps.flush();
}
```

服务端案例如下

```java
public static void main(String[] args) throws Exception {
    // （1）注册端口
    ServerSocket serverSocket = new ServerSocket(8888);
    //（2）开始在这里暂停等待接收客户端的连接,得到一个端到端的Socket管道
    Socket socket = serverSocket.accept();
    //（3）从Socket管道中得到一个字节输入流。
    InputStream is = socket.getInputStream();
    //（4）把字节输入流包装成自己需要的流进行数据的读取。
    BufferedReader br = new BufferedReader(new InputStreamReader(is));
    //（5）读取数据
    String line ;
    while((line = br.readLine())!=null){
        System.out.println("服务端收到："+line);
    }
}
```



* 在以上通信中，服务端会一致等待客户端的消息，如果客户端没有进行消息的发送，服务端将一直进入阻塞状态。
* 同时服务端是按照行获取消息的，这意味着客户端也必须按照行进行消息的发送，否则服务端将进入等待消息的阻塞状态！

## BIO模式下多发和多收消息

客户端代码如下

```java
public static void main(String[] args) throws Exception {
    System.out.println("==客户端的启动==");
    // （1）创建一个Socket的通信管道，请求与服务端的端口连接。
    Socket socket = new Socket("127.0.0.1", 8888);
    // （2）从Socket通信管道中得到一个字节输出流。
    OutputStream os = socket.getOutputStream();
    // （3）把字节流改装成自己需要的流进行数据的发送
    PrintStream ps = new PrintStream(os);
    // （4）开始发送消息
    Scanner sc = new Scanner(System.in);
    while (true) {
        System.out.print("请说:");
        String msg = sc.nextLine();
        ps.println(msg);
        ps.flush();
    }
}
```

服务端代码如下

```java
package com.itheima._03bio02;

import java.io.BufferedReader;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.net.ServerSocket;
import java.net.Socket;

/**
 * 服务端
 */
public class ServerDemo {
    public static void main(String[] args) throws Exception {
        String s = "886";
        System.out.println("886".equals(s));
        System.out.println("==服务器的启动==");
        //（1）注册端口
        ServerSocket serverSocket = new ServerSocket(8888);
        //（2）开始在这里暂停等待接收客户端的连接,得到一个端到端的Socket管道
        Socket socket = serverSocket.accept();
        //（3）从Socket管道中得到一个字节输入流。
        InputStream is = socket.getInputStream();
        //（4）把字节输入流包装成  自己需要的流进行数据的读取。
        BufferedReader br = new BufferedReader(new InputStreamReader(is));
        //（5）读取数据
        String line ;
        while((line = br.readLine())!=null){
            System.out.println("服务端收到："+line);
        }
    }
}
```



* 本案例中确实可以实现客户端多发多收
* 但是服务端只能处理一个客户端的请求，因为服务端是单线程的。一次只能与一个客户端进行消息通信。

## BIO模式下接收多个客户端


在上述的案例中，一个服务端只能接收一个客户端的通信请求，**那么如果服务端需要处理很多个客户端的消息通信请求应该如何处理呢**，此时我们就需要在服务端引入线程了，也就是说客户端每发起一个请求，服务端就创建一个新的线程来处理这个客户端的请求，这样就实现了一个客户端一个线程的模型

客户端案例代码如下

```java
/**
    客户端
 */
public class ClientDemo {
    public static void main(String[] args) throws Exception {
        // （1）创建一个Socket的通信管道，请求与服务端的端口连接。
        Socket socket = new Socket("127.0.0.1",7777);
        // （2）从Socket通信管道中得到一个字节输出流。
        OutputStream os = socket.getOutputStream();
        // （3）把字节流改装成自己需要的流进行数据的发送
        PrintStream ps = new PrintStream(os);
        // （4）开始发送消息
        Scanner sc = new Scanner(System.in);
        while(true){
            System.out.print("请说:");
            String msg = sc.nextLine();
            ps.println(msg);
            ps.flush();
        }
    }
}
```

服务端案例代码如下

```java
/**
    服务端
 */
public class ServerDemo {
    public static void main(String[] args) throws Exception {
        // （1）注册端口
        ServerSocket serverSocket = new ServerSocket(7777);
        while (true) {
            //（2）开始在这里暂停等待接收客户端的连接,得到一个端到端的Socket管道
            Socket socket = serverSocket.accept();
            new ServerReadThread(socket).start();
            System.out.println(socket.getRemoteSocketAddress() + "上线了！");
        }
    }

}

class ServerReadThread extends Thread {
    private Socket socket;

    public ServerReadThread(Socket socket) {
        this.socket = socket;
    }

    @Override
    public void run() {
        try {
            //（3）从Socket管道中得到一个字节输入流。
            InputStream is = socket.getInputStream();
            //（4）把字节输入流包装成自己需要的流进行数据的读取。
            BufferedReader br = new BufferedReader(new InputStreamReader(is));
            //（5）读取数据
            String line;
            while ((line = br.readLine()) != null) {
                System.out.println("服务端收到：" + socket.getRemoteSocketAddress() + ":" + line);
            }
        } catch (Exception e) {
            System.out.println(socket.getRemoteSocketAddress() + "下线了！");
        }
    }
}
```

小结:

* 1.每个Socket接收到，都会创建一个线程，线程的竞争、切换上下文影响性能；
* 2.每个线程都会占用栈空间和CPU资源；
* 3.并不是每个socket都进行IO操作，无意义的线程处理；
* 4.客户端的并发访问增加时。服务端将呈现1:1的线程开销，访问量越大，系统将发生线程栈溢出，线程创建失败，最终导致进程宕机或者僵死，从而不能对外提供服务。

## 伪异步I/O编程

在上述案例中：客户端的并发访问增加时。服务端将呈现1:1的线程开销，访问量越大，系统将发生线程栈溢出，线程创建失败，最终导致进程宕机或者僵死，从而不能对外提供服务。
接下来我们采用一个伪异步I/O的通信框架，采用线程池和任务队列实现，当客户端接入时，将客户端的Socket封装成一个Task(该任务实现java.lang.Runnable线程任务接口)交给后端的线程池中进行处理。JDK的线程池维护一个消息队列和N个活跃的线程，对消息队列中Socket任务进行处理，由于线程池可以设置消息队列的大小和最大线程数，因此，它的资源占用是可控的，无论多少个客户端并发访问，都不会导致资源的耗尽和宕机。


客户端源码分析

```java
public class ClientDemo {
    public static void main(String[] args) {
        try {
            // 1.简历一个与服务端的Socket对象：套接字
            Socket socket = new Socket("127.0.0.1", 9999);
            // 2.从socket管道中获取一个输出流，写数据给服务端
            OutputStream os = socket.getOutputStream();
            // 3.把输出流包装成一个打印流
            PrintWriter pw = new PrintWriter(os);
            // 4.反复接收用户的输入
            BufferedReader br = new BufferedReader(new InputStreamReader(System.in));
            String line = null;
            while ((line = br.readLine()) != null) {
                pw.println(line);
                pw.flush();
            }
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
```

线程池处理类

```java
// 线程池处理类
public class ServerSocketThreadPool {
    // 线程池
    private static final ExecutorService executor = new ThreadPoolExecutor(
            3,
            2,
            120L,
            TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(1000));

    public static void execute(Runnable task) {
        executor.execute(task);
    }
}
```

服务端源码分析

```java
public class ServerDemo {
    public static void main(String[] args) {
        try {
            ServerSocket ss = new ServerSocket(9999);

            // 客户端可能有很多个
            while (true) {
                Socket socket = ss.accept(); // 阻塞式的！
                System.out.println("有人上线了！！");
                // 每次收到一个客户端的socket请求，都需要为这个客户端分配一个
                // 独立的线程 专门负责对这个客户端的通信！！
                ServerSocketThreadPool.execute(new ReaderClientRunnable(socket));
            }
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}

class ReaderClientRunnable implements Runnable {

    private Socket socket;

    public ReaderClientRunnable(Socket socket) {
        this.socket = socket;
    }

    @Override
    public void run() {
        try {
            // 读取一行数据
            InputStream is = socket.getInputStream();
            // 转成一个缓冲字符流
            Reader fr = new InputStreamReader(is);
            BufferedReader br = new BufferedReader(fr);
            // 一行一行的读取数据
            String line = null;
            while ((line = br.readLine()) != null) { // 阻塞式的！！
                System.out.println("服务端收到了数据：" + line);
            }
        } catch (Exception e) {
            System.out.println("有人下线了");
        }
    }
}
```

小结

* 伪异步io采用了线程池实现，因此避免了为每个请求创建一个独立线程造成线程资源耗尽的问题，但由于底层依然是采用的同步阻塞模型，因此无法从根本上解决问题。
* 如果单个消息处理的缓慢，或者服务器线程池中的全部线程都被阻塞，那么后续socket的i/o消息都将在队列中排队。新的Socket请求将被拒绝，客户端会发生大量连接超时。



## 基于BIO形式下的文件上传

客户端开发

```java
public class Client {
    public static void main(String[] args) {
        try(
                InputStream is = new FileInputStream("D:/hello.jpg");
        ){
            //  1、请求与服务端的Socket链接
            Socket socket = new Socket("127.0.0.1" , 8888);
            //  2、把字节输出流包装成一个数据输出流
            DataOutputStream dos = new DataOutputStream(socket.getOutputStream());
            //  3、先发送上传文件的后缀给服务端
            dos.writeUTF(".png");
            //  4、把文件数据发送给服务端进行接收
            byte[] buffer = new byte[1024];
            int len;
            while((len = is.read(buffer)) &gt; 0 ){
                dos.write(buffer , 0 , len);
            }
            dos.flush();
            Thread.sleep(10000);
        }catch (Exception e){
            e.printStackTrace();
        }
    }
}
```

服务端开发

```java
public class Server {
    public static void main(String[] args) {
        try{
            ServerSocket ss = new ServerSocket(8888);
            while (true){
                Socket socket = ss.accept();
                // 交给一个独立的线程来处理与这个客户端的文件通信需求。
                new ServerReaderThread(socket).start();
            }
        }catch (Exception e){
            e.printStackTrace();
        }
    }
}
```

```java
public class ServerReaderThread extends Thread {
    private Socket socket;
    public ServerReaderThread(Socket socket){
        this.socket = socket;
    }
    @Override
    public void run() {
        try{
            // 1、得到一个数据输入流读取客户端发送过来的数据
            DataInputStream dis = new DataInputStream(socket.getInputStream());
            // 2、读取客户端发送过来的文件类型
            String suffix = dis.readUTF();
            System.out.println("服务端已经成功接收到了文件类型：" + suffix);
            // 3、定义一个字节输出管道负责把客户端发来的文件数据写出去
            OutputStream os = new FileOutputStream("D:/"+UUID.randomUUID().toString()+suffix);
            // 4、从数据输入流中读取文件数据，写出到字节输出流中去
            byte[] buffer = new byte[1024];
            int len;
            while((len = dis.read(buffer)) &gt; 0){
                os.write(buffer,0, len);
            }
            os.close();
            System.out.println("服务端接收文件保存成功！");
        }catch (Exception e){
            e.printStackTrace();
        }
    }
}
```

小结

客户端怎么发，服务端就怎么接收

# Java NIO深入剖析

* Java NIO（New IO）也有人称之为 java non-blocking IO是从Java 1.4版本开始引入的一个新的IO API，可以替代标准的Java IO API。NIO与原来的IO有同样的作用和目的，但是使用的方式完全不同，NIO支持面**向缓冲区**的、基于**通道**的IO操作。NIO将以更加高效的方式进行文件的读写操作。NIO可以理解为非阻塞IO,传统的IO的read和write只能阻塞执行，线程在读写IO期间不能干其他事情，比如调用socket.read()时，如果服务器一直没有数据传输过来，线程就一直阻塞，而NIO中可以配置socket为非阻塞模式。
*  NIO 相关类都被放在 java.nio 包及子包下，并且对原 java.io 包中的很多类进行改写。
* NIO 有三大核心部分：**Channel( 通道) ，Buffer( 缓冲区), Selector( 选择器)**
* Java NIO 的非阻塞模式，使一个线程从某通道发送请求或者读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取，而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此，一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。
* 通俗理解：NIO 是可以做到用一个线程来处理多个操作的。假设有 1000 个请求过来,根据实际情况，可以分配20 或者 80个线程来处理。不像之前的阻塞 IO 那样，非得分配 1000 个。

##  NIO 和 BIO 的比较

* BIO 以流的方式处理数据,而 NIO 以块的方式处理数据,块 I/O 的效率比流 I/O 高很多
* BIO 是阻塞的，NIO 则是非阻塞的
*  BIO 基于字节流和字符流进行操作，而 NIO 基于 Channel(通道)和 Buffer(缓冲区)进行操作，数据总是从通道
  读取到缓冲区中，或者从缓冲区写入到通道中。Selector(选择器)用于监听多个通道的事件（比如：连接请求，数据到达等），因此使用单个线程就可以监听多个客户端通道

| NIO                       | BIO                 |
| ------------------------- | ------------------- |
| 面向缓冲区（Buffer）      | 面向流（Stream）    |
| 非阻塞（Non Blocking IO） | 阻塞IO(Blocking IO) |
| 选择器（Selectors）       |                     |



## NIO 三大核心原理示意图

NIO 有三大核心部分：**Channel( 通道) ，Buffer( 缓冲区), Selector( 选择器)**

### Buffer缓冲区

缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象，并提供了一组方法，用来方便的访问该块内存。相比较直接对数组的操作，Buffer API更加容易操作和管理。

### **Channel（通道）**

Java NIO的通道类似流，但又有些不同：既可以从通道中读取数据，又可以写数据到通道。但流的（input或output)读写通常是单向的。 通道可以非阻塞读取和写入通道，通道可以支持读取或写入缓冲区，也支持异步地读写。

### Selector选择器

Selector是 一个Java NIO组件，可以能够检查一个或多个 NIO 通道，并确定哪些通道已经准备好进行读取或写入。这样，一个单独的线程可以管理多个channel，从而管理多个网络连接，提高效率


* 每个 channel 都会对应一个 Buffer
* 一个线程对应Selector ， 一个Selector对应多个 channel(连接)
* 程序切换到哪个 channel 是由事件决定的
*  Selector 会根据不同的事件，在各个通道上切换
* Buffer 就是一个内存块 ， 底层是一个数组
* 数据的读取写入是通过 Buffer完成的 , BIO 中要么是输入流，或者是输出流, 不能双向，但是 NIO 的 Buffer 是可以读也可以写。
* Java NIO系统的核心在于：通道(Channel)和缓冲区 (Buffer)。通道表示打开到 IO 设备(例如：文件、 套接字)的连接。若需要使用 NIO 系统，需要获取 用于连接 IO 设备的通道以及用于容纳数据的缓冲 区。然后操作缓冲区，对数据进行处理。简而言之，Channel 负责传输， Buffer 负责存取数据

## NIO核心一：缓冲区(Buffer)

一个用于特定基本数据类 型的容器。由 java.nio 包定义的，所有缓冲区 都是 Buffer 抽象类的子类.。Java NIO 中的 Buffer 主要用于与 NIO 通道进行 交互，数据是从通道读入缓冲区，从缓冲区写入通道中的


### Buffer 类及其子类

**Buffer** 就像一个数组，可以保存多个相同类型的数据。根 据数据类型不同 ，有以下 Buffer 常用子类：

* ByteBuffer
* CharBuffer
* ShortBuffer
* IntBuffer
*  LongBuffer
* FloatBuffer
* DoubleBuffer

上述 Buffer 类 他们都采用相似的方法进行管理数据，只是各自 管理的数据类型不同而已。都是通过`allocate(int capacity)`方法获取一个 Buffer 对象

### 缓冲区的基本属性

Buffer 中的重要概念：

* **容量 (capacity)** ：作为一个内存块，Buffer具有一定的固定大小，也称为"容量"，缓冲区容量不能为负，并且创建后不能更改。
*  **限制 (limit)**：表示缓冲区中可以操作数据的大小（limit 后数据不能进行读写）。缓冲区的限制不能为负，并且不能大于其容量。 **写入模式，限制等于buffer的容量。读取模式下，limit等于写入的数据量**。
* **位置 (position)**：下一个要读取或写入的数据的索引。缓冲区的位置不能为 负，并且不能大于其限制
* **标记 (mark)与重置 (reset)**：标记是一个索引，通过 Buffer 中的 mark() 方法 指定 Buffer 中一个特定的 position，之后可以通过调用 reset() 方法恢复到这 个 position.
   **标记、位置、限制、容量遵守以下不变式： 0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity**
* **图示:**

### Buffer常见方法

```java
Buffer clear() 清空缓冲区并返回对缓冲区的引用
Buffer flip() 为 将缓冲区的界限设置为当前位置，并将当前位置充值为 0
int capacity() 返回 Buffer 的 capacity 大小
boolean hasRemaining() 判断缓冲区中是否还有元素
int limit() 返回 Buffer 的界限(limit) 的位置
Buffer limit(int n) 将设置缓冲区界限为 n, 并返回一个具有新 limit 的缓冲区对象
Buffer mark() 对缓冲区设置标记
int position() 返回缓冲区的当前位置 position
Buffer position(int n) 将设置缓冲区的当前位置为 n , 并返回修改后的 Buffer 对象
int remaining() 返回 position 和 limit 之间的元素个数
Buffer reset() 将位置 position 转到以前设置的 mark 所在的位置
Buffer rewind() 将位置设为为 0， 取消设置的 mark
```

### 缓冲区的数据操作

```java
Buffer 所有子类提供了两个用于数据操作的方法：get()put() 方法
取获取 Buffer中的数据
get() ：读取单个字节
get(byte[] dst)：批量读取多个字节到 dst 中
get(int index)：读取指定索引位置的字节(不会移动 position)

放到 入数据到 Buffer 中 中
put(byte b)：将给定单个字节写入缓冲区的当前位置
put(byte[] src)：将 src 中的字节写入缓冲区的当前位置
put(int index, byte b)：将指定字节写入缓冲区的索引位置(不会移动 position)
```

**使用Buffer读写数据一般遵循以下四个步骤：**

* 1.写入数据到Buffer
* 2.调用flip()方法，转换为读取模式
* 3.从Buffer中读取数据
* 4.调用buffer.clear()方法或者buffer.compact()方法清除缓冲区


### 直接与非直接缓冲区

`byte byffer`可以是两种类型，一种是基于直接内存（也就是非堆内存）；另一种是非直接内存（也就是堆内存）。对于直接内存来说，JVM将会在IO操作上具有更高的性能，因为它直接作用于本地系统的IO操作。而非直接内存，也就是堆内存中的数据，如果要作IO操作，会先从本进程内存复制到直接内存，再利用本地IO处理。

从数据流的角度，非直接内存是下面这样的作用链：

```
本地IO--&gt;直接内存--&gt;非直接内存--&gt;直接内存--&gt;本地IO
```

而直接内存是：

```
本地IO--&gt;直接内存--&gt;本地IO
```

很明显，在做IO处理时，比如网络发送大量数据时，直接内存会具有更高的效率。直接内存使用allocateDirect创建，但是它比申请普通的堆内存需要耗费更高的性能。不过，这部分的数据是在JVM之外的，因此它不会占用应用的内存。所以呢，当你有很大的数据要缓存，并且它的生命周期又很长，那么就比较适合使用直接内存。只是一般来说，如果不是能带来很明显的性能提升，还是推荐直接使用堆内存。字节缓冲区是直接缓冲区还是非直接缓冲区可通过调用其 isDirect()  方法来确定。

**使用场景**

- 1 有很大的数据需要存储，它的生命周期又很长
- 2 适合频繁的IO操作，比如网络并发场景



## NIO核心二：通道(Channel)

通道（Channel）：由 java.nio.channels 包定义 的。Channel 表示 IO 源与目标打开的连接。 Channel 类似于传统的“流”。只不过 Channel 本身不能直接访问数据，Channel 只能与 Buffer 进行交互。

 NIO 的通道类似于流，但有些区别如下：

* 通道可以同时进行读写，而流只能读或者只能写
*  通道可以实现异步读写数据
*  通道可以从缓冲读数据，也可以写数据到缓冲:

BIO 中的 stream 是单向的，例如 FileInputStream 对象只能进行读取数据的操作，而 NIO 中的通道(Channel)是双向的，可以读操作，也可以写操作。

Channel 在 NIO 中是一个接口
```java
public interface Channel extends Closeable{}
```

### 常用的Channel实现类

* FileChannel：用于读取、写入、映射和操作文件的通道。
* DatagramChannel：通过 UDP 读写网络中的数据通道。
* SocketChannel：通过 TCP 读写网络中的数据。
* ServerSocketChannel：可以监听新进来的 TCP 连接，对每一个新进来的连接都会创建一个 SocketChannel。ServerSocketChanne 类似 ServerSocket , SocketChannel 类似 Socket

### FileChannel 类

获取通道的一种方式是对支持通道的对象调用getChannel() 方法。支持通道的类如下：

* FileInputStream
* FileOutputStream
* RandomAccessFile
* DatagramSocket
* Socket
* ServerSocket

获取通道的其他方式是使用 Files 类的静态方法 newByteChannel() 获取字节通道。或者通过通道的静态方法 open() 打开并返回指定通道

### FileChannel的常用方法

```java
int read(ByteBuffer dst) 从 从  Channel 到 中读取数据到  ByteBuffer
long  read(ByteBuffer[] dsts) 将 将  Channel 到 中的数据“分散”到  ByteBuffer[]
int  write(ByteBuffer src) 将 将  ByteBuffer 到 中的数据写入到  Channel
long write(ByteBuffer[] srcs) 将 将  ByteBuffer[] 到 中的数据“聚集”到  Channel
long position() 返回此通道的文件位置
FileChannel position(long p) 设置此通道的文件位置
long size() 返回此通道的文件的当前大小
FileChannel truncate(long s) 将此通道的文件截取为给定大小
void force(boolean metaData) 强制将所有对此通道的文件更新写入到存储设备中
```

本地文件写数据
```java
public class ChannelTest {
    @Test
    public void write(){
        try {
            // 1、字节输出流通向目标文件
            FileOutputStream fos = new FileOutputStream("hello.txt");
            // 2、得到字节输出流对应的通道Channel
            FileChannel channel = fos.getChannel();
            // 3、分配缓冲区
            ByteBuffer buffer = ByteBuffer.allocate(1024);
            buffer.put("hello,学习Java-NIO！".getBytes());
            // 4、把缓冲区切换成写出模式
            buffer.flip();
            channel.write(buffer);
            channel.close();
            System.out.println("写数据到文件中！");
        } catch (Exception e) {
            e.printStackTrace();
        }
    }
}
```

本地文件读数据
```java
public class ChannelTest {

    @Test
    public void read() throws Exception {
        // 1、定义一个文件字节输入流与源文件接通
        FileInputStream is = new FileInputStream("hello.txt");
        // 2、需要得到文件字节输入流的文件通道
        FileChannel channel = is.getChannel();
        // 3、定义一个缓冲区
        ByteBuffer buffer = ByteBuffer.allocate(1024);
        // 4、读取数据到缓冲区
        channel.read(buffer);
        buffer.flip();
        // 5、读取出缓冲区中的数据并输出即可
        String rs = new String(buffer.array(),0,buffer.remaining());
        System.out.println(rs);

    }
```

使用 FileChannel(通道) ，完成文件的拷贝。

```java
@Test
public void copy() throws Exception {
    // 源文件
    File srcFile = new File("D:/background.jpg");
    File destFile = new File("D:/backgroundNew.jpg");
    // 得到一个字节字节输入流
    FileInputStream fis = new FileInputStream(srcFile);
    // 得到一个字节输出流
    FileOutputStream fos = new FileOutputStream(destFile);
    // 得到的是文件通道
    FileChannel isChannel = fis.getChannel();
    FileChannel osChannel = fos.getChannel();
    // 分配缓冲区
    ByteBuffer buffer = ByteBuffer.allocate(1024); while(isChannel.read(buffer)!=-1){
        // 已经读取了数据 ，把缓冲区的模式切换成可读模式
        buffer.flip();
        // 把数据写出到
        osChannel.write(buffer);
         // 必须先清空缓冲然后再写入数据到缓冲区
        buffer.clear();
    }
    isChannel.close();
    osChannel.close();
    System.out.println("复制完成！");
}
```

### transferFrom

从目标通道中去复制原通道数据

```java
public static void main(String[] args) throws Exception {
    // 1、字节输入管道
    FileInputStream is = new FileInputStream("orange.txt");
    FileChannel isChannel = is.getChannel();
    // 2、字节输出流管道
    FileOutputStream fos = new FileOutputStream("orange-2.txt");
    FileChannel osChannel = fos.getChannel();
    // 3、复制
    osChannel.transferFrom(isChannel, isChannel.position(), isChannel.size());
    isChannel.close();
    osChannel.close();
}
```

### transferTo

把原通道数据复制到目标通道

```java
public static void main(String[] args) throws Exception {
    // 1、字节输入管道
    FileInputStream is = new FileInputStream("orange.txt");
    FileChannel isChannel = is.getChannel();
    // 2、字节输出流管道
    FileOutputStream fos = new FileOutputStream("orange-2.txt");
    FileChannel osChannel = fos.getChannel();
    // 3、复制
    isChannel.transferTo(isChannel.position(), isChannel.size(), osChannel);
    isChannel.close();
    osChannel.close();
}
```

## NIO核心三：选择器(Selector)

选择器（Selector） 是 SelectableChannle 对象的多路复用器，Selector 可以同时监控多个 SelectableChannel 的 IO 状况，也就是说，利用 Selector可使一个单独的线程管理多个 Channel。Selector 是非阻塞 IO 的核心


* Java 的 NIO，用非阻塞的 IO 方式。可以用一个线程，处理多个的客户端连接，就会使用到 Selector(选择器)

* Selector 能够检测多个注册的通道上是否有事件发生(注意:多个 Channel 以事件的方式可以注册到同一个
  Selector)，如果有事件发生，便获取事件然后针对每个事件进行相应的处理。这样就可以只用一个单线程去管
  理多个通道，也就是管理多个连接和请求。

* 只有在 连接/通道 真正有读写事件发生时，才会进行读写，就大大地减少了系统开销，并且不必为每个连接都
  创建一个线程，不用去维护多个线程

* 避免了多线程之间的上下文切换导致的开销


创建 Selector ：通过调用 Selector.open() 方法创建一个 Selector。

```java
Selector selector = Selector.open();
```

向选择器注册通道：SelectableChannel.register(Selector sel, int ops)

```java
//1. 获取通道
ServerSocketChannel ssChannel = ServerSocketChannel.open();
//2. 切换非阻塞模式
ssChannel.configureBlocking(false);
//3. 绑定连接
ssChannel.bind(new InetSocketAddress(9898));
//4. 获取选择器
Selector selector = Selector.open();
//5. 将通道注册到选择器上, 并且指定“监听接收事件”
ssChannel.register(selector, SelectionKey.OP_ACCEPT);
```

当调用 register(Selector sel, int ops) 将通道注册选择器时，选择器对通道的监听事件，需要通过第二个参数 ops 指定。可以监听的事件类型（用 可使用 SelectionKey  的四个常量 表示）：

* 读 : SelectionKey.OP_READ （1）
* 写 : SelectionKey.OP_WRITE （4）
* 连接 : SelectionKey.OP_CONNECT （8）
*  接收 : SelectionKey.OP_ACCEPT （16）
* 若注册时不止监听一个事件，则可以使用“位或”操作符连接。

```java
int interestSet = SelectionKey.OP_READ|SelectionKey.OP_WRITE
```

## NIO非阻塞式网络通信原理分析

Selector可以实现： 一个 I/O 线程可以并发处理 N 个客户端连接和读写操作，这从根本上解决了传统同步阻塞 I/O 一连接一线程模型，架构的性能、弹性伸缩能力和可靠性都得到了极大的提升。

### 服务端流程

当客户端连接服务端时，服务端会通过 ServerSocketChannel 得到 SocketChannel

```java
public static void main(String[] args) throws Exception {
    //1、获取通道
    ServerSocketChannel ssChannel = ServerSocketChannel.open();
    //2、切换非阻塞模式
    ssChannel.configureBlocking(false);
    //3、绑定连接
    ssChannel.bind(new InetSocketAddress(9999));
    //4、获取选择器
    Selector selector = Selector.open();
    //5、将通道注册到选择器上, 并且指定“监听接收事件”
    ssChannel.register(selector, SelectionKey.OP_ACCEPT);
    //6. 轮询式的获取选择器上已经“准备就绪”的事件
    while (selector.select() &gt; 0) {
        System.out.println("轮一轮");
        //7. 获取当前选择器中所有注册的“选择键(已就绪的监听事件)”
        Iterator&lt;SelectionKey&gt; it = selector.selectedKeys().iterator();
        while (it.hasNext()) {
            //8. 获取准备“就绪”的是事件
            SelectionKey sk = it.next();
            //9. 判断具体是什么事件准备就绪
            if (sk.isAcceptable()) {
                //10. 若“接收就绪”，获取客户端连接
                SocketChannel sChannel = ssChannel.accept();
                //11. 切换非阻塞模式
                sChannel.configureBlocking(false);
                //12. 将该通道注册到选择器上
                sChannel.register(selector, SelectionKey.OP_READ);
            } else if (sk.isReadable()) {
                //13. 获取当前选择器上“读就绪”状态的通道
                SocketChannel sChannel = (SocketChannel) sk.channel();
                //14. 读取数据
                ByteBuffer buf = ByteBuffer.allocate(1024);
                int len = 0;
                while ((len = sChannel.read(buf)) &gt; 0) {
                    buf.flip();
                    System.out.println(new String(buf.array(), 0, len));
                    buf.clear();
                }
            }
            //15. 取消选择键 SelectionKey
            it.remove();
        }
    }
}
```

### 客户端流程
```java
public static void main(String[] args) throws Exception {
    // 1. 获取通道
    SocketChannel sChannel = SocketChannel.open(new InetSocketAddress("127.0.0.1", 9999));
    // 2. 切换非阻塞模式
    sChannel.configureBlocking(false);
    //3. 分配指定大小的缓冲区
    ByteBuffer buf = ByteBuffer.allocate(1024);
    //4. 发送数据给服务端
    Scanner scan = new Scanner(System.in);
    while (scan.hasNext()) {
        String str = scan.nextLine();
        buf.put((new SimpleDateFormat("yyyy/MM/dd HH:mm:ss").format(System.currentTimeMillis()) + "\n" + str).getBytes());
        buf.flip();
        sChannel.write(buf);
        buf.clear();
    }
    //关闭通道
    sChannel.close();
}
```


## NIO非阻塞式网络通信入门案例

需求：服务端接收客户端的连接请求，并接收多个客户端发送过来的事件。

```java
/**
  客户端
 */
public class Client {
    public static void main(String[] args) throws Exception {
        //1. 获取通道
        SocketChannel sChannel = SocketChannel.open(new InetSocketAddress("127.0.0.1", 9999));
        //2. 切换非阻塞模式
        sChannel.configureBlocking(false);
        //3. 分配指定大小的缓冲区
        ByteBuffer buf = ByteBuffer.allocate(1024);
        //4. 发送数据给服务端
        Scanner scan = new Scanner(System.in);
        while (scan.hasNext()) {
            String str = scan.nextLine();
            String dateTime = new SimpleDateFormat("yyyy/MM/dd HH:mm:ss").format(System.currentTimeMillis());
            String message = dateTime + str;
            buf.put(message.getBytes());
            buf.flip();
            sChannel.write(buf);
            buf.clear();
        }
        //5. 关闭通道
        sChannel.close();
    }
}
```

```java
/**
 服务端
 */
public class Server {
    public static void main(String[] args) throws Exception {
        //1. 获取通道
        ServerSocketChannel ssChannel = ServerSocketChannel.open();
        //2. 切换非阻塞模式
        ssChannel.configureBlocking(false);
        //3. 绑定连接
        ssChannel.bind(new InetSocketAddress(9999));
        //4. 获取选择器
        Selector selector = Selector.open();
        //5. 将通道注册到选择器上, 并且指定“监听接收事件”
        ssChannel.register(selector, SelectionKey.OP_ACCEPT);
        //6. 轮询式的获取选择器上已经“准备就绪”的事件
        while (selector.select() &gt; 0) {
            System.out.println("轮一轮");
            //7. 获取当前选择器中所有注册的“选择键(已就绪的监听事件)”
            Iterator&lt;SelectionKey&gt; it = selector.selectedKeys().iterator();
            while (it.hasNext()) {
                //8. 获取准备“就绪”的是事件
                SelectionKey sk = it.next();
                //9. 判断具体是什么事件准备就绪
                if (sk.isAcceptable()) {
                    //10. 若“接收就绪”，获取客户端连接
                    SocketChannel sChannel = ssChannel.accept();
                    //11. 切换非阻塞模式
                    sChannel.configureBlocking(false);
                    //12. 将该通道注册到选择器上
                    sChannel.register(selector, SelectionKey.OP_READ);
                } else if (sk.isReadable()) {
                    //13. 获取当前选择器上“读就绪”状态的通道
                    SocketChannel sChannel = (SocketChannel) sk.channel();
                    //14. 读取数据
                    ByteBuffer buf = ByteBuffer.allocate(1024);
                    int len = 0;
                    while ((len = sChannel.read(buf)) &gt; 0) {
                        buf.flip();
                        System.out.println(new String(buf.array(), 0, len));
                        buf.clear();
                    }
                }
                //15. 取消选择键 SelectionKey
                it.remove();
            }
        }
    }
}
```

## NIO 网络编程应用实例-群聊系统


* 编写一个 NIO 群聊系统，实现客户端与客户端的通信需求（非阻塞）
* 服务器端：可以监测用户上线，离线，并实现消息转发功能
* 客户端：通过 channel 可以无阻塞发送消息给其它所有客户端用户，同时可以接受其它客户端用户通过服务端转发来的消息

服务端代码实现

```java
public class ServerDemo {
    //定义属性
    private Selector selector;
    private ServerSocketChannel ssChannel;
    private static final int PORT = 9999;

    //构造器
    //初始化工作
    public ServerDemo() {
        try {
            // 1、获取通道
            ssChannel = ServerSocketChannel.open();
            // 2、切换为非阻塞模式
            ssChannel.configureBlocking(false);
            // 3、绑定连接的端口
            ssChannel.bind(new InetSocketAddress(PORT));
            // 4、获取选择器Selector
            selector = Selector.open();
            // 5、将通道都注册到选择器上去，并且开始指定监听接收事件
            ssChannel.register(selector, SelectionKey.OP_ACCEPT);
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    //监听
    public void listen() {
        System.out.println("监听线程: " + Thread.currentThread().getName());
        try {
            while (selector.select() &gt; 0) {
                System.out.println("开始一轮事件处理~~~");
                // 7、获取选择器中的所有注册的通道中已经就绪好的事件
                Iterator&lt;SelectionKey&gt; it = selector.selectedKeys().iterator();
                // 8、开始遍历这些准备好的事件
                while (it.hasNext()) {
                    // 提取当前这个事件
                    SelectionKey sk = it.next();
                    // 9、判断这个事件具体是什么
                    if (sk.isAcceptable()) {
                        // 10、直接获取当前接入的客户端通道
                        SocketChannel sChannel = ssChannel.accept();
                        // 11 、切换成非阻塞模式
                        sChannel.configureBlocking(false);
                        // 12、将本客户端通道注册到选择器
                        System.out.println(sChannel.getRemoteAddress() + " 上线 ");
                        sChannel.register(selector, SelectionKey.OP_READ);
                        //提示
                    } else if (sk.isReadable()) {
                        //处理读 (专门写方法..)
                        readData(sk);
                    }
                    // 处理完毕之后需要移除当前事件
                    it.remove();
                }
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            //发生异常处理....
        }
    }

    //读取客户端消息
    private void readData(SelectionKey key) {
        //取到关联的channle
        SocketChannel channel = null;
        try {
            //得到channel
            channel = (SocketChannel) key.channel();
            //创建buffer
            ByteBuffer buffer = ByteBuffer.allocate(1024);
            int count = channel.read(buffer);
            //根据count的值做处理
            if (count &gt; 0) {
                //把缓存区的数据转成字符串
                String msg = new String(buffer.array());
                //输出该消息
                System.out.println("form 客户端: " + msg);
                //向其它的客户端转发消息(去掉自己), 专门写一个方法来处理
                sendInfoToOtherClients(msg, channel);
            }
        } catch (IOException e) {
            try {
                System.out.println(channel.getRemoteAddress() + " 离线了..");
                e.printStackTrace();
                //取消注册
                key.cancel();
                //关闭通道
                channel.close();
            } catch (IOException e2) {
                e2.printStackTrace();
            }
        }
    }

    //转发消息给其它客户(通道)
    private void sendInfoToOtherClients(String msg, SocketChannel self) throws IOException {
        System.out.println("服务器转发消息中...");
        System.out.println("服务器转发数据给客户端线程: " + Thread.currentThread().getName());
        //遍历 所有注册到selector 上的 SocketChannel,并排除 self
        for (SelectionKey key : selector.keys()) {
            //通过 key  取出对应的 SocketChannel
            Channel targetChannel = key.channel();
            //排除自己
            if (targetChannel instanceof SocketChannel &amp;&amp; targetChannel != self) {
                //转型
                SocketChannel dest = (SocketChannel) targetChannel;
                //将msg 存储到buffer
                ByteBuffer buffer = ByteBuffer.wrap(msg.getBytes());
                //将buffer 的数据写入 通道
                dest.write(buffer);
            }
        }
    }

    public static void main(String[] args) {
        //创建服务器对象
        ServerDemo groupChatServer = new ServerDemo();
        groupChatServer.listen();
    }
}
```

客户端代码实现
```java
public class ClientDemo {
    //定义相关的属性
    private final String HOST = "127.0.0.1"; // 服务器的ip
    private final int PORT = 9999; //服务器端口
    private Selector selector;
    private SocketChannel socketChannel;
    private String username;

    //构造器, 完成初始化工作
    public ClientDemo() throws IOException {
        selector = Selector.open();
        //连接服务器
        socketChannel = socketChannel.open(new InetSocketAddress("127.0.0.1", PORT));
        //设置非阻塞
        socketChannel.configureBlocking(false);
        //将channel 注册到selector
        socketChannel.register(selector, SelectionKey.OP_READ);
        //得到username
        username = socketChannel.getLocalAddress().toString().substring(1);
        System.out.println(username + " is ok...");

    }

    //向服务器发送消息
    public void sendInfo(String info) {
        info = username + " 说：" + info;
        try {
            socketChannel.write(ByteBuffer.wrap(info.getBytes()));
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    //读取从服务器端回复的消息
    public void readInfo() {
        try {
            int readChannels = selector.select();
            //有可以用的通道
            if (readChannels &gt; 0) {
                Iterator&lt;SelectionKey&gt; iterator = selector.selectedKeys().iterator();
                while (iterator.hasNext()) {
                    SelectionKey key = iterator.next();
                    if (key.isReadable()) {
                        //得到相关的通道
                        SocketChannel sc = (SocketChannel) key.channel();
                        //得到一个Buffer
                        ByteBuffer buffer = ByteBuffer.allocate(1024);
                        //读取
                        sc.read(buffer);
                        //把读到的缓冲区的数据转成字符串
                        String msg = new String(buffer.array());
                        System.out.println(msg.trim());
                    }
                }
                //删除当前的selectionKey, 防止重复操作
                iterator.remove();
            } else {
                //System.out.println("没有可以用的通道...");
            }
        } catch (Exception e) {
            e.printStackTrace();
        }
    }

    public static void main(String[] args) throws Exception {
        //启动我们客户端
        ClientDemo chatClient = new ClientDemo();
        //启动一个线程, 每个3秒，读取从服务器发送数据
        new Thread(() -&gt; {
            while (true) {
                chatClient.readInfo();
                try {
                    Thread.currentThread().sleep(3000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }).start();

        //发送数据给服务器端
        Scanner scanner = new Scanner(System.in);
        while (scanner.hasNextLine()) {
            String s = scanner.nextLine();
            chatClient.sendInfo(s);
        }
    }
}
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/16246301.html</id>
        <title type="text">Java-运行时数据区-青橙e</title>
        <summary type="html"></summary>
        <published>2022-05-08T10:04:00Z</published>
        <updated>2022-05-08T10:04:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/16246301.html" />
        <content type="text">-摘自《深入理解Java虚拟机》

Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。这些区域 有各自的用途，以及创建和销毁的时间，有的区域随着虚拟机进程的启动而一直存在，有些区域则是 依赖用户线程的启动和结束而建立和销毁。根据《Java虚拟机规范》的规定，Java虚拟机所管理的内存 将会包括以下几个运行时数据区域

 ![](https://img2022.cnblogs.com/blog/1801000/202205/1801000-20220508181726297-743095264.png)




# 程序计数器

程序计数器（Program Counter Register）是一块较小的内存空间，它可以看作是当前线程所执行的 字节码的行号指示器。在Java虚拟机的概念模型里，字节码解释器工作时就是通过改变这个计数器 的值来选取下一条需要执行的字节码指令，它是程序控制流的指示器，分支、循环、跳转、异常处 理、线程恢复等基础功能都需要依赖这个计数器来完成。 由于Java虚拟机的多线程是通过线程轮流切换、分配处理器执行时间的方式来实现的，在任何一 个确定的时刻，一个处理器（对于多核处理器来说是一个内核）都只会执行一条线程中的指令。因 此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程 之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存。 如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是本地（Native）方法，这个计数器值则应为空（Undefined）。此内存区域是唯一一个在《Java虚拟机规范》中没有规定任何OutOfMemoryError情况的区域。


 # Java虚拟机栈

Java虚拟机栈（Java Virtual Machine Stack）也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是Java方法执行的线程内存模型：每个方法被执行的时候，Java虚拟机都 会同步创建一个栈帧[1]（Stack Frame）用于存储局部变量表、操作数栈、动态连接、方法出口等信 息。每一个方法被调用直至执行完毕的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 经常有人把Java内存区域笼统地划分为堆内存（Heap）和栈内存（Stack），这种划分方式直接继 承自传统的C、C++程序的内存布局结构，在Java语言里就显得有些粗糙了，实际的内存区域划分要比 这更复杂。不过这种划分方式的流行也间接说明了程序员最关注的、与对象内存分配关系最密切的区 域是“堆”和“栈”两块。“栈”通常就是指这里讲的虚拟机栈，或者更多的情况下只是指虚拟机栈中局部变量表部分。局部变量表存放了编译期可知的各种Java虚拟机基本数据类型（boolean、byte、char、short、int、 float、long、double）、对象引用（reference类型，它并不等同于对象本身，可能是一个指向对象起始 地址的引用指针，也可能是指向一个代表对象的句柄或者其他与此对象相关的位置）和returnAddress 类型（指向了一条字节码指令的地址）。 这些数据类型在局部变量表中的存储空间以局部变量槽（Slot）来表示，其中64位长度的long和 double类型的数据会占用两个变量槽，其余的数据类型只占用一个。局部变量表所需的内存空间在编 译期间完成分配，当进入一个方法时，这个方法需要在栈帧中分配多大的局部变量空间是完全确定 的，在方法运行期间不会改变局部变量表的大小。这里说的“大小”是指变量槽的数量，虚拟机真正使用多大的内存空间（譬如按照1个变量槽占用32个比特、64个比特，或者更多）来实现一个变量槽，这是完全由具体的虚拟机实现自行决定的事情。 在《Java虚拟机规范》中，对这个内存区域规定了两类异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果Java虚拟机栈容量可以动态扩展，当栈扩展时无法申请到足够的内存会抛出OutOfMemoryError异常。


 # 本地方法栈

 本地方法栈（Native Method Stacks）与虚拟机栈所发挥的作用是非常相似的，其区别只是虚拟机栈为虚拟机执行Java方法（也就是字节码）服务，而本地方法栈则是为虚拟机使用到的本地（Native） 方法服务。 《Java虚拟机规范》对本地方法栈中方法使用的语言、使用方式与数据结构并没有任何强制规 定，因此具体的虚拟机可以根据需要自由实现它，甚至有的Java虚拟机（譬如Hot-Spot虚拟机）直接 就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法栈也会在栈深度溢出或者栈扩展失 败时分别抛出StackOverflowError和OutOfMemoryError异常。


 # Java堆

 对于Java应用程序来说，Java堆（Java Heap）是虚拟机所管理的内存中最大的一块。Java堆是被所 有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，Java 世界里“几乎”所有的对象实例都在这里分配内存。在《Java虚拟机规范》中对Java堆的描述是：“所有 的对象实例以及数组都应当在堆上分配[1]”，而这里笔者写的“几乎”是指从实现角度来看，随着Java语 言的发展，现在已经能看到些许迹象表明日后可能出现值类型的支持，即使只考虑现在，由于即时编 译技术的进步，尤其是逃逸分析技术的日渐强大，栈上分配、标量替换[2]优化手段已经导致一些微妙 的变化悄然发生，所以说Java对象实例都分配在堆上也渐渐变得不是那么绝对了。 Java堆是垃圾收集器管理的内存区域，因此一些资料中它也被称作“GC堆”（Garbage Collected Heap，幸好国内没翻译成“垃圾堆”）。从回收内存的角度看，由于现代垃圾收集器大部分都是基于分 代收集理论设计的，所以Java堆中经常会出现“新生代”“老年代”“永久代”“Eden空间”“From Survivor空 间”“To Survivor空间”等名词，这些概念在本书后续章节中还会反复登场亮相，在这里笔者想先说明的 是这些区域划分仅仅是一部分垃圾收集器的共同特性或者说设计风格而已，而非某个Java虚拟机具体 实现的固有内存布局，更不是《Java虚拟机规范》里对Java堆的进一步细致划分。不少资料上经常写着 类似于“Java虚拟机的堆内存分为新生代、老年代、永久代、Eden、Survivor……”这样的内容。在十年 之前（以G1收集器的出现为分界），作为业界绝对主流的HotSpot虚拟机，它内部的垃圾收集器全部 都基于“经典分代”[3]来设计，需要新生代、老年代收集器搭配才能工作，在这种背景下，上述说法还 算是不会产生太大歧义。但是到了今天，垃圾收集器技术与十年前已不可同日而语，HotSpot里面也出 现了不采用分代设计的新垃圾收集器，再按照上面的提法就有很多需要商榷的地方了。 如果从分配内存的角度看，所有线程共享的Java堆中可以划分出多个线程私有的分配缓冲区 （Thread Local Allocation Buffer，TLAB），以提升对象分配时的效率。不过无论从什么角度，无论如 何划分，都不会改变Java堆中存储内容的共性，无论是哪个区域，存储的都只能是对象的实例，将Java 堆细分的目的只是为了更好地回收内存，或者更快地分配内存。在本章中，我们仅仅针对内存区域的 作用进行讨论，Java堆中的上述各个区域的分配、回收等细节将会是下一章的主题。 根据《Java虚拟机规范》的规定，Java堆可以处于物理上不连续的内存空间中，但在逻辑上它应该 被视为连续的，这点就像我们用磁盘空间去存储文件一样，并不要求每个文件都连续存放。但对于大 对象（典型的如数组对象），多数虚拟机实现出于实现简单、存储高效的考虑，很可能会要求连续的 内存空间。 Java堆既可以被实现成固定大小的，也可以是可扩展的，不过当前主流的Java虚拟机都是按照可扩 展来实现的（通过参数-Xmx和-Xms设定）。如果在Java堆中没有内存完成实例分配，并且堆也无法再 扩展时，Java虚拟机将会抛出OutOfMemoryError异常。


 # 方法区

 方法区（Method Area）与Java堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载 的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。虽然《Java虚拟机规范》中把 方法区描述为堆的一个逻辑部分，但是它却有一个别名叫作“非堆”（Non-Heap），目的是与Java堆区 分开来。说到方法区，不得不提一下“永久代”这个概念，尤其是在JDK 8以前，许多Java程序员都习惯在 HotSpot虚拟机上开发、部署程序，很多人都更愿意把方法区称呼为“永久代”（Permanent Generation），或将两者混为一谈。本质上这两者并不是等价的，因为仅仅是当时的HotSpot虚拟机设 计团队选择把收集器的分代设计扩展至方法区，或者说使用永久代来实现方法区而已，这样使得 HotSpot的垃圾收集器能够像管理Java堆一样管理这部分内存，省去专门为方法区编写内存管理代码的 工作。但是对于其他虚拟机实现，譬如BEA JRockit、IBM J9等来说，是不存在永久代的概念的。原则 上如何实现方法区属于虚拟机实现细节，不受《Java虚拟机规范》管束，并不要求统一。但现在回头 来看，当年使用永久代来实现方法区的决定并不是一个好主意，这种设计导致了Java应用更容易遇到 内存溢出的问题（永久代有-XX：MaxPermSize的上限，即使不设置也有默认大小，而J9和JRockit只要 没有触碰到进程可用内存的上限，例如32位系统中的4GB限制，就不会出问题），而且有极少数方法 （例如String::intern()）会因永久代的原因而导致不同虚拟机下有不同的表现。当Oracle收购BEA获得了 JRockit的所有权后，准备把JRockit中的优秀功能，譬如Java Mission Control管理工具，移植到HotSpot 虚拟机时，但因为两者对方法区实现的差异而面临诸多困难。考虑到HotSpot未来的发展，在JDK 6的 时候HotSpot开发团队就有放弃永久代，逐步改为采用本地内存（Native Memory）来实现方法区的计 划了[1]，到了JDK 7的HotSpot，已经把原本放在永久代的字符串常量池、静态变量等移出，而到了 JDK 8，终于完全废弃了永久代的概念，改用与JRockit、J9一样在本地内存中实现的元空间（Meta- space）来代替，把JDK 7中永久代还剩余的内容（主要是类型信息）全部移到元空间中。 《Java虚拟机规范》对方法区的约束是非常宽松的，除了和Java堆一样不需要连续的内存和可以选 择固定大小或者可扩展外，甚至还可以选择不实现垃圾收集。相对而言，垃圾收集行为在这个区域的 确是比较少出现的，但并非数据进入了方法区就如永久代的名字一样“永久”存在了。这区域的内存回 收目标主要是针对常量池的回收和对类型的卸载，一般来说这个区域的回收效果比较难令人满意，尤 其是类型的卸载，条件相当苛刻，但是这部分区域的回收有时又确实是必要的。以前Sun公司的Bug列 表中，曾出现过的若干个严重的Bug就是由于低版本的HotSpot虚拟机对此区域未完全回收而导致内存 泄漏。根据《Java虚拟机规范》的规定，如果方法区无法满足新的内存分配需求时，将抛出 OutOfMemoryError异常。


 # 运行时常量池

 运行时常量池（Runtime Constant Pool）是方法区的一部分。Class文件中除了有类的版本、字 段、方法、接口等描述信息外，还有一项信息是常量池表（Constant Pool Table），用于存放编译期生 成的各种字面量与符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。 Java虚拟机对于Class文件每一部分（自然也包括常量池）的格式都有严格规定，如每一个字节用 于存储哪种数据都必须符合规范上的要求才会被虚拟机认可、加载和执行，但对于运行时常量池， 《Java虚拟机规范》并没有做任何细节的要求，不同提供商实现的虚拟机可以按照自己的需要来实现这个内存区域，不过一般来说，除了保存Class文件中描述的符号引用外，还会把由符号引用翻译出来 的直接引用也存储在运行时常量池中。 运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性，Java语言并不要求常量一定只有编译期才能产生，也就是说，并非预置入Class文件中常量池的内容才能进入方法区运行时常量池，运行期间也可以将新的常量放入池中，这种特性被开发人员利用得比较多的便是String类的 intern()方法。 既然运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存 时会抛出OutOfMemoryError异常。


 # 直接内存

 直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是《Java虚拟机规范》中定义的内存区域。但是这部分内存也被频繁地使用，而且也可能导致OutOfMemoryError异常出现，在JDK 1.4中新加入了NIO（New Input/Output）类，引入了一种基于通道（Channel）与缓冲区 （Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的 DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了 在Java堆和Native堆中来回复制数据。 显然，本机直接内存的分配不会受到Java堆大小的限制，但是，既然是内存，则肯定还是会受到 本机总内存（包括物理内存、SWAP分区或者分页文件）大小以及处理器寻址空间的限制，一般服务 器管理员配置虚拟机参数时，会根据实际内存去设置-Xmx等参数信息，但经常忽略掉直接内存，使得 各个内存区域总和大于物理内存限制（包括物理的和操作系统级的限制），从而导致动态扩展时出现 OutOfMemoryError异常。</content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/16858330.html</id>
        <title type="text">Linux-防火墙操作-青橙e</title>
        <summary type="html"></summary>
        <published>2022-11-04T08:45:00Z</published>
        <updated>2022-11-04T08:45:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/16858330.html" />
        <content type="text">
# 描述

CentOS6自带的防火墙是iptables，CentOS7自带的防火墙是firewall。
**iptables：**用于过滤数据包，属于网络层防火墙。
**firewall：**底层还是使用 iptables 对内核命令动态通信包过滤的，简单理解就是firewall是centos7下管理

# iptables 防火墙

```
# 查看防火墙状态
service iptables status

# 停止防火墙
service iptables stop

# 启动防火墙
service iptables start

# 重启防火墙
service iptables restart

# 永久关闭防火墙
chkconfig iptables off

# 永久关闭后重启
chkconfig iptables on
```

## 开启80端口

```
# 编辑iptales
vim /etc/sysconfig/iptables

# 加入以下代码然后保存退出
-A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT

#重启防火墙
service iptables restart
```

# firewall 防火墙

## 查看firewall服务状态

```
systemctl status firewalld
```

出现Active: **active (running)**绿色高亮显示则表示是启动状态。 出现 Active: inactive (dead)灰色表示停止状态。

## 查看firewall的状态

```
firewall-cmd --state
```

## 开启、重启、关闭firewall服务

```
# 开启
service firewalld start

# 重启
service firewalld restart

# 关闭
service firewalld stop

4.查看防火墙规则
firewall-cmd --list-all
```

## 查看、开放、关闭端口

```
# 查询端口是否开放
firewall-cmd --query-port=8080/tcp

# 开放80端口
firewall-cmd --permanent --add-port=80/tcp

# 移除端口
firewall-cmd --permanent --remove-port=8080/tcp

#重启防火墙(修改配置后要重启防火墙)
firewall-cmd --reload
```

## 指定IP和端口访问

```
# 添加规则
firewall-cmd --permanent --add-rich-rule="rule family="ipv4" source address="192.168.1.100" port protocol="tcp" port="8080" accept"

# 移除规则
firewall-cmd --permanent --remove-rich-rule="rule family="ipv4" source address="192.168.1.100" port protocol="tcp" port="8080" accept"
```

## firewall 常用命令

```
# 查看防火墙状态，是否是running
firewall-cmd --state

# 重新载入配置，比如添加规则之后，需要执行此命令
firewall-cmd --reload

# 列出支持的zone
firewall-cmd --get-zones

# 列出支持的服务，在列表中的服务是放行的
firewall-cmd --get-services

# 查看ftp服务是否支持，返回yes或者no
firewall-cmd --query-service ftp

# 临时开放ftp服务
firewall-cmd --add-service=ftp

# 永久开放ftp服务
firewall-cmd --add-service=ftp --permanent

# 永久移除ftp服务
firewall-cmd --remove-service=ftp --permanent

# 永久添加80端口
firewall-cmd --add-port=80/tcp --permanent

# 查看规则，这个命令和iptables的相同
iptables -L -n

# 查看帮助
man firewall-cmd
```
        </content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/16858453.html</id>
        <title type="text">MySQL-修改密码及远程登录-青橙e</title>
        <summary type="html"></summary>
        <published>2022-11-04T09:06:00Z</published>
        <updated>2022-11-04T09:06:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/16858453.html" />
        <content type="text">修改密码
```
ALTER USER 'root'@'localhost' IDENTIFIED BY 'password';
```

添加用户
```
CREATE USER 'orange'@'%' IDENTIFIED BY 'password';
```

授权
```
GRANT ALL ON *.* TO 'orange'@'%';
```

支持远程登录
```
ALTER USER 'orange'@'%' IDENTIFIED WITH mysql_native_password BY 'password';
```

刷新权限
```
FLUSH PRIVILEGES;
```</content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/17277595.html</id>
        <title type="text">RockyLinux9配置网络-青橙e</title>
        <summary type="html"></summary>
        <published>2023-03-31T13:59:00Z</published>
        <updated>2023-03-31T13:59:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/17277595.html" />
        <content type="text">编辑配置文件`vim /etc/sysconfig/network-scripts/ifcfg-enp0s3` ```bash TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=none DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=no NAME=enp0s3 DEVICE=enp0s3 ONBOOT=yes IPADDR=192.168.1.110 PREFIX=24 GATEWAY=192.168.1.1 DNS1=8.8.8.8 DNS2=114.114.114.114 IPV6_DISABLED=yes
```

重新加载配置文件
```bash
nmcli connection load /etc/sysconfig/network-scripts/ifcfg-enp0s3
```

激活配置文件
```bash
nmcli connection up /etc/sysconfig/network-scripts/ifcfg-enp0s3
```</content>
    </entry>
    <entry>
        <id>https://www.cnblogs.com/cy-e/p/17290390.html</id>
        <title type="text">数据结构与算法-青橙e</title>
        <summary type="html"></summary>
        <published>2023-04-05T10:44:00Z</published>
        <updated>2023-04-05T10:44:00Z</updated>
        <author>
            <name>青橙e</name>
            <uri>https://www.cnblogs.com/cy-e</uri>
        </author>
        <link rel="alternate" href="https://www.cnblogs.com/cy-e/p/17290390.html" />
        <content type="text"># 时间复杂度
计算机科学中，时间复杂度是用来衡量：一个算法的执行，随数据规模增大，而增长的时间成本

表示时间复杂度：假设算法要处理的数据规模是n，代码总的执行行数用函数 f(n)来表示：
- 线性查找算法的函数：f(n)= 3*n +3
- 二分查找算法的函数：f(n) = ($floor(\log_{2}n))$ + 1)* 5 + 4

# 二分法查找

```
public static int binarySearchMethod(int[] array, int target) {
    int i = 0, j = array.length;
    while (i &lt;= j) {
        int center = (i + j) / 2;
        if (target &gt; array[center]) {
            i = center + 1;
        } else if (target &lt; array[center]) {
            j = center - 1;
        } else {
            return center;
        }
    }
    return -1;
}
```</content>
    </entry>
</feed>